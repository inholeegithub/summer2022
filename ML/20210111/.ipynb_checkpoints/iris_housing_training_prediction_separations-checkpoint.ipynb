{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:30:23.757040Z",
     "start_time": "2022-06-24T02:28:21.481541Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihlee\\anaconda3\\envs\\testAI\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\ihlee\\anaconda3\\envs\\testAI\\lib\\site-packages\\numpy\\.libs\\libopenblas.el2c6ple4zyw3eceviv3oxxgrn2nrfm2.gfortran-win_amd64.dll\n",
      "C:\\Users\\ihlee\\anaconda3\\envs\\testAI\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of plotting learning curves\n",
    "from sklearn.datasets import make_classification\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "n_features = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "sgd = SGD(learning_rate=0.001, momentum=0.8)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy')\n",
    "history = model.fit(X,y, epochs=300,batch_size=32,verbose=0,validation_split=0.3)\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Cross Entropy')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "plot_model(model,'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:32:44.296157Z",
     "start_time": "2022-06-24T02:30:23.758029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 361\n",
      "Trainable params: 361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "111/111 - 1s - loss: 10.2295 - accuracy: 0.5797 - val_loss: 0.9114 - val_accuracy: 0.7097\n",
      "Epoch 2/300\n",
      "111/111 - 0s - loss: 2.3561 - accuracy: 0.5054 - val_loss: 0.7766 - val_accuracy: 0.6452\n",
      "Epoch 3/300\n",
      "111/111 - 0s - loss: 1.4436 - accuracy: 0.5091 - val_loss: 0.7184 - val_accuracy: 0.5484\n",
      "Epoch 4/300\n",
      "111/111 - 0s - loss: 0.9440 - accuracy: 0.5779 - val_loss: 0.6704 - val_accuracy: 0.7903\n",
      "Epoch 5/300\n",
      "111/111 - 0s - loss: 0.8905 - accuracy: 0.6196 - val_loss: 0.6393 - val_accuracy: 0.8226\n",
      "Epoch 6/300\n",
      "111/111 - 0s - loss: 0.8639 - accuracy: 0.5851 - val_loss: 0.6339 - val_accuracy: 0.8065\n",
      "Epoch 7/300\n",
      "111/111 - 0s - loss: 0.8419 - accuracy: 0.6069 - val_loss: 0.6070 - val_accuracy: 0.8387\n",
      "Epoch 8/300\n",
      "111/111 - 0s - loss: 0.7499 - accuracy: 0.6033 - val_loss: 0.5691 - val_accuracy: 0.8387\n",
      "Epoch 9/300\n",
      "111/111 - 0s - loss: 0.7121 - accuracy: 0.6069 - val_loss: 0.5546 - val_accuracy: 0.8710\n",
      "Epoch 10/300\n",
      "111/111 - 0s - loss: 0.6765 - accuracy: 0.6232 - val_loss: 0.5510 - val_accuracy: 0.8387\n",
      "Epoch 11/300\n",
      "111/111 - 0s - loss: 0.6570 - accuracy: 0.6304 - val_loss: 0.5426 - val_accuracy: 0.8387\n",
      "Epoch 12/300\n",
      "111/111 - 0s - loss: 0.6467 - accuracy: 0.6395 - val_loss: 0.5256 - val_accuracy: 0.8548\n",
      "Epoch 13/300\n",
      "111/111 - 0s - loss: 0.6490 - accuracy: 0.6359 - val_loss: 0.5275 - val_accuracy: 0.8548\n",
      "Epoch 14/300\n",
      "111/111 - 0s - loss: 0.6473 - accuracy: 0.6359 - val_loss: 0.5270 - val_accuracy: 0.8387\n",
      "Epoch 15/300\n",
      "111/111 - 0s - loss: 0.6457 - accuracy: 0.6431 - val_loss: 0.5344 - val_accuracy: 0.8387\n",
      "Epoch 16/300\n",
      "111/111 - 0s - loss: 0.6385 - accuracy: 0.6413 - val_loss: 0.5316 - val_accuracy: 0.8387\n",
      "Epoch 17/300\n",
      "111/111 - 0s - loss: 0.6487 - accuracy: 0.6431 - val_loss: 0.5550 - val_accuracy: 0.8387\n",
      "Epoch 18/300\n",
      "111/111 - 0s - loss: 0.6368 - accuracy: 0.6486 - val_loss: 0.5265 - val_accuracy: 0.8387\n",
      "Epoch 19/300\n",
      "111/111 - 0s - loss: 0.6284 - accuracy: 0.6576 - val_loss: 0.5072 - val_accuracy: 0.8387\n",
      "Epoch 20/300\n",
      "111/111 - 0s - loss: 0.6422 - accuracy: 0.6431 - val_loss: 0.5323 - val_accuracy: 0.8548\n",
      "Epoch 21/300\n",
      "111/111 - 0s - loss: 0.6361 - accuracy: 0.6467 - val_loss: 0.5342 - val_accuracy: 0.8548\n",
      "Epoch 22/300\n",
      "111/111 - 0s - loss: 0.6335 - accuracy: 0.6467 - val_loss: 0.5108 - val_accuracy: 0.8387\n",
      "Epoch 23/300\n",
      "111/111 - 0s - loss: 0.6371 - accuracy: 0.6594 - val_loss: 0.5209 - val_accuracy: 0.8387\n",
      "Epoch 24/300\n",
      "111/111 - 0s - loss: 0.6431 - accuracy: 0.6449 - val_loss: 0.5279 - val_accuracy: 0.8387\n",
      "Epoch 25/300\n",
      "111/111 - 1s - loss: 0.6360 - accuracy: 0.6522 - val_loss: 0.5284 - val_accuracy: 0.8548\n",
      "Epoch 26/300\n",
      "111/111 - 0s - loss: 0.6371 - accuracy: 0.6431 - val_loss: 0.5256 - val_accuracy: 0.8548\n",
      "Epoch 27/300\n",
      "111/111 - 0s - loss: 0.6453 - accuracy: 0.6431 - val_loss: 0.5202 - val_accuracy: 0.8226\n",
      "Epoch 28/300\n",
      "111/111 - 0s - loss: 0.6424 - accuracy: 0.6486 - val_loss: 0.5336 - val_accuracy: 0.8387\n",
      "Epoch 29/300\n",
      "111/111 - 0s - loss: 0.6389 - accuracy: 0.6467 - val_loss: 0.5186 - val_accuracy: 0.8387\n",
      "Epoch 30/300\n",
      "111/111 - 0s - loss: 0.6345 - accuracy: 0.6431 - val_loss: 0.5233 - val_accuracy: 0.8548\n",
      "Epoch 31/300\n",
      "111/111 - 0s - loss: 0.6295 - accuracy: 0.6540 - val_loss: 0.5124 - val_accuracy: 0.8548\n",
      "Epoch 32/300\n",
      "111/111 - 0s - loss: 0.6364 - accuracy: 0.6431 - val_loss: 0.5177 - val_accuracy: 0.8548\n",
      "Epoch 33/300\n",
      "111/111 - 0s - loss: 0.6274 - accuracy: 0.6486 - val_loss: 0.5148 - val_accuracy: 0.8387\n",
      "Epoch 34/300\n",
      "111/111 - 0s - loss: 0.6315 - accuracy: 0.6504 - val_loss: 0.5109 - val_accuracy: 0.8548\n",
      "Epoch 35/300\n",
      "111/111 - 0s - loss: 0.6314 - accuracy: 0.6540 - val_loss: 0.5145 - val_accuracy: 0.8548\n",
      "Epoch 36/300\n",
      "111/111 - 0s - loss: 0.6354 - accuracy: 0.6431 - val_loss: 0.4891 - val_accuracy: 0.8387\n",
      "Epoch 37/300\n",
      "111/111 - 0s - loss: 0.6326 - accuracy: 0.6413 - val_loss: 0.5098 - val_accuracy: 0.8387\n",
      "Epoch 38/300\n",
      "111/111 - 0s - loss: 0.6319 - accuracy: 0.6431 - val_loss: 0.5113 - val_accuracy: 0.8387\n",
      "Epoch 39/300\n",
      "111/111 - 0s - loss: 0.6415 - accuracy: 0.6413 - val_loss: 0.5017 - val_accuracy: 0.8548\n",
      "Epoch 40/300\n",
      "111/111 - 0s - loss: 0.6249 - accuracy: 0.6467 - val_loss: 0.5042 - val_accuracy: 0.8387\n",
      "Epoch 41/300\n",
      "111/111 - 0s - loss: 0.6442 - accuracy: 0.6467 - val_loss: 0.5105 - val_accuracy: 0.8226\n",
      "Epoch 42/300\n",
      "111/111 - 0s - loss: 0.6233 - accuracy: 0.6504 - val_loss: 0.5071 - val_accuracy: 0.8226\n",
      "Epoch 43/300\n",
      "111/111 - 0s - loss: 0.6400 - accuracy: 0.6522 - val_loss: 0.5163 - val_accuracy: 0.8065\n",
      "Epoch 44/300\n",
      "111/111 - 0s - loss: 0.6372 - accuracy: 0.6486 - val_loss: 0.5218 - val_accuracy: 0.8548\n",
      "Epoch 45/300\n",
      "111/111 - 1s - loss: 0.6326 - accuracy: 0.6449 - val_loss: 0.5147 - val_accuracy: 0.8387\n",
      "Epoch 46/300\n",
      "111/111 - 0s - loss: 0.6329 - accuracy: 0.6449 - val_loss: 0.5139 - val_accuracy: 0.8548\n",
      "Epoch 47/300\n",
      "111/111 - 0s - loss: 0.6246 - accuracy: 0.6558 - val_loss: 0.4934 - val_accuracy: 0.8226\n",
      "Epoch 48/300\n",
      "111/111 - 0s - loss: 0.6339 - accuracy: 0.6431 - val_loss: 0.4843 - val_accuracy: 0.8548\n",
      "Epoch 49/300\n",
      "111/111 - 0s - loss: 0.6269 - accuracy: 0.6431 - val_loss: 0.4951 - val_accuracy: 0.8387\n",
      "Epoch 50/300\n",
      "111/111 - 0s - loss: 0.6307 - accuracy: 0.6540 - val_loss: 0.5140 - val_accuracy: 0.8548\n",
      "Epoch 51/300\n",
      "111/111 - 0s - loss: 0.6313 - accuracy: 0.6467 - val_loss: 0.5115 - val_accuracy: 0.8387\n",
      "Epoch 52/300\n",
      "111/111 - 0s - loss: 0.6316 - accuracy: 0.6522 - val_loss: 0.4789 - val_accuracy: 0.8387\n",
      "Epoch 53/300\n",
      "111/111 - 0s - loss: 0.6375 - accuracy: 0.6377 - val_loss: 0.5082 - val_accuracy: 0.8387\n",
      "Epoch 54/300\n",
      "111/111 - 0s - loss: 0.6387 - accuracy: 0.6431 - val_loss: 0.5042 - val_accuracy: 0.8387\n",
      "Epoch 55/300\n",
      "111/111 - 0s - loss: 0.6329 - accuracy: 0.6449 - val_loss: 0.5041 - val_accuracy: 0.8226\n",
      "Epoch 56/300\n",
      "111/111 - 0s - loss: 0.6279 - accuracy: 0.6467 - val_loss: 0.4703 - val_accuracy: 0.8548\n",
      "Epoch 57/300\n",
      "111/111 - 0s - loss: 0.6438 - accuracy: 0.6467 - val_loss: 0.5038 - val_accuracy: 0.8387\n",
      "Epoch 58/300\n",
      "111/111 - 0s - loss: 0.6432 - accuracy: 0.6395 - val_loss: 0.5002 - val_accuracy: 0.8226\n",
      "Epoch 59/300\n",
      "111/111 - 0s - loss: 0.6305 - accuracy: 0.6449 - val_loss: 0.5088 - val_accuracy: 0.8226\n",
      "Epoch 60/300\n",
      "111/111 - 0s - loss: 0.6399 - accuracy: 0.6431 - val_loss: 0.5107 - val_accuracy: 0.8065\n",
      "Epoch 61/300\n",
      "111/111 - 0s - loss: 0.6381 - accuracy: 0.6377 - val_loss: 0.4946 - val_accuracy: 0.8226\n",
      "Epoch 62/300\n",
      "111/111 - 0s - loss: 0.6262 - accuracy: 0.6413 - val_loss: 0.4878 - val_accuracy: 0.8548\n",
      "Epoch 63/300\n",
      "111/111 - 0s - loss: 0.6189 - accuracy: 0.6486 - val_loss: 0.4832 - val_accuracy: 0.8548\n",
      "Epoch 64/300\n",
      "111/111 - 0s - loss: 0.6256 - accuracy: 0.6540 - val_loss: 0.4968 - val_accuracy: 0.8871\n",
      "Epoch 65/300\n",
      "111/111 - 0s - loss: 0.6412 - accuracy: 0.6540 - val_loss: 0.5185 - val_accuracy: 0.8548\n",
      "Epoch 66/300\n",
      "111/111 - 0s - loss: 0.6217 - accuracy: 0.6649 - val_loss: 0.5088 - val_accuracy: 0.8548\n",
      "Epoch 67/300\n",
      "111/111 - 0s - loss: 0.6248 - accuracy: 0.6576 - val_loss: 0.5083 - val_accuracy: 0.8226\n",
      "Epoch 68/300\n",
      "111/111 - 0s - loss: 0.6026 - accuracy: 0.6739 - val_loss: 0.4794 - val_accuracy: 0.8548\n",
      "Epoch 69/300\n",
      "111/111 - 0s - loss: 0.6291 - accuracy: 0.6576 - val_loss: 0.4746 - val_accuracy: 0.8548\n",
      "Epoch 70/300\n",
      "111/111 - 0s - loss: 0.6363 - accuracy: 0.6558 - val_loss: 0.4886 - val_accuracy: 0.8387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/300\n",
      "111/111 - 0s - loss: 0.6155 - accuracy: 0.6594 - val_loss: 0.4704 - val_accuracy: 0.8387\n",
      "Epoch 72/300\n",
      "111/111 - 0s - loss: 0.6213 - accuracy: 0.6504 - val_loss: 0.4624 - val_accuracy: 0.8548\n",
      "Epoch 73/300\n",
      "111/111 - 0s - loss: 0.6039 - accuracy: 0.6920 - val_loss: 0.5091 - val_accuracy: 0.8226\n",
      "Epoch 74/300\n",
      "111/111 - 0s - loss: 0.6094 - accuracy: 0.6793 - val_loss: 0.4655 - val_accuracy: 0.8548\n",
      "Epoch 75/300\n",
      "111/111 - 0s - loss: 0.6254 - accuracy: 0.6558 - val_loss: 0.4825 - val_accuracy: 0.8548\n",
      "Epoch 76/300\n",
      "111/111 - 0s - loss: 0.6138 - accuracy: 0.6685 - val_loss: 0.4580 - val_accuracy: 0.8387\n",
      "Epoch 77/300\n",
      "111/111 - 0s - loss: 0.6264 - accuracy: 0.6558 - val_loss: 0.4780 - val_accuracy: 0.8387\n",
      "Epoch 78/300\n",
      "111/111 - 0s - loss: 0.6022 - accuracy: 0.6739 - val_loss: 0.4720 - val_accuracy: 0.8226\n",
      "Epoch 79/300\n",
      "111/111 - 0s - loss: 0.6177 - accuracy: 0.6594 - val_loss: 0.4591 - val_accuracy: 0.8548\n",
      "Epoch 80/300\n",
      "111/111 - 0s - loss: 0.6114 - accuracy: 0.6558 - val_loss: 0.4641 - val_accuracy: 0.8387\n",
      "Epoch 81/300\n",
      "111/111 - 0s - loss: 0.6167 - accuracy: 0.6775 - val_loss: 0.4750 - val_accuracy: 0.8387\n",
      "Epoch 82/300\n",
      "111/111 - 0s - loss: 0.6208 - accuracy: 0.6812 - val_loss: 0.5065 - val_accuracy: 0.8387\n",
      "Epoch 83/300\n",
      "111/111 - 0s - loss: 0.6260 - accuracy: 0.6667 - val_loss: 0.4906 - val_accuracy: 0.8226\n",
      "Epoch 84/300\n",
      "111/111 - 0s - loss: 0.6130 - accuracy: 0.6649 - val_loss: 0.4848 - val_accuracy: 0.8387\n",
      "Epoch 85/300\n",
      "111/111 - 0s - loss: 0.6104 - accuracy: 0.6667 - val_loss: 0.4875 - val_accuracy: 0.8387\n",
      "Epoch 86/300\n",
      "111/111 - 0s - loss: 0.6174 - accuracy: 0.6612 - val_loss: 0.4865 - val_accuracy: 0.8226\n",
      "Epoch 87/300\n",
      "111/111 - 0s - loss: 0.6055 - accuracy: 0.6594 - val_loss: 0.4639 - val_accuracy: 0.8387\n",
      "Epoch 88/300\n",
      "111/111 - 0s - loss: 0.6060 - accuracy: 0.6721 - val_loss: 0.4663 - val_accuracy: 0.8387\n",
      "Epoch 89/300\n",
      "111/111 - 0s - loss: 0.6154 - accuracy: 0.6558 - val_loss: 0.4337 - val_accuracy: 0.8387\n",
      "Epoch 90/300\n",
      "111/111 - 0s - loss: 0.6135 - accuracy: 0.6721 - val_loss: 0.4875 - val_accuracy: 0.8387\n",
      "Epoch 91/300\n",
      "111/111 - 0s - loss: 0.5978 - accuracy: 0.6630 - val_loss: 0.4526 - val_accuracy: 0.8387\n",
      "Epoch 92/300\n",
      "111/111 - 0s - loss: 0.6057 - accuracy: 0.6649 - val_loss: 0.4696 - val_accuracy: 0.8226\n",
      "Epoch 93/300\n",
      "111/111 - 0s - loss: 0.5939 - accuracy: 0.6757 - val_loss: 0.4784 - val_accuracy: 0.8387\n",
      "Epoch 94/300\n",
      "111/111 - 0s - loss: 0.6096 - accuracy: 0.6793 - val_loss: 0.4849 - val_accuracy: 0.8548\n",
      "Epoch 95/300\n",
      "111/111 - 0s - loss: 0.6004 - accuracy: 0.6848 - val_loss: 0.4757 - val_accuracy: 0.8226\n",
      "Epoch 96/300\n",
      "111/111 - 0s - loss: 0.6142 - accuracy: 0.6594 - val_loss: 0.4695 - val_accuracy: 0.8387\n",
      "Epoch 97/300\n",
      "111/111 - 0s - loss: 0.5999 - accuracy: 0.6703 - val_loss: 0.4491 - val_accuracy: 0.8548\n",
      "Epoch 98/300\n",
      "111/111 - 0s - loss: 0.5914 - accuracy: 0.6902 - val_loss: 0.4458 - val_accuracy: 0.8226\n",
      "Epoch 99/300\n",
      "111/111 - 0s - loss: 0.6014 - accuracy: 0.6757 - val_loss: 0.4642 - val_accuracy: 0.8710\n",
      "Epoch 100/300\n",
      "111/111 - 0s - loss: 0.6023 - accuracy: 0.6866 - val_loss: 0.4500 - val_accuracy: 0.8548\n",
      "Epoch 101/300\n",
      "111/111 - 0s - loss: 0.5957 - accuracy: 0.6775 - val_loss: 0.4533 - val_accuracy: 0.8710\n",
      "Epoch 102/300\n",
      "111/111 - 0s - loss: 0.6169 - accuracy: 0.6649 - val_loss: 0.4289 - val_accuracy: 0.8387\n",
      "Epoch 103/300\n",
      "111/111 - 0s - loss: 0.6125 - accuracy: 0.6612 - val_loss: 0.4422 - val_accuracy: 0.8548\n",
      "Epoch 104/300\n",
      "111/111 - 0s - loss: 0.6048 - accuracy: 0.6630 - val_loss: 0.4627 - val_accuracy: 0.8226\n",
      "Epoch 105/300\n",
      "111/111 - 0s - loss: 0.6002 - accuracy: 0.6703 - val_loss: 0.4382 - val_accuracy: 0.8387\n",
      "Epoch 106/300\n",
      "111/111 - 0s - loss: 0.5983 - accuracy: 0.6884 - val_loss: 0.4410 - val_accuracy: 0.8387\n",
      "Epoch 107/300\n",
      "111/111 - 0s - loss: 0.5996 - accuracy: 0.6775 - val_loss: 0.4377 - val_accuracy: 0.8548\n",
      "Epoch 108/300\n",
      "111/111 - 0s - loss: 0.6020 - accuracy: 0.6522 - val_loss: 0.4401 - val_accuracy: 0.8226\n",
      "Epoch 109/300\n",
      "111/111 - 0s - loss: 0.5835 - accuracy: 0.6902 - val_loss: 0.4519 - val_accuracy: 0.8387\n",
      "Epoch 110/300\n",
      "111/111 - 1s - loss: 0.6117 - accuracy: 0.6594 - val_loss: 0.4854 - val_accuracy: 0.8387\n",
      "Epoch 111/300\n",
      "111/111 - 0s - loss: 0.6021 - accuracy: 0.6848 - val_loss: 0.4720 - val_accuracy: 0.8387\n",
      "Epoch 112/300\n",
      "111/111 - 0s - loss: 0.5930 - accuracy: 0.6884 - val_loss: 0.4509 - val_accuracy: 0.8710\n",
      "Epoch 113/300\n",
      "111/111 - 0s - loss: 0.6048 - accuracy: 0.6685 - val_loss: 0.4691 - val_accuracy: 0.8226\n",
      "Epoch 114/300\n",
      "111/111 - 0s - loss: 0.6171 - accuracy: 0.6630 - val_loss: 0.4722 - val_accuracy: 0.8387\n",
      "Epoch 115/300\n",
      "111/111 - 0s - loss: 0.5947 - accuracy: 0.6812 - val_loss: 0.4197 - val_accuracy: 0.8387\n",
      "Epoch 116/300\n",
      "111/111 - 0s - loss: 0.6073 - accuracy: 0.6667 - val_loss: 0.4263 - val_accuracy: 0.8548\n",
      "Epoch 117/300\n",
      "111/111 - 0s - loss: 0.6146 - accuracy: 0.6522 - val_loss: 0.4395 - val_accuracy: 0.8226\n",
      "Epoch 118/300\n",
      "111/111 - 0s - loss: 0.5964 - accuracy: 0.6866 - val_loss: 0.4521 - val_accuracy: 0.8548\n",
      "Epoch 119/300\n",
      "111/111 - 0s - loss: 0.6084 - accuracy: 0.6685 - val_loss: 0.4544 - val_accuracy: 0.8387\n",
      "Epoch 120/300\n",
      "111/111 - 0s - loss: 0.6031 - accuracy: 0.6830 - val_loss: 0.4621 - val_accuracy: 0.9032\n",
      "Epoch 121/300\n",
      "111/111 - 0s - loss: 0.5887 - accuracy: 0.6739 - val_loss: 0.4291 - val_accuracy: 0.8548\n",
      "Epoch 122/300\n",
      "111/111 - 0s - loss: 0.5995 - accuracy: 0.6721 - val_loss: 0.4308 - val_accuracy: 0.8226\n",
      "Epoch 123/300\n",
      "111/111 - 0s - loss: 0.5966 - accuracy: 0.6775 - val_loss: 0.4624 - val_accuracy: 0.8226\n",
      "Epoch 124/300\n",
      "111/111 - 0s - loss: 0.5895 - accuracy: 0.6884 - val_loss: 0.4575 - val_accuracy: 0.8548\n",
      "Epoch 125/300\n",
      "111/111 - 0s - loss: 0.5956 - accuracy: 0.6667 - val_loss: 0.4538 - val_accuracy: 0.8387\n",
      "Epoch 126/300\n",
      "111/111 - 0s - loss: 0.5979 - accuracy: 0.6667 - val_loss: 0.4459 - val_accuracy: 0.8226\n",
      "Epoch 127/300\n",
      "111/111 - 0s - loss: 0.5915 - accuracy: 0.6739 - val_loss: 0.4483 - val_accuracy: 0.8548\n",
      "Epoch 128/300\n",
      "111/111 - 0s - loss: 0.5781 - accuracy: 0.6920 - val_loss: 0.4319 - val_accuracy: 0.8710\n",
      "Epoch 129/300\n",
      "111/111 - 0s - loss: 0.5818 - accuracy: 0.6902 - val_loss: 0.4401 - val_accuracy: 0.9032\n",
      "Epoch 130/300\n",
      "111/111 - 0s - loss: 0.6070 - accuracy: 0.6667 - val_loss: 0.4526 - val_accuracy: 0.8387\n",
      "Epoch 131/300\n",
      "111/111 - 0s - loss: 0.5870 - accuracy: 0.6812 - val_loss: 0.4212 - val_accuracy: 0.8548\n",
      "Epoch 132/300\n",
      "111/111 - 0s - loss: 0.5884 - accuracy: 0.6703 - val_loss: 0.4601 - val_accuracy: 0.8387\n",
      "Epoch 133/300\n",
      "111/111 - 0s - loss: 0.5878 - accuracy: 0.6830 - val_loss: 0.4576 - val_accuracy: 0.8387\n",
      "Epoch 134/300\n",
      "111/111 - 0s - loss: 0.5798 - accuracy: 0.6830 - val_loss: 0.4287 - val_accuracy: 0.8226\n",
      "Epoch 135/300\n",
      "111/111 - 0s - loss: 0.5919 - accuracy: 0.6667 - val_loss: 0.4302 - val_accuracy: 0.8226\n",
      "Epoch 136/300\n",
      "111/111 - 1s - loss: 0.5823 - accuracy: 0.6757 - val_loss: 0.4157 - val_accuracy: 0.8387\n",
      "Epoch 137/300\n",
      "111/111 - 0s - loss: 0.5923 - accuracy: 0.6612 - val_loss: 0.4281 - val_accuracy: 0.8226\n",
      "Epoch 138/300\n",
      "111/111 - 0s - loss: 0.5899 - accuracy: 0.6685 - val_loss: 0.4521 - val_accuracy: 0.8226\n",
      "Epoch 139/300\n",
      "111/111 - 0s - loss: 0.5904 - accuracy: 0.6812 - val_loss: 0.4574 - val_accuracy: 0.8548\n",
      "Epoch 140/300\n",
      "111/111 - 0s - loss: 0.5865 - accuracy: 0.6793 - val_loss: 0.4885 - val_accuracy: 0.8226\n",
      "Epoch 141/300\n",
      "111/111 - 0s - loss: 0.5957 - accuracy: 0.6594 - val_loss: 0.4465 - val_accuracy: 0.8387\n",
      "Epoch 142/300\n",
      "111/111 - 0s - loss: 0.5820 - accuracy: 0.6703 - val_loss: 0.4322 - val_accuracy: 0.8387\n",
      "Epoch 143/300\n",
      "111/111 - 0s - loss: 0.5789 - accuracy: 0.6848 - val_loss: 0.4314 - val_accuracy: 0.8548\n",
      "Epoch 144/300\n",
      "111/111 - 0s - loss: 0.5854 - accuracy: 0.6757 - val_loss: 0.4441 - val_accuracy: 0.8226\n",
      "Epoch 145/300\n",
      "111/111 - 0s - loss: 0.5806 - accuracy: 0.6685 - val_loss: 0.4275 - val_accuracy: 0.8226\n",
      "Epoch 146/300\n",
      "111/111 - 0s - loss: 0.5919 - accuracy: 0.6739 - val_loss: 0.4417 - val_accuracy: 0.8548\n",
      "Epoch 147/300\n",
      "111/111 - 0s - loss: 0.5845 - accuracy: 0.6848 - val_loss: 0.4332 - val_accuracy: 0.8226\n",
      "Epoch 148/300\n",
      "111/111 - 0s - loss: 0.5870 - accuracy: 0.6757 - val_loss: 0.4247 - val_accuracy: 0.8226\n",
      "Epoch 149/300\n",
      "111/111 - 0s - loss: 0.5963 - accuracy: 0.6703 - val_loss: 0.4640 - val_accuracy: 0.8226\n",
      "Epoch 150/300\n",
      "111/111 - 0s - loss: 0.5867 - accuracy: 0.6793 - val_loss: 0.4198 - val_accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/300\n",
      "111/111 - 0s - loss: 0.5816 - accuracy: 0.6830 - val_loss: 0.4404 - val_accuracy: 0.8387\n",
      "Epoch 152/300\n",
      "111/111 - 0s - loss: 0.5747 - accuracy: 0.6793 - val_loss: 0.4285 - val_accuracy: 0.8548\n",
      "Epoch 153/300\n",
      "111/111 - 0s - loss: 0.5890 - accuracy: 0.6793 - val_loss: 0.4370 - val_accuracy: 0.8226\n",
      "Epoch 154/300\n",
      "111/111 - 0s - loss: 0.5764 - accuracy: 0.6848 - val_loss: 0.4338 - val_accuracy: 0.8710\n",
      "Epoch 155/300\n",
      "111/111 - 0s - loss: 0.6073 - accuracy: 0.6649 - val_loss: 0.4326 - val_accuracy: 0.8387\n",
      "Epoch 156/300\n",
      "111/111 - 0s - loss: 0.5871 - accuracy: 0.6866 - val_loss: 0.4678 - val_accuracy: 0.8226\n",
      "Epoch 157/300\n",
      "111/111 - 0s - loss: 0.5835 - accuracy: 0.6830 - val_loss: 0.4300 - val_accuracy: 0.8387\n",
      "Epoch 158/300\n",
      "111/111 - 0s - loss: 0.5847 - accuracy: 0.6812 - val_loss: 0.4227 - val_accuracy: 0.8548\n",
      "Epoch 159/300\n",
      "111/111 - 0s - loss: 0.5596 - accuracy: 0.6830 - val_loss: 0.4410 - val_accuracy: 0.8387\n",
      "Epoch 160/300\n",
      "111/111 - 1s - loss: 0.5729 - accuracy: 0.6848 - val_loss: 0.4549 - val_accuracy: 0.8226\n",
      "Epoch 161/300\n",
      "111/111 - 0s - loss: 0.5753 - accuracy: 0.6812 - val_loss: 0.4479 - val_accuracy: 0.8548\n",
      "Epoch 162/300\n",
      "111/111 - 1s - loss: 0.5727 - accuracy: 0.6866 - val_loss: 0.4501 - val_accuracy: 0.8226\n",
      "Epoch 163/300\n",
      "111/111 - 0s - loss: 0.5826 - accuracy: 0.6703 - val_loss: 0.4217 - val_accuracy: 0.8226\n",
      "Epoch 164/300\n",
      "111/111 - 0s - loss: 0.5707 - accuracy: 0.6920 - val_loss: 0.4530 - val_accuracy: 0.8710\n",
      "Epoch 165/300\n",
      "111/111 - 0s - loss: 0.5923 - accuracy: 0.6667 - val_loss: 0.4416 - val_accuracy: 0.8226\n",
      "Epoch 166/300\n",
      "111/111 - 0s - loss: 0.5798 - accuracy: 0.6902 - val_loss: 0.4370 - val_accuracy: 0.8387\n",
      "Epoch 167/300\n",
      "111/111 - 0s - loss: 0.5830 - accuracy: 0.6775 - val_loss: 0.4482 - val_accuracy: 0.8710\n",
      "Epoch 168/300\n",
      "111/111 - 0s - loss: 0.5893 - accuracy: 0.6757 - val_loss: 0.4304 - val_accuracy: 0.8226\n",
      "Epoch 169/300\n",
      "111/111 - 0s - loss: 0.5725 - accuracy: 0.6884 - val_loss: 0.4446 - val_accuracy: 0.8226\n",
      "Epoch 170/300\n",
      "111/111 - 1s - loss: 0.5694 - accuracy: 0.6775 - val_loss: 0.4472 - val_accuracy: 0.8226\n",
      "Epoch 171/300\n",
      "111/111 - 0s - loss: 0.5877 - accuracy: 0.6703 - val_loss: 0.4287 - val_accuracy: 0.8226\n",
      "Epoch 172/300\n",
      "111/111 - 0s - loss: 0.5701 - accuracy: 0.6848 - val_loss: 0.4348 - val_accuracy: 0.8387\n",
      "Epoch 173/300\n",
      "111/111 - 0s - loss: 0.5846 - accuracy: 0.6775 - val_loss: 0.4241 - val_accuracy: 0.8387\n",
      "Epoch 174/300\n",
      "111/111 - 0s - loss: 0.5890 - accuracy: 0.6594 - val_loss: 0.4419 - val_accuracy: 0.8387\n",
      "Epoch 175/300\n",
      "111/111 - 0s - loss: 0.5636 - accuracy: 0.6884 - val_loss: 0.4137 - val_accuracy: 0.8548\n",
      "Epoch 176/300\n",
      "111/111 - 0s - loss: 0.5737 - accuracy: 0.6775 - val_loss: 0.4143 - val_accuracy: 0.8387\n",
      "Epoch 177/300\n",
      "111/111 - 0s - loss: 0.5734 - accuracy: 0.6848 - val_loss: 0.4470 - val_accuracy: 0.8226\n",
      "Epoch 178/300\n",
      "111/111 - 0s - loss: 0.5651 - accuracy: 0.6757 - val_loss: 0.4236 - val_accuracy: 0.8226\n",
      "Epoch 179/300\n",
      "111/111 - 0s - loss: 0.5795 - accuracy: 0.6703 - val_loss: 0.4437 - val_accuracy: 0.8226\n",
      "Epoch 180/300\n",
      "111/111 - 0s - loss: 0.5794 - accuracy: 0.6793 - val_loss: 0.4076 - val_accuracy: 0.8387\n",
      "Epoch 181/300\n",
      "111/111 - 0s - loss: 0.5636 - accuracy: 0.6775 - val_loss: 0.4141 - val_accuracy: 0.8387\n",
      "Epoch 182/300\n",
      "111/111 - 0s - loss: 0.5699 - accuracy: 0.6866 - val_loss: 0.4171 - val_accuracy: 0.8871\n",
      "Epoch 183/300\n",
      "111/111 - 0s - loss: 0.5697 - accuracy: 0.6884 - val_loss: 0.4272 - val_accuracy: 0.8871\n",
      "Epoch 184/300\n",
      "111/111 - 0s - loss: 0.5956 - accuracy: 0.6739 - val_loss: 0.4031 - val_accuracy: 0.8548\n",
      "Epoch 185/300\n",
      "111/111 - 0s - loss: 0.5748 - accuracy: 0.6830 - val_loss: 0.3984 - val_accuracy: 0.8387\n",
      "Epoch 186/300\n",
      "111/111 - 0s - loss: 0.5711 - accuracy: 0.6812 - val_loss: 0.4440 - val_accuracy: 0.8226\n",
      "Epoch 187/300\n",
      "111/111 - 0s - loss: 0.5598 - accuracy: 0.6830 - val_loss: 0.3979 - val_accuracy: 0.8226\n",
      "Epoch 188/300\n",
      "111/111 - 0s - loss: 0.5753 - accuracy: 0.6793 - val_loss: 0.4411 - val_accuracy: 0.8226\n",
      "Epoch 189/300\n",
      "111/111 - 0s - loss: 0.5730 - accuracy: 0.6757 - val_loss: 0.4169 - val_accuracy: 0.8387\n",
      "Epoch 190/300\n",
      "111/111 - 0s - loss: 0.5739 - accuracy: 0.6812 - val_loss: 0.4415 - val_accuracy: 0.8226\n",
      "Epoch 191/300\n",
      "111/111 - 0s - loss: 0.5830 - accuracy: 0.6793 - val_loss: 0.4315 - val_accuracy: 0.8548\n",
      "Epoch 192/300\n",
      "111/111 - 0s - loss: 0.5503 - accuracy: 0.6830 - val_loss: 0.4081 - val_accuracy: 0.8387\n",
      "Epoch 193/300\n",
      "111/111 - 0s - loss: 0.5736 - accuracy: 0.6812 - val_loss: 0.4410 - val_accuracy: 0.8710\n",
      "Epoch 194/300\n",
      "111/111 - 0s - loss: 0.5776 - accuracy: 0.6685 - val_loss: 0.4333 - val_accuracy: 0.8710\n",
      "Epoch 195/300\n",
      "111/111 - 0s - loss: 0.5671 - accuracy: 0.6793 - val_loss: 0.4409 - val_accuracy: 0.8387\n",
      "Epoch 196/300\n",
      "111/111 - 0s - loss: 0.5645 - accuracy: 0.6920 - val_loss: 0.4048 - val_accuracy: 0.8387\n",
      "Epoch 197/300\n",
      "111/111 - 0s - loss: 0.5700 - accuracy: 0.6902 - val_loss: 0.4519 - val_accuracy: 0.8226\n",
      "Epoch 198/300\n",
      "111/111 - 0s - loss: 0.5673 - accuracy: 0.6812 - val_loss: 0.4262 - val_accuracy: 0.8387\n",
      "Epoch 199/300\n",
      "111/111 - 0s - loss: 0.5697 - accuracy: 0.6830 - val_loss: 0.4141 - val_accuracy: 0.8387\n",
      "Epoch 200/300\n",
      "111/111 - 0s - loss: 0.5624 - accuracy: 0.6812 - val_loss: 0.4148 - val_accuracy: 0.8548\n",
      "Epoch 201/300\n",
      "111/111 - 1s - loss: 0.5724 - accuracy: 0.6739 - val_loss: 0.4531 - val_accuracy: 0.8548\n",
      "Epoch 202/300\n",
      "111/111 - 0s - loss: 0.5627 - accuracy: 0.6739 - val_loss: 0.4112 - val_accuracy: 0.8387\n",
      "Epoch 203/300\n",
      "111/111 - 0s - loss: 0.5734 - accuracy: 0.6757 - val_loss: 0.4374 - val_accuracy: 0.8548\n",
      "Epoch 204/300\n",
      "111/111 - 0s - loss: 0.5488 - accuracy: 0.7029 - val_loss: 0.4198 - val_accuracy: 0.9032\n",
      "Epoch 205/300\n",
      "111/111 - 0s - loss: 0.5727 - accuracy: 0.6793 - val_loss: 0.4450 - val_accuracy: 0.8548\n",
      "Epoch 206/300\n",
      "111/111 - 0s - loss: 0.5774 - accuracy: 0.6739 - val_loss: 0.3891 - val_accuracy: 0.8226\n",
      "Epoch 207/300\n",
      "111/111 - 0s - loss: 0.5820 - accuracy: 0.6757 - val_loss: 0.4317 - val_accuracy: 0.8226\n",
      "Epoch 208/300\n",
      "111/111 - 0s - loss: 0.5767 - accuracy: 0.6739 - val_loss: 0.4109 - val_accuracy: 0.8710\n",
      "Epoch 209/300\n",
      "111/111 - 0s - loss: 0.5596 - accuracy: 0.6812 - val_loss: 0.4471 - val_accuracy: 0.8226\n",
      "Epoch 210/300\n",
      "111/111 - 0s - loss: 0.5774 - accuracy: 0.6793 - val_loss: 0.4389 - val_accuracy: 0.8226\n",
      "Epoch 211/300\n",
      "111/111 - 0s - loss: 0.5649 - accuracy: 0.6920 - val_loss: 0.4201 - val_accuracy: 0.8710\n",
      "Epoch 212/300\n",
      "111/111 - 0s - loss: 0.5733 - accuracy: 0.6920 - val_loss: 0.4056 - val_accuracy: 0.8548\n",
      "Epoch 213/300\n",
      "111/111 - 0s - loss: 0.5603 - accuracy: 0.6739 - val_loss: 0.4188 - val_accuracy: 0.8710\n",
      "Epoch 214/300\n",
      "111/111 - 0s - loss: 0.5631 - accuracy: 0.6757 - val_loss: 0.4208 - val_accuracy: 0.8387\n",
      "Epoch 215/300\n",
      "111/111 - 0s - loss: 0.5501 - accuracy: 0.6902 - val_loss: 0.4381 - val_accuracy: 0.8387\n",
      "Epoch 216/300\n",
      "111/111 - 0s - loss: 0.5747 - accuracy: 0.6775 - val_loss: 0.4146 - val_accuracy: 0.8387\n",
      "Epoch 217/300\n",
      "111/111 - 0s - loss: 0.5706 - accuracy: 0.6775 - val_loss: 0.4457 - val_accuracy: 0.8226\n",
      "Epoch 218/300\n",
      "111/111 - 0s - loss: 0.5605 - accuracy: 0.6920 - val_loss: 0.4484 - val_accuracy: 0.8710\n",
      "Epoch 219/300\n",
      "111/111 - 0s - loss: 0.5640 - accuracy: 0.6757 - val_loss: 0.3973 - val_accuracy: 0.8548\n",
      "Epoch 220/300\n",
      "111/111 - 0s - loss: 0.5644 - accuracy: 0.6703 - val_loss: 0.4262 - val_accuracy: 0.8226\n",
      "Epoch 221/300\n",
      "111/111 - 0s - loss: 0.5689 - accuracy: 0.6884 - val_loss: 0.4537 - val_accuracy: 0.8548\n",
      "Epoch 222/300\n",
      "111/111 - 0s - loss: 0.5586 - accuracy: 0.6884 - val_loss: 0.4078 - val_accuracy: 0.8548\n",
      "Epoch 223/300\n",
      "111/111 - 0s - loss: 0.5602 - accuracy: 0.6902 - val_loss: 0.4265 - val_accuracy: 0.8548\n",
      "Epoch 224/300\n",
      "111/111 - 0s - loss: 0.5628 - accuracy: 0.6884 - val_loss: 0.4382 - val_accuracy: 0.8226\n",
      "Epoch 225/300\n",
      "111/111 - 0s - loss: 0.5661 - accuracy: 0.6812 - val_loss: 0.4359 - val_accuracy: 0.8387\n",
      "Epoch 226/300\n",
      "111/111 - 0s - loss: 0.5591 - accuracy: 0.6848 - val_loss: 0.4025 - val_accuracy: 0.8710\n",
      "Epoch 227/300\n",
      "111/111 - 0s - loss: 0.5642 - accuracy: 0.6775 - val_loss: 0.4208 - val_accuracy: 0.8548\n",
      "Epoch 228/300\n",
      "111/111 - 0s - loss: 0.5828 - accuracy: 0.6667 - val_loss: 0.4493 - val_accuracy: 0.8226\n",
      "Epoch 229/300\n",
      "111/111 - 0s - loss: 0.5707 - accuracy: 0.6902 - val_loss: 0.4633 - val_accuracy: 0.8387\n",
      "Epoch 230/300\n",
      "111/111 - 0s - loss: 0.5632 - accuracy: 0.6902 - val_loss: 0.4406 - val_accuracy: 0.8387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/300\n",
      "111/111 - 0s - loss: 0.5547 - accuracy: 0.6866 - val_loss: 0.4490 - val_accuracy: 0.8710\n",
      "Epoch 232/300\n",
      "111/111 - 0s - loss: 0.5592 - accuracy: 0.6884 - val_loss: 0.4249 - val_accuracy: 0.8710\n",
      "Epoch 233/300\n",
      "111/111 - 0s - loss: 0.5636 - accuracy: 0.6866 - val_loss: 0.4306 - val_accuracy: 0.8387\n",
      "Epoch 234/300\n",
      "111/111 - 0s - loss: 0.5788 - accuracy: 0.6721 - val_loss: 0.4181 - val_accuracy: 0.8387\n",
      "Epoch 235/300\n",
      "111/111 - 0s - loss: 0.5659 - accuracy: 0.6902 - val_loss: 0.4327 - val_accuracy: 0.8548\n",
      "Epoch 236/300\n",
      "111/111 - 0s - loss: 0.5489 - accuracy: 0.6793 - val_loss: 0.4026 - val_accuracy: 0.8548\n",
      "Epoch 237/300\n",
      "111/111 - 0s - loss: 0.5650 - accuracy: 0.6884 - val_loss: 0.4296 - val_accuracy: 0.8548\n",
      "Epoch 238/300\n",
      "111/111 - 0s - loss: 0.5585 - accuracy: 0.6812 - val_loss: 0.4468 - val_accuracy: 0.8710\n",
      "Epoch 239/300\n",
      "111/111 - 0s - loss: 0.5512 - accuracy: 0.6793 - val_loss: 0.4000 - val_accuracy: 0.8548\n",
      "Epoch 240/300\n",
      "111/111 - 0s - loss: 0.5862 - accuracy: 0.6739 - val_loss: 0.4319 - val_accuracy: 0.8548\n",
      "Epoch 241/300\n",
      "111/111 - 0s - loss: 0.5493 - accuracy: 0.6902 - val_loss: 0.4603 - val_accuracy: 0.8548\n",
      "Epoch 242/300\n",
      "111/111 - 0s - loss: 0.5700 - accuracy: 0.6884 - val_loss: 0.4144 - val_accuracy: 0.8710\n",
      "Epoch 243/300\n",
      "111/111 - 0s - loss: 0.5513 - accuracy: 0.6957 - val_loss: 0.4296 - val_accuracy: 0.8226\n",
      "Epoch 244/300\n",
      "111/111 - 0s - loss: 0.5670 - accuracy: 0.6757 - val_loss: 0.4175 - val_accuracy: 0.8710\n",
      "Epoch 245/300\n",
      "111/111 - 0s - loss: 0.5617 - accuracy: 0.6667 - val_loss: 0.4100 - val_accuracy: 0.8710\n",
      "Epoch 246/300\n",
      "111/111 - 0s - loss: 0.5639 - accuracy: 0.6848 - val_loss: 0.4238 - val_accuracy: 0.8548\n",
      "Epoch 247/300\n",
      "111/111 - 0s - loss: 0.5774 - accuracy: 0.6775 - val_loss: 0.4220 - val_accuracy: 0.8387\n",
      "Epoch 248/300\n",
      "111/111 - 0s - loss: 0.5574 - accuracy: 0.6866 - val_loss: 0.4390 - val_accuracy: 0.8387\n",
      "Epoch 249/300\n",
      "111/111 - 1s - loss: 0.5779 - accuracy: 0.6757 - val_loss: 0.4233 - val_accuracy: 0.8387\n",
      "Epoch 250/300\n",
      "111/111 - 0s - loss: 0.5604 - accuracy: 0.6957 - val_loss: 0.4055 - val_accuracy: 0.8387\n",
      "Epoch 251/300\n",
      "111/111 - 0s - loss: 0.5608 - accuracy: 0.6848 - val_loss: 0.4388 - val_accuracy: 0.8548\n",
      "Epoch 252/300\n",
      "111/111 - 0s - loss: 0.5690 - accuracy: 0.6848 - val_loss: 0.4069 - val_accuracy: 0.8226\n",
      "Epoch 253/300\n",
      "111/111 - 0s - loss: 0.5550 - accuracy: 0.6938 - val_loss: 0.3935 - val_accuracy: 0.8871\n",
      "Epoch 254/300\n",
      "111/111 - 0s - loss: 0.5535 - accuracy: 0.6902 - val_loss: 0.4110 - val_accuracy: 0.8871\n",
      "Epoch 255/300\n",
      "111/111 - 0s - loss: 0.5485 - accuracy: 0.6830 - val_loss: 0.4195 - val_accuracy: 0.8548\n",
      "Epoch 256/300\n",
      "111/111 - 0s - loss: 0.5659 - accuracy: 0.6848 - val_loss: 0.4079 - val_accuracy: 0.8387\n",
      "Epoch 257/300\n",
      "111/111 - 0s - loss: 0.5458 - accuracy: 0.6920 - val_loss: 0.4045 - val_accuracy: 0.8387\n",
      "Epoch 258/300\n",
      "111/111 - 0s - loss: 0.5494 - accuracy: 0.6920 - val_loss: 0.4578 - val_accuracy: 0.8387\n",
      "Epoch 259/300\n",
      "111/111 - 0s - loss: 0.5460 - accuracy: 0.6993 - val_loss: 0.4558 - val_accuracy: 0.8710\n",
      "Epoch 260/300\n",
      "111/111 - 1s - loss: 0.5783 - accuracy: 0.6848 - val_loss: 0.4258 - val_accuracy: 0.8226\n",
      "Epoch 261/300\n",
      "111/111 - 0s - loss: 0.5398 - accuracy: 0.6848 - val_loss: 0.3857 - val_accuracy: 0.8548\n",
      "Epoch 262/300\n",
      "111/111 - 0s - loss: 0.5634 - accuracy: 0.6812 - val_loss: 0.3906 - val_accuracy: 0.8710\n",
      "Epoch 263/300\n",
      "111/111 - 0s - loss: 0.5672 - accuracy: 0.6830 - val_loss: 0.4118 - val_accuracy: 0.8387\n",
      "Epoch 264/300\n",
      "111/111 - 0s - loss: 0.5543 - accuracy: 0.6848 - val_loss: 0.4363 - val_accuracy: 0.8226\n",
      "Epoch 265/300\n",
      "111/111 - 0s - loss: 0.5681 - accuracy: 0.6775 - val_loss: 0.3904 - val_accuracy: 0.8710\n",
      "Epoch 266/300\n",
      "111/111 - 0s - loss: 0.5421 - accuracy: 0.6957 - val_loss: 0.4256 - val_accuracy: 0.8710\n",
      "Epoch 267/300\n",
      "111/111 - 0s - loss: 0.5571 - accuracy: 0.6920 - val_loss: 0.4329 - val_accuracy: 0.8548\n",
      "Epoch 268/300\n",
      "111/111 - 0s - loss: 0.5595 - accuracy: 0.6848 - val_loss: 0.4188 - val_accuracy: 0.8387\n",
      "Epoch 269/300\n",
      "111/111 - 0s - loss: 0.5728 - accuracy: 0.6920 - val_loss: 0.4327 - val_accuracy: 0.8387\n",
      "Epoch 270/300\n",
      "111/111 - 0s - loss: 0.5609 - accuracy: 0.6739 - val_loss: 0.4288 - val_accuracy: 0.8226\n",
      "Epoch 271/300\n",
      "111/111 - 0s - loss: 0.5375 - accuracy: 0.6975 - val_loss: 0.4307 - val_accuracy: 0.8548\n",
      "Epoch 272/300\n",
      "111/111 - 1s - loss: 0.5621 - accuracy: 0.6793 - val_loss: 0.4333 - val_accuracy: 0.8226\n",
      "Epoch 273/300\n",
      "111/111 - 0s - loss: 0.5453 - accuracy: 0.6975 - val_loss: 0.3951 - val_accuracy: 0.8710\n",
      "Epoch 274/300\n",
      "111/111 - 0s - loss: 0.5699 - accuracy: 0.6812 - val_loss: 0.4657 - val_accuracy: 0.8226\n",
      "Epoch 275/300\n",
      "111/111 - 0s - loss: 0.5631 - accuracy: 0.6757 - val_loss: 0.4097 - val_accuracy: 0.8226\n",
      "Epoch 276/300\n",
      "111/111 - 0s - loss: 0.5528 - accuracy: 0.6993 - val_loss: 0.4293 - val_accuracy: 0.8226\n",
      "Epoch 277/300\n",
      "111/111 - 0s - loss: 0.5302 - accuracy: 0.7011 - val_loss: 0.4354 - val_accuracy: 0.8871\n",
      "Epoch 278/300\n",
      "111/111 - 0s - loss: 0.5731 - accuracy: 0.6830 - val_loss: 0.4214 - val_accuracy: 0.8548\n",
      "Epoch 279/300\n",
      "111/111 - 0s - loss: 0.5474 - accuracy: 0.6812 - val_loss: 0.4168 - val_accuracy: 0.8387\n",
      "Epoch 280/300\n",
      "111/111 - 0s - loss: 0.5292 - accuracy: 0.6975 - val_loss: 0.4126 - val_accuracy: 0.8710\n",
      "Epoch 281/300\n",
      "111/111 - 0s - loss: 0.5581 - accuracy: 0.6902 - val_loss: 0.4356 - val_accuracy: 0.8387\n",
      "Epoch 282/300\n",
      "111/111 - 0s - loss: 0.5664 - accuracy: 0.6812 - val_loss: 0.4282 - val_accuracy: 0.8548\n",
      "Epoch 283/300\n",
      "111/111 - 0s - loss: 0.5615 - accuracy: 0.6866 - val_loss: 0.4592 - val_accuracy: 0.8548\n",
      "Epoch 284/300\n",
      "111/111 - 0s - loss: 0.5607 - accuracy: 0.6920 - val_loss: 0.4330 - val_accuracy: 0.8548\n",
      "Epoch 285/300\n",
      "111/111 - 0s - loss: 0.5439 - accuracy: 0.6938 - val_loss: 0.4120 - val_accuracy: 0.8548\n",
      "Epoch 286/300\n",
      "111/111 - 0s - loss: 0.5482 - accuracy: 0.6993 - val_loss: 0.3992 - val_accuracy: 0.8710\n",
      "Epoch 287/300\n",
      "111/111 - 0s - loss: 0.5637 - accuracy: 0.6757 - val_loss: 0.3918 - val_accuracy: 0.8548\n",
      "Epoch 288/300\n",
      "111/111 - 0s - loss: 0.5497 - accuracy: 0.6920 - val_loss: 0.3982 - val_accuracy: 0.8710\n",
      "Epoch 289/300\n",
      "111/111 - 0s - loss: 0.5607 - accuracy: 0.6938 - val_loss: 0.4203 - val_accuracy: 0.8226\n",
      "Epoch 290/300\n",
      "111/111 - 0s - loss: 0.5502 - accuracy: 0.6848 - val_loss: 0.4308 - val_accuracy: 0.8387\n",
      "Epoch 291/300\n",
      "111/111 - 0s - loss: 0.5493 - accuracy: 0.6902 - val_loss: 0.4001 - val_accuracy: 0.9032\n",
      "Epoch 292/300\n",
      "111/111 - 0s - loss: 0.5510 - accuracy: 0.6902 - val_loss: 0.4236 - val_accuracy: 0.8387\n",
      "Epoch 293/300\n",
      "111/111 - 0s - loss: 0.5537 - accuracy: 0.6938 - val_loss: 0.4078 - val_accuracy: 0.8387\n",
      "Epoch 294/300\n",
      "111/111 - 0s - loss: 0.5369 - accuracy: 0.6957 - val_loss: 0.4469 - val_accuracy: 0.8548\n",
      "Epoch 295/300\n",
      "111/111 - 0s - loss: 0.5543 - accuracy: 0.6793 - val_loss: 0.3947 - val_accuracy: 0.8226\n",
      "Epoch 296/300\n",
      "111/111 - 0s - loss: 0.5461 - accuracy: 0.6866 - val_loss: 0.4231 - val_accuracy: 0.8548\n",
      "Epoch 297/300\n",
      "111/111 - 0s - loss: 0.5562 - accuracy: 0.6866 - val_loss: 0.4320 - val_accuracy: 0.8548\n",
      "Epoch 298/300\n",
      "111/111 - 0s - loss: 0.5582 - accuracy: 0.6830 - val_loss: 0.3955 - val_accuracy: 0.8548\n",
      "Epoch 299/300\n",
      "111/111 - 1s - loss: 0.5486 - accuracy: 0.6739 - val_loss: 0.3905 - val_accuracy: 0.8387\n",
      "Epoch 300/300\n",
      "111/111 - 0s - loss: 0.5439 - accuracy: 0.6957 - val_loss: 0.4665 - val_accuracy: 0.8548\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.6169\n",
      "\n",
      "accuracy: 61.69%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#       Binary classification\n",
    "#       A training program with keras\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "np.random.seed(34)\n",
    "#      fix random seed for reproducibility\n",
    "#      np.random.seed(7)\n",
    "#      load pima indians dataset\n",
    "dataset = np.loadtxt(\"C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "#      split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X, Y = shuffle(X,Y,random_state=0)\n",
    "x_train, x_test, y_train, y_test= train_test_split(X,Y, test_size=0.2)\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=8, activation='relu'))\n",
    "for i in range(2):\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.10, epochs=300, batch_size=5, verbose=2)\n",
    "#      evaluate the model\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "predictions=model.predict(x_test)\n",
    "rounded=[round(x[0]) for x in predictions]\n",
    "print(rounded)\n",
    "if True:\n",
    "#      serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "#      serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:32:44.476297Z",
     "start_time": "2022-06-24T02:32:44.299155Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "[[5.57566509e-02]\n",
      " [2.00396523e-01]\n",
      " [2.78462410e-01]\n",
      " [8.91121328e-01]\n",
      " [2.87220955e-01]\n",
      " [1.42738357e-01]\n",
      " [7.44971454e-01]\n",
      " [6.25792027e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [5.64414024e-01]\n",
      " [8.69751573e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [1.94189683e-01]\n",
      " [2.63632506e-01]\n",
      " [3.20296288e-01]\n",
      " [2.52689898e-01]\n",
      " [4.37259108e-01]\n",
      " [2.25064531e-01]\n",
      " [4.37259108e-01]\n",
      " [5.63245192e-02]\n",
      " [4.37259108e-01]\n",
      " [2.46866699e-02]\n",
      " [1.64217025e-01]\n",
      " [2.01007396e-01]\n",
      " [9.16695371e-02]\n",
      " [1.57079831e-01]\n",
      " [1.58050105e-01]\n",
      " [3.74191344e-01]\n",
      " [7.17220724e-01]\n",
      " [1.59580097e-01]\n",
      " [3.19090873e-01]\n",
      " [4.39022034e-01]\n",
      " [3.85261059e-01]\n",
      " [4.37259108e-01]\n",
      " [4.58492279e-01]\n",
      " [1.75472125e-01]\n",
      " [2.15503022e-01]\n",
      " [1.64756879e-01]\n",
      " [2.19071388e-01]\n",
      " [3.44951078e-02]\n",
      " [2.38672093e-01]\n",
      " [3.86851192e-01]\n",
      " [6.46254420e-01]\n",
      " [4.37259108e-01]\n",
      " [2.95233369e-01]\n",
      " [4.39022034e-01]\n",
      " [2.83956766e-01]\n",
      " [2.29111284e-01]\n",
      " [4.37259108e-01]\n",
      " [2.46844485e-01]\n",
      " [7.03081667e-01]\n",
      " [4.37259108e-01]\n",
      " [1.39778480e-01]\n",
      " [2.86032826e-01]\n",
      " [2.02696681e-01]\n",
      " [2.66970452e-02]\n",
      " [2.66267002e-01]\n",
      " [4.37259108e-01]\n",
      " [7.91543543e-01]\n",
      " [7.15215504e-02]\n",
      " [1.09314337e-01]\n",
      " [9.39266622e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [3.36350590e-01]\n",
      " [4.37259108e-01]\n",
      " [1.85664386e-01]\n",
      " [2.42267668e-01]\n",
      " [4.37259108e-01]\n",
      " [9.06183794e-02]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [2.97852516e-01]\n",
      " [8.67456291e-03]\n",
      " [8.07572842e-01]\n",
      " [2.48575453e-02]\n",
      " [2.84042448e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [2.58734554e-01]\n",
      " [3.42193961e-01]\n",
      " [4.37259108e-01]\n",
      " [1.44924954e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [8.57104361e-01]\n",
      " [4.37259108e-01]\n",
      " [2.80527949e-01]\n",
      " [8.21942315e-02]\n",
      " [3.19218159e-01]\n",
      " [2.61267185e-01]\n",
      " [4.37259108e-01]\n",
      " [1.19932629e-01]\n",
      " [1.53157771e-01]\n",
      " [8.21956322e-02]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [2.30062213e-02]\n",
      " [3.28102410e-01]\n",
      " [3.26023661e-02]\n",
      " [2.00644538e-01]\n",
      " [2.20831081e-01]\n",
      " [4.37259108e-01]\n",
      " [3.78142178e-01]\n",
      " [4.87951934e-02]\n",
      " [2.04907462e-01]\n",
      " [4.37259108e-01]\n",
      " [6.04021624e-02]\n",
      " [5.95160961e-01]\n",
      " [4.37259108e-01]\n",
      " [2.06237614e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.14277122e-03]\n",
      " [3.01267058e-01]\n",
      " [2.53531784e-02]\n",
      " [5.22525668e-01]\n",
      " [3.90894055e-01]\n",
      " [4.36579585e-02]\n",
      " [4.36367154e-01]\n",
      " [4.37259108e-01]\n",
      " [3.38955075e-01]\n",
      " [2.53266692e-01]\n",
      " [6.46766275e-02]\n",
      " [4.23415244e-01]\n",
      " [4.37259108e-01]\n",
      " [3.66960242e-02]\n",
      " [5.93340099e-01]\n",
      " [4.37259108e-01]\n",
      " [2.57068396e-01]\n",
      " [4.37259108e-01]\n",
      " [1.77921474e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.64629877e-01]\n",
      " [4.39022034e-01]\n",
      " [2.85191864e-01]\n",
      " [3.57945003e-02]\n",
      " [4.37259108e-01]\n",
      " [2.51509726e-01]\n",
      " [1.56196818e-01]\n",
      " [3.86672854e-01]\n",
      " [6.03188425e-02]\n",
      " [4.37259108e-01]\n",
      " [1.72284499e-01]\n",
      " [5.09585254e-02]\n",
      " [2.94910938e-01]\n",
      " [2.27148205e-01]\n",
      " [5.02062500e-01]\n",
      " [2.33283609e-01]\n",
      " [1.28030956e-01]\n",
      " [4.84430909e-01]\n",
      " [4.37259108e-01]\n",
      " [9.69200194e-01]\n",
      " [7.59330213e-01]\n",
      " [4.37259108e-01]\n",
      " [2.38513291e-01]\n",
      " [3.68900865e-01]\n",
      " [4.37259108e-01]\n",
      " [7.65634000e-01]\n",
      " [4.37259108e-01]\n",
      " [3.50146055e-01]\n",
      " [4.37259108e-01]\n",
      " [3.17695886e-02]\n",
      " [1.81988269e-01]\n",
      " [1.26383692e-01]\n",
      " [3.93402964e-01]\n",
      " [3.52164149e-01]\n",
      " [4.37259108e-01]\n",
      " [1.73196152e-01]\n",
      " [4.37259108e-01]\n",
      " [1.32387131e-01]\n",
      " [2.41200671e-01]\n",
      " [6.08059093e-02]\n",
      " [1.84653312e-01]\n",
      " [4.37259108e-01]\n",
      " [1.72967374e-01]\n",
      " [4.11270350e-01]\n",
      " [2.77212441e-01]\n",
      " [3.33575681e-02]\n",
      " [9.76261854e-01]\n",
      " [4.26790386e-01]\n",
      " [5.16733825e-01]\n",
      " [1.46728300e-04]\n",
      " [4.37259108e-01]\n",
      " [2.11458385e-01]\n",
      " [4.37259108e-01]\n",
      " [3.31958115e-01]\n",
      " [2.33453158e-02]\n",
      " [4.39022034e-01]\n",
      " [4.34925050e-01]\n",
      " [4.39022034e-01]\n",
      " [3.17823201e-01]\n",
      " [2.20147431e-01]\n",
      " [2.03572493e-02]\n",
      " [7.00876163e-03]\n",
      " [4.39022034e-01]\n",
      " [4.37259108e-01]\n",
      " [8.27995315e-02]\n",
      " [1.76277503e-01]\n",
      " [1.91115588e-01]\n",
      " [2.86759771e-02]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.03718944e-01]\n",
      " [1.66943252e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [2.06822500e-01]\n",
      " [1.37233436e-01]\n",
      " [6.52434349e-01]\n",
      " [7.99229965e-02]\n",
      " [4.37259108e-01]\n",
      " [2.90147275e-01]\n",
      " [4.00602102e-01]\n",
      " [5.90154827e-02]\n",
      " [2.57496357e-01]\n",
      " [4.37259108e-01]\n",
      " [7.63282506e-03]\n",
      " [4.37259108e-01]\n",
      " [5.34384727e-01]\n",
      " [3.79875004e-01]\n",
      " [2.20428586e-01]\n",
      " [2.02819407e-01]\n",
      " [4.37259108e-01]\n",
      " [1.89215306e-03]\n",
      " [6.42278045e-02]\n",
      " [3.30930889e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [3.33750188e-01]\n",
      " [4.01906639e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.27599746e-01]\n",
      " [8.23304713e-01]\n",
      " [2.11955179e-02]\n",
      " [1.47822440e-01]\n",
      " [4.39022034e-01]\n",
      " [4.37259108e-01]\n",
      " [1.04656197e-01]\n",
      " [4.37259108e-01]\n",
      " [3.02348047e-01]\n",
      " [2.37696096e-02]\n",
      " [1.88902780e-01]\n",
      " [4.37259108e-01]\n",
      " [1.35040775e-01]\n",
      " [4.39022034e-01]\n",
      " [5.54043464e-02]\n",
      " [4.19672690e-02]\n",
      " [2.37958595e-01]\n",
      " [2.41610378e-01]\n",
      " [1.36979654e-01]\n",
      " [7.63708651e-02]\n",
      " [4.37259108e-01]\n",
      " [2.60400504e-01]\n",
      " [1.77389234e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.59330085e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.32173789e-01]\n",
      " [2.79019505e-01]\n",
      " [4.37259108e-01]\n",
      " [1.33894250e-01]\n",
      " [3.35541844e-01]\n",
      " [4.05163467e-01]\n",
      " [3.07171315e-01]\n",
      " [4.37259108e-01]\n",
      " [1.97732329e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [9.29913074e-02]\n",
      " [2.74604082e-01]\n",
      " [4.37259108e-01]\n",
      " [1.60813779e-01]\n",
      " [1.96123019e-01]\n",
      " [1.97351217e-01]\n",
      " [2.41516948e-01]\n",
      " [4.37259108e-01]\n",
      " [2.50822663e-01]\n",
      " [4.37259108e-01]\n",
      " [9.60387349e-01]\n",
      " [7.53793061e-01]\n",
      " [4.37259108e-01]\n",
      " [1.02246240e-01]\n",
      " [4.37259108e-01]\n",
      " [3.86403888e-01]\n",
      " [4.37259108e-01]\n",
      " [8.80876243e-01]\n",
      " [1.75051779e-01]\n",
      " [2.07443431e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.07232332e-01]\n",
      " [2.10082263e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [3.86474192e-01]\n",
      " [3.26699615e-01]\n",
      " [2.61941910e-01]\n",
      " [7.59884119e-01]\n",
      " [4.37259108e-01]\n",
      " [9.19429660e-02]\n",
      " [6.30994260e-01]\n",
      " [3.45769525e-01]\n",
      " [2.05004103e-02]\n",
      " [6.46645352e-02]\n",
      " [3.38278472e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [4.37259108e-01]\n",
      " [4.16497022e-01]\n",
      " [1.60984099e-01]\n",
      " [4.22139347e-01]\n",
      " [1.98891535e-01]\n",
      " [1.16212152e-01]\n",
      " [2.42509850e-06]\n",
      " [4.22498882e-01]\n",
      " [2.17782632e-01]\n",
      " [4.37259108e-01]\n",
      " [6.71377003e-01]\n",
      " [7.50219822e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [2.40234390e-01]\n",
      " [2.09964633e-01]\n",
      " [5.95417619e-01]\n",
      " [1.79584369e-01]\n",
      " [9.21450794e-01]\n",
      " [3.63214582e-01]\n",
      " [3.21482927e-01]\n",
      " [4.17051941e-01]\n",
      " [2.56692350e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [8.86935815e-02]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [6.83258533e-01]\n",
      " [4.37259108e-01]\n",
      " [2.52726853e-01]\n",
      " [4.39022034e-01]\n",
      " [3.02386522e-01]\n",
      " [2.09787171e-02]\n",
      " [2.20627114e-01]\n",
      " [7.47962713e-01]\n",
      " [4.37259108e-01]\n",
      " [3.06816429e-01]\n",
      " [6.45178556e-01]\n",
      " [1.09127171e-01]\n",
      " [7.98530519e-01]\n",
      " [3.72144271e-08]\n",
      " [4.37259108e-01]\n",
      " [2.85297662e-01]\n",
      " [6.06770277e-01]\n",
      " [2.16248319e-01]\n",
      " [8.09439540e-01]\n",
      " [4.39022034e-01]\n",
      " [3.34716111e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [2.28190154e-01]\n",
      " [1.63771600e-01]\n",
      " [4.73071665e-01]\n",
      " [3.56378317e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [1.58216640e-01]\n",
      " [2.23630235e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.55674502e-01]\n",
      " [4.18457985e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [7.49144852e-01]\n",
      " [2.32407674e-01]\n",
      " [4.37259108e-01]\n",
      " [2.93008536e-01]\n",
      " [1.58526614e-01]\n",
      " [3.78978327e-02]\n",
      " [1.52400387e-02]\n",
      " [2.62931406e-01]\n",
      " [7.61675894e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [8.11207220e-02]\n",
      " [9.45779562e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [6.22652113e-01]\n",
      " [1.68346971e-01]\n",
      " [4.37259108e-01]\n",
      " [4.24868643e-01]\n",
      " [1.78081244e-01]\n",
      " [4.37259108e-01]\n",
      " [1.76096901e-01]\n",
      " [4.37259108e-01]\n",
      " [3.65724444e-01]\n",
      " [4.22644615e-02]\n",
      " [4.37259108e-01]\n",
      " [5.23063958e-01]\n",
      " [4.37259108e-01]\n",
      " [3.43666792e-01]\n",
      " [9.12599713e-02]\n",
      " [7.37323910e-02]\n",
      " [4.37259108e-01]\n",
      " [1.16364241e-01]\n",
      " [4.37259108e-01]\n",
      " [5.40685415e-01]\n",
      " [4.37259108e-01]\n",
      " [7.86141753e-01]\n",
      " [4.37259108e-01]\n",
      " [3.06589484e-01]\n",
      " [4.31513906e-01]\n",
      " [2.10506454e-01]\n",
      " [8.29712331e-01]\n",
      " [3.98729324e-01]\n",
      " [1.58062920e-01]\n",
      " [2.68718630e-01]\n",
      " [4.99455690e-01]\n",
      " [3.59507091e-02]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.70363829e-01]\n",
      " [2.22635448e-01]\n",
      " [4.37259108e-01]\n",
      " [2.36062095e-01]\n",
      " [4.39022034e-01]\n",
      " [3.16294469e-02]\n",
      " [4.36913490e-01]\n",
      " [5.85979462e-01]\n",
      " [3.05747658e-01]\n",
      " [4.39022034e-01]\n",
      " [4.39022034e-01]\n",
      " [1.66001655e-02]\n",
      " [4.37259108e-01]\n",
      " [7.36274347e-02]\n",
      " [4.39022034e-01]\n",
      " [3.23201358e-01]\n",
      " [3.13827068e-01]\n",
      " [3.57512802e-01]\n",
      " [4.37259108e-01]\n",
      " [4.78893876e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.17397499e-01]\n",
      " [4.37259108e-01]\n",
      " [2.24022239e-01]\n",
      " [4.37259108e-01]\n",
      " [2.90706754e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [3.20016861e-01]\n",
      " [3.52370948e-01]\n",
      " [6.26730099e-02]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [7.06988052e-02]\n",
      " [1.40067697e-01]\n",
      " [2.19529897e-01]\n",
      " [7.32628703e-02]\n",
      " [4.37259108e-01]\n",
      " [1.66410834e-01]\n",
      " [9.97978747e-01]\n",
      " [2.21269503e-02]\n",
      " [4.37259108e-01]\n",
      " [4.01818156e-01]\n",
      " [4.37259108e-01]\n",
      " [4.07724857e-01]\n",
      " [1.51664108e-01]\n",
      " [4.37259108e-01]\n",
      " [8.38495865e-02]\n",
      " [2.70585567e-01]\n",
      " [4.37259108e-01]\n",
      " [4.19557452e-01]\n",
      " [9.03365254e-01]\n",
      " [2.11599376e-02]\n",
      " [7.26027310e-01]\n",
      " [4.07384276e-01]\n",
      " [4.37259108e-01]\n",
      " [9.68377531e-01]\n",
      " [3.80218297e-01]\n",
      " [1.78180501e-01]\n",
      " [8.42461304e-04]\n",
      " [4.37259108e-01]\n",
      " [5.39555192e-01]\n",
      " [8.59995559e-02]\n",
      " [4.34080809e-01]\n",
      " [4.37259108e-01]\n",
      " [6.06390655e-01]\n",
      " [3.82080853e-01]\n",
      " [4.99440283e-02]\n",
      " [4.37259108e-01]\n",
      " [2.20490336e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [8.76388192e-01]\n",
      " [2.14348212e-01]\n",
      " [4.39022034e-01]\n",
      " [4.39022034e-01]\n",
      " [1.04257673e-01]\n",
      " [4.37259108e-01]\n",
      " [3.09808552e-01]\n",
      " [4.90979664e-02]\n",
      " [7.02343464e-01]\n",
      " [4.03447658e-01]\n",
      " [5.42417586e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [3.94625127e-01]\n",
      " [4.37259108e-01]\n",
      " [4.14651692e-01]\n",
      " [2.97443807e-01]\n",
      " [4.37259108e-01]\n",
      " [3.96655738e-01]\n",
      " [4.37259108e-01]\n",
      " [6.63406849e-02]\n",
      " [9.23300907e-02]\n",
      " [1.92616582e-01]\n",
      " [1.59065768e-01]\n",
      " [8.40960681e-01]\n",
      " [2.00442493e-01]\n",
      " [4.37259108e-01]\n",
      " [1.10552967e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [2.45129153e-01]\n",
      " [1.70582324e-01]\n",
      " [4.37259108e-01]\n",
      " [2.71704733e-01]\n",
      " [3.77834260e-01]\n",
      " [4.83132809e-01]\n",
      " [1.46941125e-01]\n",
      " [1.77106097e-01]\n",
      " [4.39022034e-01]\n",
      " [6.52578712e-01]\n",
      " [4.37259108e-01]\n",
      " [6.44455329e-02]\n",
      " [2.22652897e-01]\n",
      " [1.90675929e-01]\n",
      " [1.14325330e-01]\n",
      " [7.86120165e-03]\n",
      " [1.63717091e-01]\n",
      " [4.37259108e-01]\n",
      " [1.94484621e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.87779851e-02]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [3.91328695e-06]\n",
      " [3.52347881e-01]\n",
      " [4.84853297e-01]\n",
      " [4.39022034e-01]\n",
      " [4.39022034e-01]\n",
      " [3.30621183e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [4.02009934e-01]\n",
      " [4.37259108e-01]\n",
      " [1.87772334e-01]\n",
      " [2.27131307e-01]\n",
      " [4.37259108e-01]\n",
      " [4.88928229e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.67670622e-01]\n",
      " [1.28964394e-01]\n",
      " [4.75281924e-01]\n",
      " [7.08912760e-02]\n",
      " [4.39022034e-01]\n",
      " [4.07293618e-01]\n",
      " [4.37259108e-01]\n",
      " [8.64663243e-01]\n",
      " [1.91414520e-01]\n",
      " [3.62150222e-01]\n",
      " [6.23214878e-02]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [2.89213121e-01]\n",
      " [3.13535452e-01]\n",
      " [4.39022034e-01]\n",
      " [1.14608161e-01]\n",
      " [4.37259108e-01]\n",
      " [1.77863643e-01]\n",
      " [4.50837076e-01]\n",
      " [1.91624314e-01]\n",
      " [4.81672496e-01]\n",
      " [9.15881693e-01]\n",
      " [4.39022034e-01]\n",
      " [1.38868520e-03]\n",
      " [4.37259108e-01]\n",
      " [4.94614057e-02]\n",
      " [4.40990329e-01]\n",
      " [4.37259108e-01]\n",
      " [4.47460040e-02]\n",
      " [5.46613038e-01]\n",
      " [4.37259108e-01]\n",
      " [6.95179477e-02]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [3.29258665e-02]\n",
      " [5.90794325e-01]\n",
      " [4.39022034e-01]\n",
      " [3.69415462e-01]\n",
      " [1.30052716e-02]\n",
      " [2.78958529e-01]\n",
      " [2.39429995e-01]\n",
      " [3.69220436e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.06442422e-01]\n",
      " [2.91684717e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [2.26647541e-01]\n",
      " [1.43943101e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [8.59910667e-01]\n",
      " [1.25991479e-02]\n",
      " [7.34155029e-02]\n",
      " [4.37259108e-01]\n",
      " [1.99035872e-02]\n",
      " [1.68370068e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [4.37259108e-01]\n",
      " [7.09402621e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.62768066e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [4.37259108e-01]\n",
      " [1.61313433e-02]\n",
      " [1.02757193e-01]\n",
      " [1.82312906e-01]\n",
      " [7.03396499e-01]\n",
      " [1.26802623e-01]\n",
      " [4.37259108e-01]\n",
      " [5.78442097e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [2.06030101e-01]\n",
      " [2.86114961e-01]\n",
      " [1.49733707e-01]\n",
      " [5.52995689e-03]\n",
      " [4.39022034e-01]\n",
      " [2.46827841e-01]\n",
      " [4.39022034e-01]\n",
      " [4.37259108e-01]\n",
      " [3.83143425e-01]\n",
      " [2.74700284e-01]\n",
      " [5.91671646e-01]\n",
      " [1.85053959e-03]\n",
      " [4.37259108e-01]\n",
      " [1.27095819e-01]\n",
      " [4.37259108e-01]\n",
      " [1.99972346e-01]\n",
      " [4.37259108e-01]\n",
      " [2.63398826e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [6.47251233e-02]\n",
      " [4.37259108e-01]\n",
      " [4.05742049e-01]\n",
      " [3.36408652e-02]\n",
      " [1.67229008e-02]\n",
      " [2.18043864e-01]\n",
      " [1.08757369e-01]\n",
      " [1.06920928e-01]\n",
      " [2.69896209e-01]\n",
      " [8.58640790e-01]\n",
      " [4.68797274e-02]\n",
      " [4.39022034e-01]\n",
      " [1.33155078e-01]\n",
      " [4.37259108e-01]\n",
      " [1.47325069e-01]\n",
      " [1.80969745e-01]\n",
      " [2.16936320e-01]\n",
      " [6.84543923e-02]\n",
      " [1.77016512e-01]\n",
      " [8.79823323e-03]\n",
      " [3.09491843e-01]\n",
      " [1.56412721e-01]\n",
      " [1.11062422e-01]\n",
      " [4.39022034e-01]\n",
      " [1.14957817e-01]\n",
      " [1.00897156e-01]\n",
      " [2.14524671e-01]\n",
      " [2.85706129e-02]\n",
      " [7.37795353e-01]\n",
      " [4.37259108e-01]\n",
      " [2.36438736e-01]\n",
      " [5.38969934e-01]\n",
      " [2.37706408e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [5.22543848e-01]\n",
      " [2.26734683e-01]\n",
      " [1.32818401e-01]\n",
      " [1.23072676e-01]\n",
      " [1.91516936e-01]\n",
      " [4.39022034e-01]\n",
      " [1.33371651e-01]\n",
      " [3.00903559e-01]\n",
      " [1.33617818e-01]\n",
      " [4.39022034e-01]\n",
      " [1.49740070e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [1.98334038e-01]\n",
      " [1.31796598e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [4.37259108e-01]\n",
      " [7.69238174e-03]\n",
      " [3.25122952e-01]\n",
      " [4.37259108e-01]\n",
      " [1.20742381e-01]\n",
      " [1.65298581e-01]\n",
      " [1.67322680e-01]\n",
      " [4.37259108e-01]\n",
      " [6.00996986e-02]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [3.21411081e-02]\n",
      " [1.41519338e-01]\n",
      " [1.84792519e-01]\n",
      " [5.65548718e-01]\n",
      " [4.37259108e-01]\n",
      " [3.82203758e-01]\n",
      " [1.56144053e-01]\n",
      " [4.35883254e-01]\n",
      " [8.26764226e-01]\n",
      " [4.37259108e-01]\n",
      " [4.39022034e-01]\n",
      " [4.37259108e-01]\n",
      " [6.34090081e-02]\n",
      " [3.44242066e-01]\n",
      " [4.37259108e-01]]\n"
     ]
    }
   ],
   "source": [
    "#      Binary classification\n",
    "#      A prediction program with keras\n",
    "from keras.models import model_from_json\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "np.random.seed(34)\n",
    "random.seed(56)\n",
    "#        fix random seed for reproducibility\n",
    "#        np.random.seed(7)\n",
    "#        load pima indians dataset\n",
    "dataset = np.loadtxt(\"C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "#        split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X, Y = shuffle(X,Y,random_state=0)\n",
    "#           load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "#           load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "#           evaluate loaded model on test data\n",
    "loaded_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "predicted = loaded_model.predict(X)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:32:54.903347Z",
     "start_time": "2022-06-24T02:32:44.477299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 503\n",
      "Trainable params: 503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "22/22 - 1s - loss: 1.4213 - accuracy: 0.3426 - val_loss: 1.1237 - val_accuracy: 0.4167\n",
      "Epoch 2/100\n",
      "22/22 - 0s - loss: 1.1902 - accuracy: 0.3333 - val_loss: 1.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "22/22 - 0s - loss: 1.0959 - accuracy: 0.2315 - val_loss: 1.0868 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "22/22 - 0s - loss: 1.0279 - accuracy: 0.6481 - val_loss: 1.0287 - val_accuracy: 0.5833\n",
      "Epoch 5/100\n",
      "22/22 - 0s - loss: 0.9654 - accuracy: 0.6759 - val_loss: 0.9682 - val_accuracy: 0.5833\n",
      "Epoch 6/100\n",
      "22/22 - 0s - loss: 0.8902 - accuracy: 0.6759 - val_loss: 0.8754 - val_accuracy: 0.5833\n",
      "Epoch 7/100\n",
      "22/22 - 0s - loss: 0.8179 - accuracy: 0.6759 - val_loss: 0.7944 - val_accuracy: 0.5833\n",
      "Epoch 8/100\n",
      "22/22 - 0s - loss: 0.7444 - accuracy: 0.6759 - val_loss: 0.7175 - val_accuracy: 0.5833\n",
      "Epoch 9/100\n",
      "22/22 - 0s - loss: 0.6699 - accuracy: 0.7500 - val_loss: 0.6461 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "22/22 - 0s - loss: 0.6035 - accuracy: 0.8056 - val_loss: 0.5738 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "22/22 - 0s - loss: 0.5424 - accuracy: 0.8333 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "22/22 - 0s - loss: 0.4876 - accuracy: 0.8796 - val_loss: 0.4616 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "22/22 - 0s - loss: 0.4405 - accuracy: 0.9167 - val_loss: 0.3934 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "22/22 - 0s - loss: 0.3949 - accuracy: 0.9352 - val_loss: 0.3415 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "22/22 - 0s - loss: 0.3580 - accuracy: 0.9537 - val_loss: 0.3175 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "22/22 - 0s - loss: 0.3315 - accuracy: 0.9352 - val_loss: 0.2733 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "22/22 - 0s - loss: 0.3043 - accuracy: 0.9537 - val_loss: 0.2503 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "22/22 - 0s - loss: 0.2864 - accuracy: 0.9167 - val_loss: 0.2302 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "22/22 - 0s - loss: 0.2683 - accuracy: 0.9352 - val_loss: 0.2319 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "22/22 - 0s - loss: 0.2471 - accuracy: 0.9630 - val_loss: 0.1865 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "22/22 - 0s - loss: 0.2251 - accuracy: 0.9537 - val_loss: 0.1960 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "22/22 - 0s - loss: 0.2285 - accuracy: 0.9259 - val_loss: 0.1689 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "22/22 - 0s - loss: 0.2000 - accuracy: 0.9537 - val_loss: 0.1446 - val_accuracy: 0.9167\n",
      "Epoch 24/100\n",
      "22/22 - 0s - loss: 0.1929 - accuracy: 0.9537 - val_loss: 0.1390 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "22/22 - 0s - loss: 0.1874 - accuracy: 0.9352 - val_loss: 0.1973 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "22/22 - 0s - loss: 0.1797 - accuracy: 0.9352 - val_loss: 0.1169 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "22/22 - 0s - loss: 0.1577 - accuracy: 0.9722 - val_loss: 0.1128 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "22/22 - 0s - loss: 0.1608 - accuracy: 0.9259 - val_loss: 0.1233 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "22/22 - 0s - loss: 0.1393 - accuracy: 0.9444 - val_loss: 0.0981 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "22/22 - 0s - loss: 0.1353 - accuracy: 0.9537 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "22/22 - 0s - loss: 0.1582 - accuracy: 0.9074 - val_loss: 0.1002 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "22/22 - 0s - loss: 0.1259 - accuracy: 0.9630 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "22/22 - 0s - loss: 0.1266 - accuracy: 0.9630 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "22/22 - 0s - loss: 0.1215 - accuracy: 0.9537 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "22/22 - 0s - loss: 0.1196 - accuracy: 0.9722 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "22/22 - 0s - loss: 0.1185 - accuracy: 0.9722 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "22/22 - 0s - loss: 0.1200 - accuracy: 0.9259 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "22/22 - 0s - loss: 0.1278 - accuracy: 0.9630 - val_loss: 0.0645 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "22/22 - 0s - loss: 0.1054 - accuracy: 0.9722 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "22/22 - 0s - loss: 0.1121 - accuracy: 0.9352 - val_loss: 0.0650 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "22/22 - 0s - loss: 0.1046 - accuracy: 0.9722 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "22/22 - 0s - loss: 0.1201 - accuracy: 0.9352 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "22/22 - 0s - loss: 0.1063 - accuracy: 0.9722 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "22/22 - 0s - loss: 0.0991 - accuracy: 0.9815 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "22/22 - 0s - loss: 0.1195 - accuracy: 0.9444 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "22/22 - 0s - loss: 0.1107 - accuracy: 0.9630 - val_loss: 0.0674 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "22/22 - 0s - loss: 0.0957 - accuracy: 0.9630 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "22/22 - 0s - loss: 0.1045 - accuracy: 0.9444 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "22/22 - 0s - loss: 0.1017 - accuracy: 0.9722 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "22/22 - 0s - loss: 0.1096 - accuracy: 0.9444 - val_loss: 0.0949 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "22/22 - 0s - loss: 0.1169 - accuracy: 0.9444 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "22/22 - 0s - loss: 0.0938 - accuracy: 0.9722 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "22/22 - 0s - loss: 0.0965 - accuracy: 0.9630 - val_loss: 0.0614 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "22/22 - 0s - loss: 0.0923 - accuracy: 0.9630 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "22/22 - 0s - loss: 0.0911 - accuracy: 0.9722 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "22/22 - 0s - loss: 0.0893 - accuracy: 0.9722 - val_loss: 0.0665 - val_accuracy: 0.9167\n",
      "Epoch 57/100\n",
      "22/22 - 0s - loss: 0.0893 - accuracy: 0.9722 - val_loss: 0.0418 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "22/22 - 0s - loss: 0.0899 - accuracy: 0.9722 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "22/22 - 0s - loss: 0.0917 - accuracy: 0.9722 - val_loss: 0.0899 - val_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "22/22 - 0s - loss: 0.0955 - accuracy: 0.9444 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "22/22 - 0s - loss: 0.0942 - accuracy: 0.9722 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "22/22 - 0s - loss: 0.0968 - accuracy: 0.9444 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "22/22 - 0s - loss: 0.0840 - accuracy: 0.9722 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "22/22 - 0s - loss: 0.0856 - accuracy: 0.9815 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "22/22 - 0s - loss: 0.0905 - accuracy: 0.9537 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "22/22 - 0s - loss: 0.0876 - accuracy: 0.9722 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "22/22 - 0s - loss: 0.0838 - accuracy: 0.9815 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "22/22 - 0s - loss: 0.0812 - accuracy: 0.9722 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "22/22 - 0s - loss: 0.0797 - accuracy: 0.9630 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "22/22 - 0s - loss: 0.1098 - accuracy: 0.9722 - val_loss: 0.0945 - val_accuracy: 0.9167\n",
      "Epoch 71/100\n",
      "22/22 - 0s - loss: 0.0720 - accuracy: 0.9815 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "22/22 - 0s - loss: 0.1078 - accuracy: 0.9537 - val_loss: 0.0326 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "22/22 - 0s - loss: 0.0825 - accuracy: 0.9630 - val_loss: 0.0722 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      "22/22 - 0s - loss: 0.0852 - accuracy: 0.9722 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "22/22 - 0s - loss: 0.0812 - accuracy: 0.9630 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "22/22 - 0s - loss: 0.0826 - accuracy: 0.9630 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "22/22 - 0s - loss: 0.0999 - accuracy: 0.9630 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "22/22 - 0s - loss: 0.0992 - accuracy: 0.9444 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "22/22 - 0s - loss: 0.1206 - accuracy: 0.9537 - val_loss: 0.1273 - val_accuracy: 0.9167\n",
      "Epoch 80/100\n",
      "22/22 - 0s - loss: 0.1296 - accuracy: 0.9259 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "22/22 - 0s - loss: 0.0894 - accuracy: 0.9537 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "22/22 - 0s - loss: 0.0734 - accuracy: 0.9815 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "22/22 - 0s - loss: 0.0817 - accuracy: 0.9537 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "22/22 - 0s - loss: 0.0910 - accuracy: 0.9537 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "22/22 - 0s - loss: 0.0749 - accuracy: 0.9815 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "22/22 - 0s - loss: 0.0804 - accuracy: 0.9722 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "22/22 - 0s - loss: 0.0771 - accuracy: 0.9630 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "22/22 - 0s - loss: 0.0860 - accuracy: 0.9630 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "22/22 - 0s - loss: 0.0931 - accuracy: 0.9630 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "22/22 - 0s - loss: 0.0728 - accuracy: 0.9815 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "22/22 - 0s - loss: 0.0796 - accuracy: 0.9630 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "22/22 - 0s - loss: 0.0763 - accuracy: 0.9722 - val_loss: 0.0740 - val_accuracy: 0.9167\n",
      "Epoch 93/100\n",
      "22/22 - 0s - loss: 0.0832 - accuracy: 0.9722 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "22/22 - 0s - loss: 0.0775 - accuracy: 0.9815 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "22/22 - 0s - loss: 0.0865 - accuracy: 0.9537 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "22/22 - 0s - loss: 0.0822 - accuracy: 0.9630 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "22/22 - 0s - loss: 0.0833 - accuracy: 0.9537 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "22/22 - 0s - loss: 0.0736 - accuracy: 0.9815 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "22/22 - 0s - loss: 0.0841 - accuracy: 0.9630 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "22/22 - 0s - loss: 0.0878 - accuracy: 0.9630 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0949 - accuracy: 0.9667\n",
      "\n",
      "Test: Loss: 0.0949\n",
      "\n",
      "Test: Accuracy: 0.9667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "[[ 8  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1 11]]\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#       Multi-class classification\n",
    "#       A training program with keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(34)\n",
    "random.seed(56)\n",
    "random.seed(time.time())\n",
    "df = pd.read_csv('C:/Users/ihlee/testAI/scikitlearn_keras_examples/iris.csv',names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "data_set = df.values\n",
    "X = data_set[:, 0:4].astype(float)\n",
    "obj_y = data_set[:, 4]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(obj_y)\n",
    "Y_encodered = encoder.transform(obj_y)\n",
    "Y = np_utils.to_categorical(Y_encodered)\n",
    "X, Y = shuffle(X,Y,random_state=0)\n",
    "x_train, x_test, y_train, y_test= train_test_split(X,Y, test_size=0.2)\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=4, activation='relu'))\n",
    "for i in range(3):\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.10, epochs=100, batch_size=5, verbose=2)\n",
    "scores=model.evaluate(x_test, y_test)\n",
    "print('\\nTest: Loss: {:.4f}'.format(scores[0]))\n",
    "print('\\nTest: Accuracy: {:.4f}'.format(scores[1]))\n",
    "y_pred=model.predict(x_test)\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "y_test=np.argmax(y_test,axis=1)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "if True:\n",
    "#       serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "#       serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:32:55.113183Z",
     "start_time": "2022-06-24T02:32:54.904303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "[[7.07582402e-08 8.52727983e-03 9.91472602e-01]\n",
      " [6.11987256e-04 9.99217153e-01 1.70855987e-04]\n",
      " [9.99951363e-01 4.86578501e-05 2.43597464e-16]\n",
      " [1.21667396e-08 1.17937373e-02 9.88206208e-01]\n",
      " [9.99762595e-01 2.37417422e-04 3.62492527e-14]\n",
      " [8.83054074e-09 4.46071196e-03 9.95539248e-01]\n",
      " [9.99814570e-01 1.85471756e-04 2.19096456e-14]\n",
      " [7.30650718e-05 9.98774588e-01 1.15224568e-03]\n",
      " [6.80643789e-05 9.97919261e-01 2.01270264e-03]\n",
      " [4.18061769e-04 9.99473870e-01 1.08035900e-04]\n",
      " [2.78747621e-07 3.95965204e-02 9.60403204e-01]\n",
      " [1.04511018e-04 9.99031305e-01 8.64126603e-04]\n",
      " [8.53945385e-05 9.92542148e-01 7.37242308e-03]\n",
      " [7.94601656e-05 9.95455980e-01 4.46455646e-03]\n",
      " [5.95519050e-05 9.78124499e-01 2.18158755e-02]\n",
      " [9.99700546e-01 2.99468986e-04 9.52487397e-14]\n",
      " [7.80690534e-05 9.81852710e-01 1.80692598e-02]\n",
      " [1.22707861e-04 9.65559363e-01 3.43178995e-02]\n",
      " [9.99541402e-01 4.58684022e-04 3.54442224e-13]\n",
      " [9.99909878e-01 9.01148160e-05 1.76518913e-15]\n",
      " [1.22371304e-07 1.19759217e-02 9.88023937e-01]\n",
      " [5.94745470e-05 9.14511859e-01 8.54286104e-02]\n",
      " [9.99298573e-01 7.01363198e-04 3.75021411e-13]\n",
      " [9.99289989e-01 7.10039458e-04 1.61901829e-12]\n",
      " [1.37060424e-05 5.78443289e-01 4.21543002e-01]\n",
      " [9.99856472e-01 1.43480371e-04 2.05858195e-14]\n",
      " [9.99522448e-01 4.77621419e-04 7.36648223e-14]\n",
      " [2.11234001e-04 9.99403596e-01 3.85163468e-04]\n",
      " [2.20880634e-03 9.97669160e-01 1.22081547e-04]\n",
      " [9.99594271e-01 4.05766012e-04 1.18513936e-13]\n",
      " [3.38545391e-07 7.06809983e-02 9.29318607e-01]\n",
      " [4.65560879e-05 7.98843980e-01 2.01109469e-01]\n",
      " [9.99833941e-01 1.65971505e-04 1.15230921e-14]\n",
      " [8.27124950e-06 4.57311600e-01 5.42680085e-01]\n",
      " [2.08721751e-08 5.93145099e-03 9.94068503e-01]\n",
      " [2.65157287e-04 9.86252010e-01 1.34828584e-02]\n",
      " [9.99891162e-01 1.08785338e-04 1.58809286e-15]\n",
      " [2.17548040e-06 1.54375404e-01 8.45622420e-01]\n",
      " [1.62796729e-04 9.97322857e-01 2.51439749e-03]\n",
      " [4.10003006e-04 9.99118149e-01 4.71932639e-04]\n",
      " [1.40911396e-07 4.15489972e-02 9.58450854e-01]\n",
      " [9.99695659e-01 3.04359302e-04 1.29790032e-13]\n",
      " [1.99509395e-06 2.87281364e-01 7.12716639e-01]\n",
      " [9.99422789e-01 5.77209459e-04 2.40807049e-13]\n",
      " [9.99894500e-01 1.05519990e-04 2.62507178e-15]\n",
      " [1.19924988e-03 9.97363627e-01 1.43713516e-03]\n",
      " [3.98703975e-07 8.02578405e-02 9.19741809e-01]\n",
      " [6.57888011e-09 4.34696116e-03 9.95653033e-01]\n",
      " [2.25381632e-06 1.13575876e-01 8.86421859e-01]\n",
      " [1.89530667e-08 6.90409262e-03 9.93095815e-01]\n",
      " [5.56708954e-04 9.99010921e-01 4.32284258e-04]\n",
      " [1.04751736e-08 1.23040145e-02 9.87696052e-01]\n",
      " [5.03679294e-05 9.91538286e-01 8.41136836e-03]\n",
      " [6.65550819e-04 9.98834431e-01 4.99925169e-04]\n",
      " [8.34202820e-06 4.36696529e-01 5.63295126e-01]\n",
      " [1.43199140e-05 7.05478370e-01 2.94507295e-01]\n",
      " [6.85037207e-07 2.11773440e-02 9.78821993e-01]\n",
      " [9.84711846e-07 8.25332627e-02 9.17465806e-01]\n",
      " [1.05350955e-04 9.99806702e-01 8.79037252e-05]\n",
      " [1.06835125e-06 1.45368338e-01 8.54630589e-01]\n",
      " [7.21773395e-05 9.93608236e-01 6.31967746e-03]\n",
      " [9.99514341e-01 4.85654600e-04 3.01188870e-13]\n",
      " [7.39476818e-08 9.30371974e-03 9.90696192e-01]\n",
      " [1.87174184e-04 9.92266595e-01 7.54625304e-03]\n",
      " [8.86322814e-04 9.99060810e-01 5.29110002e-05]\n",
      " [2.83063913e-04 9.93558943e-01 6.15803758e-03]\n",
      " [7.91625062e-05 9.92304027e-01 7.61675555e-03]\n",
      " [3.05934094e-07 1.42521799e-01 8.57477844e-01]\n",
      " [9.99879599e-01 1.20358345e-04 3.94158778e-15]\n",
      " [9.99629736e-01 3.70240421e-04 4.49473873e-13]\n",
      " [2.13954152e-07 3.48436236e-02 9.65156138e-01]\n",
      " [2.52323633e-04 9.98985469e-01 7.62158947e-04]\n",
      " [9.99803722e-01 1.96294917e-04 1.31276732e-14]\n",
      " [9.99947071e-01 5.28765922e-05 1.81452761e-16]\n",
      " [4.92338950e-05 9.98188555e-01 1.76219048e-03]\n",
      " [9.99465883e-01 5.34094055e-04 5.00476505e-13]\n",
      " [6.90186084e-07 7.04778507e-02 9.29521501e-01]\n",
      " [1.68049764e-02 9.83177483e-01 1.75664463e-05]\n",
      " [9.99591768e-01 4.08290449e-04 2.10803665e-13]\n",
      " [7.19952077e-05 9.22571421e-01 7.73565397e-02]\n",
      " [1.68418957e-09 3.05927498e-03 9.96940732e-01]\n",
      " [2.06200784e-04 9.97536659e-01 2.25717877e-03]\n",
      " [9.99682546e-01 3.17483995e-04 1.47085713e-13]\n",
      " [1.62744342e-08 1.11509729e-02 9.88849044e-01]\n",
      " [1.27244553e-08 8.15584697e-03 9.91844118e-01]\n",
      " [1.14349703e-08 4.99153975e-03 9.95008469e-01]\n",
      " [2.00240873e-08 5.94854169e-03 9.94051397e-01]\n",
      " [9.99831557e-01 1.68467930e-04 8.64048992e-15]\n",
      " [9.99634624e-01 3.65372252e-04 1.10871829e-13]\n",
      " [4.06290701e-06 4.14241880e-01 5.85754037e-01]\n",
      " [3.77357665e-08 1.84120946e-02 9.81587887e-01]\n",
      " [9.98882592e-01 1.11735507e-03 9.10317481e-12]\n",
      " [2.40223930e-08 8.87189247e-03 9.91128087e-01]\n",
      " [9.99665380e-01 3.34575423e-04 1.52070834e-13]\n",
      " [1.24838337e-07 1.02517065e-02 9.89748240e-01]\n",
      " [8.04387980e-07 1.71352670e-01 8.28646600e-01]\n",
      " [9.99548376e-01 4.51611908e-04 4.39324277e-13]\n",
      " [9.99833941e-01 1.66007914e-04 1.37227986e-14]\n",
      " [2.90777916e-06 5.89905739e-01 4.10091400e-01]\n",
      " [9.99807656e-01 1.92358057e-04 1.97971268e-14]\n",
      " [9.99454081e-01 5.45951712e-04 8.55313541e-13]\n",
      " [9.99823511e-01 1.76479400e-04 5.98111775e-15]\n",
      " [2.71123048e-04 9.87201929e-01 1.25269005e-02]\n",
      " [5.37978373e-09 4.06637415e-03 9.95933592e-01]\n",
      " [1.29597699e-09 2.66319537e-03 9.97336805e-01]\n",
      " [9.99839902e-01 1.60029362e-04 1.27526172e-14]\n",
      " [9.99700546e-01 2.99468986e-04 9.52487397e-14]\n",
      " [9.99845743e-01 1.54265683e-04 1.18510235e-14]\n",
      " [9.27920555e-05 9.73510325e-01 2.63968538e-02]\n",
      " [1.73627457e-04 9.99670386e-01 1.56051989e-04]\n",
      " [9.99826610e-01 1.73387991e-04 2.82608765e-14]\n",
      " [9.99385715e-01 6.14278484e-04 2.84324918e-13]\n",
      " [2.35768428e-04 9.99621153e-01 1.42949240e-04]\n",
      " [9.99797404e-01 2.02670592e-04 1.71873708e-14]\n",
      " [1.81583304e-09 2.68863095e-03 9.97311354e-01]\n",
      " [2.02293484e-03 9.97840524e-01 1.36548057e-04]\n",
      " [3.43896943e-07 3.85455430e-01 6.14544272e-01]\n",
      " [1.86822857e-04 9.99746740e-01 6.64403487e-05]\n",
      " [9.99921799e-01 7.81364361e-05 1.00564442e-15]\n",
      " [1.12421676e-05 5.10383248e-01 4.89605457e-01]\n",
      " [9.99971628e-01 2.83257705e-05 7.61097815e-17]\n",
      " [1.30261713e-09 2.70229508e-03 9.97297704e-01]\n",
      " [9.99828815e-01 1.71182299e-04 9.88663548e-15]\n",
      " [9.99496222e-01 5.03793301e-04 3.24098495e-13]\n",
      " [3.57082861e-08 2.47591678e-02 9.75240827e-01]\n",
      " [9.99779284e-01 2.20673872e-04 3.72811150e-14]\n",
      " [1.00031450e-08 5.08150179e-03 9.94918406e-01]\n",
      " [2.60615343e-04 9.98148084e-01 1.59134914e-03]\n",
      " [5.37328306e-04 9.99300122e-01 1.62444674e-04]\n",
      " [6.69471454e-03 9.93295729e-01 9.55871292e-06]\n",
      " [3.85870074e-08 1.18345525e-02 9.88165379e-01]\n",
      " [2.32506935e-07 4.89532724e-02 9.51046526e-01]\n",
      " [2.45235769e-05 7.71267414e-01 2.28708103e-01]\n",
      " [2.21226819e-05 9.43912387e-01 5.60654290e-02]\n",
      " [9.99589503e-01 4.10469773e-04 1.86419267e-13]\n",
      " [1.02723902e-03 9.98854041e-01 1.18767384e-04]\n",
      " [9.65001679e-09 4.86690039e-03 9.95133102e-01]\n",
      " [7.39476818e-08 9.30371974e-03 9.90696192e-01]\n",
      " [9.99791920e-01 2.08150668e-04 2.41421161e-14]\n",
      " [1.23539401e-04 9.99432266e-01 4.44143137e-04]\n",
      " [2.56009196e-04 9.98467505e-01 1.27642252e-03]\n",
      " [1.22260863e-05 5.65219641e-01 4.34768140e-01]\n",
      " [1.54808804e-04 9.95771229e-01 4.07390436e-03]\n",
      " [9.99920130e-01 7.99211557e-05 1.84920887e-15]\n",
      " [9.99773800e-01 2.26244039e-04 2.14158559e-14]\n",
      " [9.99700546e-01 2.99468986e-04 9.52487397e-14]\n",
      " [4.23474908e-08 1.19582796e-02 9.88041639e-01]\n",
      " [4.67305974e-04 9.99376833e-01 1.55935952e-04]\n",
      " [1.88098204e-09 6.93690404e-03 9.93063152e-01]\n",
      " [9.99589384e-01 4.10651031e-04 2.64386738e-13]]\n"
     ]
    }
   ],
   "source": [
    "#        Multi-class classification\n",
    "#        A prediction program with keras\n",
    "from keras.models import model_from_json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(34)\n",
    "random.seed(56)\n",
    "\n",
    "df = pd.read_csv('C:/Users/ihlee/testAI/scikitlearn_keras_examples/iris.csv',names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "data_set = df.values\n",
    "X = data_set[:, 0:4].astype(float)\n",
    "obj_y = data_set[:, 4]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(obj_y)\n",
    "Y_encodered = encoder.transform(obj_y)\n",
    "Y = np_utils.to_categorical(Y_encodered)\n",
    "X, Y = shuffle(X,Y,random_state=0)\n",
    "x_train, x_test, y_train, y_test= train_test_split(X,Y, test_size=0.2)\n",
    "#         load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "#         load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "#         evaluate loaded model on test data\n",
    "loaded_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "predicted = loaded_model.predict(X)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regression save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:33:26.777260Z",
     "start_time": "2022-06-24T02:32:55.115183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 30)                420       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 1,365\n",
      "Trainable params: 1,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "37/37 - 1s - loss: 483.6698 - val_loss: 128.3096\n",
      "Epoch 2/200\n",
      "37/37 - 0s - loss: 82.0151 - val_loss: 40.7839\n",
      "Epoch 3/200\n",
      "37/37 - 0s - loss: 67.6760 - val_loss: 39.0909\n",
      "Epoch 4/200\n",
      "37/37 - 0s - loss: 67.4271 - val_loss: 46.9441\n",
      "Epoch 5/200\n",
      "37/37 - 0s - loss: 69.5428 - val_loss: 50.0505\n",
      "Epoch 6/200\n",
      "37/37 - 0s - loss: 82.2735 - val_loss: 37.3924\n",
      "Epoch 7/200\n",
      "37/37 - 0s - loss: 61.8949 - val_loss: 40.6377\n",
      "Epoch 8/200\n",
      "37/37 - 0s - loss: 63.1211 - val_loss: 34.8730\n",
      "Epoch 9/200\n",
      "37/37 - 0s - loss: 59.8710 - val_loss: 35.2234\n",
      "Epoch 10/200\n",
      "37/37 - 0s - loss: 66.2185 - val_loss: 60.1860\n",
      "Epoch 11/200\n",
      "37/37 - 0s - loss: 61.3889 - val_loss: 34.8247\n",
      "Epoch 12/200\n",
      "37/37 - 0s - loss: 57.5941 - val_loss: 30.9823\n",
      "Epoch 13/200\n",
      "37/37 - 0s - loss: 59.0563 - val_loss: 30.4834\n",
      "Epoch 14/200\n",
      "37/37 - 0s - loss: 55.8333 - val_loss: 29.1080\n",
      "Epoch 15/200\n",
      "37/37 - 0s - loss: 55.8651 - val_loss: 28.5244\n",
      "Epoch 16/200\n",
      "37/37 - 0s - loss: 52.3614 - val_loss: 30.1817\n",
      "Epoch 17/200\n",
      "37/37 - 0s - loss: 51.1841 - val_loss: 28.3184\n",
      "Epoch 18/200\n",
      "37/37 - 0s - loss: 48.1768 - val_loss: 31.9503\n",
      "Epoch 19/200\n",
      "37/37 - 0s - loss: 52.1525 - val_loss: 26.0717\n",
      "Epoch 20/200\n",
      "37/37 - 0s - loss: 52.1796 - val_loss: 28.3111\n",
      "Epoch 21/200\n",
      "37/37 - 0s - loss: 45.8007 - val_loss: 25.8617\n",
      "Epoch 22/200\n",
      "37/37 - 0s - loss: 43.2738 - val_loss: 23.2048\n",
      "Epoch 23/200\n",
      "37/37 - 0s - loss: 48.1126 - val_loss: 23.2063\n",
      "Epoch 24/200\n",
      "37/37 - 0s - loss: 44.5961 - val_loss: 23.0669\n",
      "Epoch 25/200\n",
      "37/37 - 0s - loss: 43.7708 - val_loss: 30.8670\n",
      "Epoch 26/200\n",
      "37/37 - 0s - loss: 41.7228 - val_loss: 21.3026\n",
      "Epoch 27/200\n",
      "37/37 - 0s - loss: 38.9107 - val_loss: 20.4459\n",
      "Epoch 28/200\n",
      "37/37 - 0s - loss: 37.2713 - val_loss: 20.2737\n",
      "Epoch 29/200\n",
      "37/37 - 0s - loss: 35.7426 - val_loss: 19.5230\n",
      "Epoch 30/200\n",
      "37/37 - 0s - loss: 36.8336 - val_loss: 19.7553\n",
      "Epoch 31/200\n",
      "37/37 - 0s - loss: 34.7711 - val_loss: 18.3711\n",
      "Epoch 32/200\n",
      "37/37 - 0s - loss: 41.2041 - val_loss: 21.2479\n",
      "Epoch 33/200\n",
      "37/37 - 0s - loss: 41.4524 - val_loss: 49.0706\n",
      "Epoch 34/200\n",
      "37/37 - 0s - loss: 39.5335 - val_loss: 18.5308\n",
      "Epoch 35/200\n",
      "37/37 - 0s - loss: 32.5022 - val_loss: 21.3981\n",
      "Epoch 36/200\n",
      "37/37 - 0s - loss: 37.2767 - val_loss: 18.5571\n",
      "Epoch 37/200\n",
      "37/37 - 0s - loss: 32.8370 - val_loss: 20.3698\n",
      "Epoch 38/200\n",
      "37/37 - 0s - loss: 35.7984 - val_loss: 22.5215\n",
      "Epoch 39/200\n",
      "37/37 - 0s - loss: 33.6543 - val_loss: 22.6172\n",
      "Epoch 40/200\n",
      "37/37 - 0s - loss: 35.2035 - val_loss: 19.5764\n",
      "Epoch 41/200\n",
      "37/37 - 0s - loss: 31.6554 - val_loss: 19.3804\n",
      "Epoch 42/200\n",
      "37/37 - 0s - loss: 31.3131 - val_loss: 17.8075\n",
      "Epoch 43/200\n",
      "37/37 - 0s - loss: 31.0475 - val_loss: 24.3582\n",
      "Epoch 44/200\n",
      "37/37 - 0s - loss: 32.5344 - val_loss: 20.9736\n",
      "Epoch 45/200\n",
      "37/37 - 0s - loss: 31.6847 - val_loss: 17.2519\n",
      "Epoch 46/200\n",
      "37/37 - 0s - loss: 28.9149 - val_loss: 16.7729\n",
      "Epoch 47/200\n",
      "37/37 - 0s - loss: 30.7248 - val_loss: 16.6992\n",
      "Epoch 48/200\n",
      "37/37 - 0s - loss: 30.3223 - val_loss: 18.4493\n",
      "Epoch 49/200\n",
      "37/37 - 0s - loss: 30.7031 - val_loss: 31.9210\n",
      "Epoch 50/200\n",
      "37/37 - 0s - loss: 30.8803 - val_loss: 17.2581\n",
      "Epoch 51/200\n",
      "37/37 - 0s - loss: 28.2003 - val_loss: 18.7628\n",
      "Epoch 52/200\n",
      "37/37 - 0s - loss: 30.3039 - val_loss: 21.6125\n",
      "Epoch 53/200\n",
      "37/37 - 0s - loss: 28.4457 - val_loss: 19.8552\n",
      "Epoch 54/200\n",
      "37/37 - 0s - loss: 27.7987 - val_loss: 23.4347\n",
      "Epoch 55/200\n",
      "37/37 - 0s - loss: 26.5852 - val_loss: 23.6130\n",
      "Epoch 56/200\n",
      "37/37 - 0s - loss: 28.4018 - val_loss: 27.6399\n",
      "Epoch 57/200\n",
      "37/37 - 0s - loss: 27.4865 - val_loss: 18.5115\n",
      "Epoch 58/200\n",
      "37/37 - 0s - loss: 26.3915 - val_loss: 15.1259\n",
      "Epoch 59/200\n",
      "37/37 - 0s - loss: 23.2237 - val_loss: 15.8409\n",
      "Epoch 60/200\n",
      "37/37 - 0s - loss: 26.5443 - val_loss: 24.1196\n",
      "Epoch 61/200\n",
      "37/37 - 0s - loss: 24.0571 - val_loss: 33.9802\n",
      "Epoch 62/200\n",
      "37/37 - 0s - loss: 37.8377 - val_loss: 20.4487\n",
      "Epoch 63/200\n",
      "37/37 - 0s - loss: 23.3940 - val_loss: 25.7284\n",
      "Epoch 64/200\n",
      "37/37 - 0s - loss: 28.7834 - val_loss: 20.0261\n",
      "Epoch 65/200\n",
      "37/37 - 0s - loss: 24.3937 - val_loss: 20.5852\n",
      "Epoch 66/200\n",
      "37/37 - 0s - loss: 29.9949 - val_loss: 15.7758\n",
      "Epoch 67/200\n",
      "37/37 - 0s - loss: 26.3649 - val_loss: 16.7248\n",
      "Epoch 68/200\n",
      "37/37 - 0s - loss: 26.0786 - val_loss: 20.5036\n",
      "Epoch 69/200\n",
      "37/37 - 0s - loss: 24.7712 - val_loss: 24.8586\n",
      "Epoch 70/200\n",
      "37/37 - 0s - loss: 25.1927 - val_loss: 16.2765\n",
      "Epoch 71/200\n",
      "37/37 - 0s - loss: 21.9450 - val_loss: 16.2539\n",
      "Epoch 72/200\n",
      "37/37 - 0s - loss: 23.5026 - val_loss: 17.9491\n",
      "Epoch 73/200\n",
      "37/37 - 0s - loss: 23.1135 - val_loss: 15.8304\n",
      "Epoch 74/200\n",
      "37/37 - 0s - loss: 23.0403 - val_loss: 12.3104\n",
      "Epoch 75/200\n",
      "37/37 - 0s - loss: 20.6746 - val_loss: 14.5328\n",
      "Epoch 76/200\n",
      "37/37 - 0s - loss: 20.8631 - val_loss: 18.8389\n",
      "Epoch 77/200\n",
      "37/37 - 0s - loss: 26.5531 - val_loss: 14.2344\n",
      "Epoch 78/200\n",
      "37/37 - 0s - loss: 24.7686 - val_loss: 13.4802\n",
      "Epoch 79/200\n",
      "37/37 - 0s - loss: 28.8493 - val_loss: 29.0970\n",
      "Epoch 80/200\n",
      "37/37 - 0s - loss: 25.3128 - val_loss: 30.1054\n",
      "Epoch 81/200\n",
      "37/37 - 0s - loss: 23.4664 - val_loss: 12.7288\n",
      "Epoch 82/200\n",
      "37/37 - 0s - loss: 21.4843 - val_loss: 14.8429\n",
      "Epoch 83/200\n",
      "37/37 - 0s - loss: 21.5872 - val_loss: 12.8426\n",
      "Epoch 84/200\n",
      "37/37 - 0s - loss: 22.0738 - val_loss: 20.4616\n",
      "Epoch 85/200\n",
      "37/37 - 0s - loss: 25.0252 - val_loss: 22.1070\n",
      "Epoch 86/200\n",
      "37/37 - 0s - loss: 24.2522 - val_loss: 17.1806\n",
      "Epoch 87/200\n",
      "37/37 - 0s - loss: 21.8874 - val_loss: 13.5084\n",
      "Epoch 88/200\n",
      "37/37 - 0s - loss: 20.2042 - val_loss: 12.7695\n",
      "Epoch 89/200\n",
      "37/37 - 0s - loss: 20.5310 - val_loss: 14.6651\n",
      "Epoch 90/200\n",
      "37/37 - 0s - loss: 19.7890 - val_loss: 13.6104\n",
      "Epoch 91/200\n",
      "37/37 - 0s - loss: 19.0339 - val_loss: 17.3471\n",
      "Epoch 92/200\n",
      "37/37 - 0s - loss: 20.9677 - val_loss: 13.9257\n",
      "Epoch 93/200\n",
      "37/37 - 0s - loss: 19.3973 - val_loss: 16.8225\n",
      "Epoch 94/200\n",
      "37/37 - 0s - loss: 19.1196 - val_loss: 11.5219\n",
      "Epoch 95/200\n",
      "37/37 - 0s - loss: 20.0626 - val_loss: 13.8218\n",
      "Epoch 96/200\n",
      "37/37 - 0s - loss: 18.7605 - val_loss: 13.5986\n",
      "Epoch 97/200\n",
      "37/37 - 0s - loss: 21.2466 - val_loss: 20.1917\n",
      "Epoch 98/200\n",
      "37/37 - 0s - loss: 21.5788 - val_loss: 12.4350\n",
      "Epoch 99/200\n",
      "37/37 - 0s - loss: 21.2052 - val_loss: 15.6484\n",
      "Epoch 100/200\n",
      "37/37 - 0s - loss: 21.1513 - val_loss: 26.9160\n",
      "Epoch 101/200\n",
      "37/37 - 0s - loss: 22.1042 - val_loss: 17.1594\n",
      "Epoch 102/200\n",
      "37/37 - 0s - loss: 20.5107 - val_loss: 22.4137\n",
      "Epoch 103/200\n",
      "37/37 - 0s - loss: 22.6246 - val_loss: 15.0316\n",
      "Epoch 104/200\n",
      "37/37 - 0s - loss: 19.2612 - val_loss: 14.4975\n",
      "Epoch 105/200\n",
      "37/37 - 0s - loss: 18.9370 - val_loss: 13.7524\n",
      "Epoch 106/200\n",
      "37/37 - 0s - loss: 20.1493 - val_loss: 11.3636\n",
      "Epoch 107/200\n",
      "37/37 - 0s - loss: 18.9414 - val_loss: 13.2792\n",
      "Epoch 108/200\n",
      "37/37 - 0s - loss: 17.9174 - val_loss: 22.6246\n",
      "Epoch 109/200\n",
      "37/37 - 0s - loss: 27.0389 - val_loss: 19.4535\n",
      "Epoch 110/200\n",
      "37/37 - 0s - loss: 28.6158 - val_loss: 11.7356\n",
      "Epoch 111/200\n",
      "37/37 - 0s - loss: 18.7112 - val_loss: 13.4591\n",
      "Epoch 112/200\n",
      "37/37 - 0s - loss: 18.0311 - val_loss: 11.1683\n",
      "Epoch 113/200\n",
      "37/37 - 0s - loss: 18.2721 - val_loss: 12.9266\n",
      "Epoch 114/200\n",
      "37/37 - 0s - loss: 20.8536 - val_loss: 11.0599\n",
      "Epoch 115/200\n",
      "37/37 - 0s - loss: 20.9298 - val_loss: 15.7800\n",
      "Epoch 116/200\n",
      "37/37 - 0s - loss: 22.3845 - val_loss: 11.8079\n",
      "Epoch 117/200\n",
      "37/37 - 0s - loss: 24.6511 - val_loss: 13.2014\n",
      "Epoch 118/200\n",
      "37/37 - 0s - loss: 19.6550 - val_loss: 20.3879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "37/37 - 0s - loss: 21.4501 - val_loss: 13.3031\n",
      "Epoch 120/200\n",
      "37/37 - 0s - loss: 16.8130 - val_loss: 17.3249\n",
      "Epoch 121/200\n",
      "37/37 - 0s - loss: 17.9071 - val_loss: 13.0979\n",
      "Epoch 122/200\n",
      "37/37 - 0s - loss: 22.4864 - val_loss: 14.9233\n",
      "Epoch 123/200\n",
      "37/37 - 0s - loss: 19.7568 - val_loss: 19.7230\n",
      "Epoch 124/200\n",
      "37/37 - 0s - loss: 23.1305 - val_loss: 11.3389\n",
      "Epoch 125/200\n",
      "37/37 - 0s - loss: 19.9766 - val_loss: 13.9330\n",
      "Epoch 126/200\n",
      "37/37 - 0s - loss: 18.1922 - val_loss: 10.4718\n",
      "Epoch 127/200\n",
      "37/37 - 0s - loss: 19.0371 - val_loss: 12.6316\n",
      "Epoch 128/200\n",
      "37/37 - 0s - loss: 21.2779 - val_loss: 16.7985\n",
      "Epoch 129/200\n",
      "37/37 - 0s - loss: 18.0726 - val_loss: 13.8360\n",
      "Epoch 130/200\n",
      "37/37 - 0s - loss: 19.7267 - val_loss: 10.4323\n",
      "Epoch 131/200\n",
      "37/37 - 0s - loss: 21.3219 - val_loss: 13.9982\n",
      "Epoch 132/200\n",
      "37/37 - 0s - loss: 23.2764 - val_loss: 16.9507\n",
      "Epoch 133/200\n",
      "37/37 - 0s - loss: 21.3691 - val_loss: 10.6773\n",
      "Epoch 134/200\n",
      "37/37 - 0s - loss: 17.4990 - val_loss: 13.2722\n",
      "Epoch 135/200\n",
      "37/37 - 0s - loss: 19.6190 - val_loss: 12.0137\n",
      "Epoch 136/200\n",
      "37/37 - 0s - loss: 18.6841 - val_loss: 11.4485\n",
      "Epoch 137/200\n",
      "37/37 - 0s - loss: 19.7827 - val_loss: 10.5067\n",
      "Epoch 138/200\n",
      "37/37 - 0s - loss: 19.8407 - val_loss: 11.0605\n",
      "Epoch 139/200\n",
      "37/37 - 0s - loss: 18.0543 - val_loss: 12.8806\n",
      "Epoch 140/200\n",
      "37/37 - 0s - loss: 17.4951 - val_loss: 12.1377\n",
      "Epoch 141/200\n",
      "37/37 - 0s - loss: 16.4713 - val_loss: 10.9088\n",
      "Epoch 142/200\n",
      "37/37 - 0s - loss: 19.8608 - val_loss: 22.9481\n",
      "Epoch 143/200\n",
      "37/37 - 0s - loss: 21.6770 - val_loss: 13.1364\n",
      "Epoch 144/200\n",
      "37/37 - 0s - loss: 19.8993 - val_loss: 14.8145\n",
      "Epoch 145/200\n",
      "37/37 - 0s - loss: 16.7356 - val_loss: 12.7445\n",
      "Epoch 146/200\n",
      "37/37 - 0s - loss: 18.9041 - val_loss: 12.1867\n",
      "Epoch 147/200\n",
      "37/37 - 0s - loss: 21.4688 - val_loss: 23.0689\n",
      "Epoch 148/200\n",
      "37/37 - 0s - loss: 18.4145 - val_loss: 13.4190\n",
      "Epoch 149/200\n",
      "37/37 - 0s - loss: 17.9095 - val_loss: 14.0431\n",
      "Epoch 150/200\n",
      "37/37 - 0s - loss: 21.7170 - val_loss: 11.4683\n",
      "Epoch 151/200\n",
      "37/37 - 0s - loss: 15.8814 - val_loss: 9.5256\n",
      "Epoch 152/200\n",
      "37/37 - 0s - loss: 16.8065 - val_loss: 13.7117\n",
      "Epoch 153/200\n",
      "37/37 - 0s - loss: 19.0876 - val_loss: 10.8707\n",
      "Epoch 154/200\n",
      "37/37 - 0s - loss: 15.8846 - val_loss: 14.5141\n",
      "Epoch 155/200\n",
      "37/37 - 0s - loss: 17.8119 - val_loss: 12.9961\n",
      "Epoch 156/200\n",
      "37/37 - 0s - loss: 18.4562 - val_loss: 23.5388\n",
      "Epoch 157/200\n",
      "37/37 - 0s - loss: 23.4918 - val_loss: 12.6222\n",
      "Epoch 158/200\n",
      "37/37 - 0s - loss: 17.1302 - val_loss: 12.7302\n",
      "Epoch 159/200\n",
      "37/37 - 0s - loss: 18.5124 - val_loss: 11.4524\n",
      "Epoch 160/200\n",
      "37/37 - 0s - loss: 18.5995 - val_loss: 16.6788\n",
      "Epoch 161/200\n",
      "37/37 - 0s - loss: 18.1317 - val_loss: 9.9223\n",
      "Epoch 162/200\n",
      "37/37 - 0s - loss: 18.0327 - val_loss: 10.7877\n",
      "Epoch 163/200\n",
      "37/37 - 0s - loss: 19.0904 - val_loss: 13.7036\n",
      "Epoch 164/200\n",
      "37/37 - 0s - loss: 15.6114 - val_loss: 11.6684\n",
      "Epoch 165/200\n",
      "37/37 - 0s - loss: 17.8555 - val_loss: 13.8290\n",
      "Epoch 166/200\n",
      "37/37 - 0s - loss: 15.9922 - val_loss: 11.9725\n",
      "Epoch 167/200\n",
      "37/37 - 0s - loss: 16.3500 - val_loss: 14.7602\n",
      "Epoch 168/200\n",
      "37/37 - 0s - loss: 17.7480 - val_loss: 12.2342\n",
      "Epoch 169/200\n",
      "37/37 - 0s - loss: 17.4914 - val_loss: 10.3668\n",
      "Epoch 170/200\n",
      "37/37 - 0s - loss: 16.7221 - val_loss: 14.2058\n",
      "Epoch 171/200\n",
      "37/37 - 0s - loss: 16.6844 - val_loss: 12.7709\n",
      "Epoch 172/200\n",
      "37/37 - 0s - loss: 16.3349 - val_loss: 11.0750\n",
      "Epoch 173/200\n",
      "37/37 - 0s - loss: 16.2899 - val_loss: 10.2540\n",
      "Epoch 174/200\n",
      "37/37 - 0s - loss: 16.5895 - val_loss: 11.4197\n",
      "Epoch 175/200\n",
      "37/37 - 0s - loss: 19.1894 - val_loss: 16.6722\n",
      "Epoch 176/200\n",
      "37/37 - 0s - loss: 18.5434 - val_loss: 10.7575\n",
      "Epoch 177/200\n",
      "37/37 - 0s - loss: 15.9250 - val_loss: 16.9780\n",
      "Epoch 178/200\n",
      "37/37 - 0s - loss: 16.5739 - val_loss: 11.7800\n",
      "Epoch 179/200\n",
      "37/37 - 0s - loss: 17.6676 - val_loss: 11.9936\n",
      "Epoch 180/200\n",
      "37/37 - 0s - loss: 16.9483 - val_loss: 12.0046\n",
      "Epoch 181/200\n",
      "37/37 - 0s - loss: 16.3617 - val_loss: 21.8800\n",
      "Epoch 182/200\n",
      "37/37 - 0s - loss: 17.6781 - val_loss: 11.2338\n",
      "Epoch 183/200\n",
      "37/37 - 0s - loss: 16.0198 - val_loss: 13.1939\n",
      "Epoch 184/200\n",
      "37/37 - 0s - loss: 15.3948 - val_loss: 14.4576\n",
      "Epoch 185/200\n",
      "37/37 - 0s - loss: 20.9538 - val_loss: 11.1385\n",
      "Epoch 186/200\n",
      "37/37 - 0s - loss: 17.4011 - val_loss: 20.0046\n",
      "Epoch 187/200\n",
      "37/37 - 0s - loss: 20.0075 - val_loss: 15.2580\n",
      "Epoch 188/200\n",
      "37/37 - 0s - loss: 17.1587 - val_loss: 12.4653\n",
      "Epoch 189/200\n",
      "37/37 - 0s - loss: 19.4922 - val_loss: 16.4210\n",
      "Epoch 190/200\n",
      "37/37 - 0s - loss: 16.9932 - val_loss: 11.1450\n",
      "Epoch 191/200\n",
      "37/37 - 0s - loss: 15.2829 - val_loss: 13.8966\n",
      "Epoch 192/200\n",
      "37/37 - 0s - loss: 18.0428 - val_loss: 12.2410\n",
      "Epoch 193/200\n",
      "37/37 - 0s - loss: 17.6539 - val_loss: 15.5425\n",
      "Epoch 194/200\n",
      "37/37 - 0s - loss: 18.9602 - val_loss: 10.1981\n",
      "Epoch 195/200\n",
      "37/37 - 0s - loss: 15.3522 - val_loss: 14.7899\n",
      "Epoch 196/200\n",
      "37/37 - 0s - loss: 15.5412 - val_loss: 14.7235\n",
      "Epoch 197/200\n",
      "37/37 - 0s - loss: 14.8974 - val_loss: 15.4540\n",
      "Epoch 198/200\n",
      "37/37 - 0s - loss: 16.7387 - val_loss: 10.3768\n",
      "Epoch 199/200\n",
      "37/37 - 0s - loss: 15.6861 - val_loss: 10.3084\n",
      "Epoch 200/200\n",
      "37/37 - 0s - loss: 17.5359 - val_loss: 16.6244\n",
      "Real Price: 21.500, Predicted Price: 20.873\n",
      "Real Price: 50.000, Predicted Price: 44.534\n",
      "Real Price: 15.200, Predicted Price: 15.717\n",
      "Real Price: 24.300, Predicted Price: 19.450\n",
      "Real Price: 25.000, Predicted Price: 16.647\n",
      "Real Price: 24.800, Predicted Price: 25.033\n",
      "Real Price: 17.600, Predicted Price: 17.297\n",
      "Real Price: 13.500, Predicted Price: 9.342\n",
      "Real Price: 24.800, Predicted Price: 25.774\n",
      "Real Price: 20.300, Predicted Price: 20.644\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#       Regression \n",
    "#       A training program with keras\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "np.random.seed(34)\n",
    "random.seed(56)\n",
    "df = pd.read_csv('C:/Users/ihlee/testAI/scikitlearn_keras_examples/housing.csv', delim_whitespace=True, header=None)\n",
    "data_set = df.values\n",
    "X = data_set[:, 0:13]\n",
    "Y = data_set[:, 13]\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.2)\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#model.fit(X_train, Y_train, epochs=200, batch_size=10)\n",
    "model.fit(X_train, Y_train, validation_split=0.10, epochs=200, batch_size=10, verbose=2)\n",
    "Y_prediction = model.predict(X_validation).flatten()\n",
    "for i in range(10):\n",
    "    real_price = Y_validation[i]\n",
    "    predicted_price = Y_prediction[i]\n",
    "    print('Real Price: {:.3f}, Predicted Price: {:.3f}'.format(real_price, predicted_price))\n",
    "if True:\n",
    "#        serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "#        serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regression load and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:33:26.956795Z",
     "start_time": "2022-06-24T02:33:26.779261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Real Price: 21.500, Predicted Price: 20.873\n",
      "Real Price: 50.000, Predicted Price: 44.534\n",
      "Real Price: 15.200, Predicted Price: 15.717\n",
      "Real Price: 24.300, Predicted Price: 19.450\n",
      "Real Price: 25.000, Predicted Price: 16.647\n",
      "Real Price: 24.800, Predicted Price: 25.033\n",
      "Real Price: 17.600, Predicted Price: 17.297\n",
      "Real Price: 13.500, Predicted Price: 9.342\n",
      "Real Price: 24.800, Predicted Price: 25.774\n",
      "Real Price: 20.300, Predicted Price: 20.644\n"
     ]
    }
   ],
   "source": [
    "#       Regression \n",
    "#       A prediction program with keras\n",
    "from keras.models import model_from_json\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "np.random.seed(34)\n",
    "random.seed(56)\n",
    "df = pd.read_csv('C:/Users/ihlee/testAI/scikitlearn_keras_examples/housing.csv', delim_whitespace=True, header=None)\n",
    "data_set = df.values\n",
    "X = data_set[:, 0:13]\n",
    "Y = data_set[:, 13]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "if True:\n",
    "#         load json and create model\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "#         load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "loaded_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "Y_prediction = loaded_model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "     real_price = Y_test[i]\n",
    "     predicted_price = Y_prediction[i]\n",
    "     print('Real Price: {:.3f}, Predicted Price: {:.3f}'.format(real_price, predicted_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:33:34.185379Z",
     "start_time": "2022-06-24T02:33:26.958779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 4,675\n",
      "Trainable params: 4,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.2769 - accuracy: 0.3667 - val_loss: 1.3776 - val_accuracy: 0.2000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0326 - accuracy: 0.3667 - val_loss: 1.0716 - val_accuracy: 0.2667\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8939 - accuracy: 0.5917 - val_loss: 0.8865 - val_accuracy: 0.5667\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7964 - accuracy: 0.6917 - val_loss: 0.7996 - val_accuracy: 0.5667\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7410 - accuracy: 0.6917 - val_loss: 0.7508 - val_accuracy: 0.5667\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6968 - accuracy: 0.7500 - val_loss: 0.6992 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6524 - accuracy: 0.7167 - val_loss: 0.6664 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6083 - accuracy: 0.7500 - val_loss: 0.6209 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5684 - accuracy: 0.8250 - val_loss: 0.5900 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5355 - accuracy: 0.8250 - val_loss: 0.5695 - val_accuracy: 0.6333\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5072 - accuracy: 0.8000 - val_loss: 0.5479 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4810 - accuracy: 0.8250 - val_loss: 0.5247 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4588 - accuracy: 0.8500 - val_loss: 0.4920 - val_accuracy: 0.7333\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4402 - accuracy: 0.9167 - val_loss: 0.4675 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4252 - accuracy: 0.9167 - val_loss: 0.4666 - val_accuracy: 0.7333\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4041 - accuracy: 0.9083 - val_loss: 0.4490 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3887 - accuracy: 0.9333 - val_loss: 0.4250 - val_accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3763 - accuracy: 0.9667 - val_loss: 0.4093 - val_accuracy: 0.8667\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3601 - accuracy: 0.9667 - val_loss: 0.4026 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3466 - accuracy: 0.9500 - val_loss: 0.4018 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3363 - accuracy: 0.9417 - val_loss: 0.3884 - val_accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3237 - accuracy: 0.9583 - val_loss: 0.3637 - val_accuracy: 0.9333\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3110 - accuracy: 0.9750 - val_loss: 0.3566 - val_accuracy: 0.9333\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2993 - accuracy: 0.9750 - val_loss: 0.3527 - val_accuracy: 0.9333\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2888 - accuracy: 0.9667 - val_loss: 0.3467 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2782 - accuracy: 0.9667 - val_loss: 0.3363 - val_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2703 - accuracy: 0.9750 - val_loss: 0.3161 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2572 - accuracy: 0.9750 - val_loss: 0.3162 - val_accuracy: 0.9333\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2487 - accuracy: 0.9750 - val_loss: 0.3175 - val_accuracy: 0.9333\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2401 - accuracy: 0.9750 - val_loss: 0.3024 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2321 - accuracy: 0.9750 - val_loss: 0.2848 - val_accuracy: 0.9333\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2242 - accuracy: 0.9750 - val_loss: 0.2760 - val_accuracy: 0.9333\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2154 - accuracy: 0.9750 - val_loss: 0.2790 - val_accuracy: 0.9333\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2071 - accuracy: 0.9750 - val_loss: 0.2682 - val_accuracy: 0.9333\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2001 - accuracy: 0.9750 - val_loss: 0.2585 - val_accuracy: 0.9333\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1939 - accuracy: 0.9833 - val_loss: 0.2445 - val_accuracy: 0.9667\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1878 - accuracy: 0.9750 - val_loss: 0.2465 - val_accuracy: 0.9333\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1820 - accuracy: 0.9750 - val_loss: 0.2458 - val_accuracy: 0.9333\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1746 - accuracy: 0.9750 - val_loss: 0.2318 - val_accuracy: 0.9667\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1718 - accuracy: 0.9833 - val_loss: 0.2179 - val_accuracy: 0.9667\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1654 - accuracy: 0.9750 - val_loss: 0.2257 - val_accuracy: 0.9333\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1598 - accuracy: 0.9750 - val_loss: 0.2217 - val_accuracy: 0.9333\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1579 - accuracy: 0.9750 - val_loss: 0.2225 - val_accuracy: 0.9333\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1508 - accuracy: 0.9750 - val_loss: 0.2020 - val_accuracy: 0.9667\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1493 - accuracy: 0.9750 - val_loss: 0.1929 - val_accuracy: 0.9667\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1448 - accuracy: 0.9833 - val_loss: 0.2038 - val_accuracy: 0.9333\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1407 - accuracy: 0.9750 - val_loss: 0.1956 - val_accuracy: 0.9667\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1363 - accuracy: 0.9750 - val_loss: 0.1931 - val_accuracy: 0.9667\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1337 - accuracy: 0.9750 - val_loss: 0.1828 - val_accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1297 - accuracy: 0.9750 - val_loss: 0.1821 - val_accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1262 - accuracy: 0.9750 - val_loss: 0.1739 - val_accuracy: 0.9667\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1253 - accuracy: 0.9750 - val_loss: 0.1684 - val_accuracy: 0.9667\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1216 - accuracy: 0.9833 - val_loss: 0.1659 - val_accuracy: 0.9667\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1189 - accuracy: 0.9750 - val_loss: 0.1760 - val_accuracy: 0.9667\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1177 - accuracy: 0.9750 - val_loss: 0.1599 - val_accuracy: 0.9667\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1139 - accuracy: 0.9833 - val_loss: 0.1559 - val_accuracy: 0.9667\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1136 - accuracy: 0.9750 - val_loss: 0.1562 - val_accuracy: 0.9667\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1098 - accuracy: 0.9750 - val_loss: 0.1544 - val_accuracy: 0.9667\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1103 - accuracy: 0.9750 - val_loss: 0.1469 - val_accuracy: 0.9667\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1060 - accuracy: 0.9750 - val_loss: 0.1510 - val_accuracy: 0.9667\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1056 - accuracy: 0.9750 - val_loss: 0.1549 - val_accuracy: 0.9667\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1053 - accuracy: 0.9750 - val_loss: 0.1433 - val_accuracy: 0.9667\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1006 - accuracy: 0.9833 - val_loss: 0.1339 - val_accuracy: 0.9667\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1019 - accuracy: 0.9833 - val_loss: 0.1326 - val_accuracy: 0.9667\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0999 - accuracy: 0.9833 - val_loss: 0.1360 - val_accuracy: 0.9667\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0987 - accuracy: 0.9750 - val_loss: 0.1346 - val_accuracy: 0.9667\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0970 - accuracy: 0.9750 - val_loss: 0.1324 - val_accuracy: 0.9667\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0978 - accuracy: 0.9750 - val_loss: 0.1368 - val_accuracy: 0.9667\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0970 - accuracy: 0.9833 - val_loss: 0.1244 - val_accuracy: 0.9667\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0953 - accuracy: 0.9833 - val_loss: 0.1247 - val_accuracy: 0.9667\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0921 - accuracy: 0.9833 - val_loss: 0.1319 - val_accuracy: 0.9667\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.1372 - val_accuracy: 0.9667\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0929 - accuracy: 0.9750 - val_loss: 0.1285 - val_accuracy: 0.9667\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0911 - accuracy: 0.9833 - val_loss: 0.1168 - val_accuracy: 0.9667\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0958 - accuracy: 0.9833 - val_loss: 0.1225 - val_accuracy: 0.9667\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0880 - accuracy: 0.9833 - val_loss: 0.1107 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0901 - accuracy: 0.9750 - val_loss: 0.1100 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0884 - accuracy: 0.9833 - val_loss: 0.1146 - val_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0887 - accuracy: 0.9750 - val_loss: 0.1233 - val_accuracy: 0.9667\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0897 - accuracy: 0.9750 - val_loss: 0.1198 - val_accuracy: 0.9667\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0987 - accuracy: 0.9583 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0883 - accuracy: 0.9833 - val_loss: 0.1148 - val_accuracy: 0.9667\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9750 - val_loss: 0.1183 - val_accuracy: 0.9667\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0857 - accuracy: 0.9750 - val_loss: 0.1052 - val_accuracy: 0.9667\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0838 - accuracy: 0.9833 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0840 - accuracy: 0.9750 - val_loss: 0.1023 - val_accuracy: 0.9667\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0844 - accuracy: 0.9750 - val_loss: 0.1149 - val_accuracy: 0.9667\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0852 - accuracy: 0.9750 - val_loss: 0.1031 - val_accuracy: 0.9667\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9750 - val_loss: 0.1008 - val_accuracy: 0.9667\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0814 - accuracy: 0.9833 - val_loss: 0.0974 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9750 - val_loss: 0.1006 - val_accuracy: 0.9667\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0808 - accuracy: 0.9750 - val_loss: 0.0994 - val_accuracy: 0.9667\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9833 - val_loss: 0.0934 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0802 - accuracy: 0.9833 - val_loss: 0.0974 - val_accuracy: 0.9667\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0799 - accuracy: 0.9833 - val_loss: 0.1040 - val_accuracy: 0.9667\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0800 - accuracy: 0.9750 - val_loss: 0.0977 - val_accuracy: 0.9667\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0812 - accuracy: 0.9750 - val_loss: 0.0899 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0808 - accuracy: 0.9750 - val_loss: 0.0910 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0841 - accuracy: 0.9750 - val_loss: 0.1096 - val_accuracy: 0.9667\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0813 - accuracy: 0.9750 - val_loss: 0.0912 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0912 - accuracy: 0.9667\n",
      "Accuracy = 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.95      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0  6]]\n",
      "Predicted target name: ['setosa']\n",
      "Predicted target name: ['versicolor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihlee\\anaconda3\\envs\\testAI\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "g = sns.pairplot(iris, hue=\"species\", palette=\"husl\")\n",
    "iris.info()\n",
    "iris['species'].unique()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = iris.iloc[:,0:4].values\n",
    "y = iris.iloc[:,4].values\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "Y = pd.get_dummies(y1).values\n",
    "print(Y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,  test_size=0.2, random_state=1) \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64,input_shape=(4,),activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.legend(['loss','val_loss', 'acc','val_acc'])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))\n",
    "test_set = np.array([[5, 2.9, 1, 0.2]])\n",
    "print(\"Predicted target name: {}\".format(iris['species'].unique()[model.predict_classes(test_set)]))\n",
    "iris.query(\"species == 'versicolor'\")\n",
    "test_set = np.array([[7, 3.0, 5, 1.4]])\n",
    "print(\"Predicted target name: {}\".format(iris['species'].unique()[model.predict_classes(test_set)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:33:42.771938Z",
     "start_time": "2022-06-24T02:33:34.187335Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 1us/step\n",
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ] 15.2\n",
      "[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426\n",
      "  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713\n",
      "  0.8252202 ]\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                144       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 574.8666 - mae: 22.1637 - val_loss: 642.8423 - val_mae: 23.6189\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 566.6696 - mae: 21.9484 - val_loss: 635.4238 - val_mae: 23.4445\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 559.7704 - mae: 21.7666 - val_loss: 627.8436 - val_mae: 23.2615\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 552.5136 - mae: 21.5695 - val_loss: 619.8347 - val_mae: 23.0647\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 544.7308 - mae: 21.3594 - val_loss: 611.0704 - val_mae: 22.8500\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 536.1263 - mae: 21.1275 - val_loss: 601.5319 - val_mae: 22.6136\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 526.7908 - mae: 20.8694 - val_loss: 590.7660 - val_mae: 22.3401\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 516.1630 - mae: 20.5715 - val_loss: 578.9678 - val_mae: 22.0289\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 504.6004 - mae: 20.2339 - val_loss: 566.5722 - val_mae: 21.6981\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 492.7355 - mae: 19.8699 - val_loss: 553.6786 - val_mae: 21.3661\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 480.0051 - mae: 19.4918 - val_loss: 540.2441 - val_mae: 21.0052\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 467.0891 - mae: 19.0802 - val_loss: 526.6975 - val_mae: 20.6154\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 453.7499 - mae: 18.6785 - val_loss: 512.7054 - val_mae: 20.2184\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 440.1935 - mae: 18.2780 - val_loss: 497.7066 - val_mae: 19.8039\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 426.1348 - mae: 17.8853 - val_loss: 483.3318 - val_mae: 19.3995\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 412.3221 - mae: 17.4795 - val_loss: 467.7958 - val_mae: 18.9979\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 397.5674 - mae: 17.0459 - val_loss: 452.3188 - val_mae: 18.6003\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 383.1011 - mae: 16.6617 - val_loss: 435.4249 - val_mae: 18.1698\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 368.4412 - mae: 16.2827 - val_loss: 421.6192 - val_mae: 17.8382\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 355.1616 - mae: 15.9530 - val_loss: 406.9200 - val_mae: 17.4980\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 341.2508 - mae: 15.6221 - val_loss: 390.6921 - val_mae: 17.1277\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 326.2968 - mae: 15.2610 - val_loss: 372.8876 - val_mae: 16.7018\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 310.3755 - mae: 14.8562 - val_loss: 355.7471 - val_mae: 16.2821\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 294.7033 - mae: 14.4761 - val_loss: 338.8987 - val_mae: 15.8565\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 279.3955 - mae: 14.0597 - val_loss: 321.8285 - val_mae: 15.4103\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 263.3890 - mae: 13.6191 - val_loss: 302.4821 - val_mae: 14.8795\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 246.0318 - mae: 13.1289 - val_loss: 283.9068 - val_mae: 14.3411\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 229.4116 - mae: 12.6336 - val_loss: 264.8971 - val_mae: 13.7633\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 212.4025 - mae: 12.0888 - val_loss: 245.3148 - val_mae: 13.1272\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 195.0753 - mae: 11.4900 - val_loss: 226.7668 - val_mae: 12.4920\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 179.2111 - mae: 10.8954 - val_loss: 209.9923 - val_mae: 11.8796\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 164.1880 - mae: 10.3631 - val_loss: 192.8028 - val_mae: 11.2092\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 149.6292 - mae: 9.7860 - val_loss: 177.4469 - val_mae: 10.6249\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 136.6951 - mae: 9.2777 - val_loss: 164.3134 - val_mae: 10.1052\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 125.1947 - mae: 8.8046 - val_loss: 151.1444 - val_mae: 9.5728\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 114.1764 - mae: 8.2910 - val_loss: 140.0000 - val_mae: 9.1260\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 104.7017 - mae: 7.8841 - val_loss: 126.7519 - val_mae: 8.6125\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 94.7136 - mae: 7.4213 - val_loss: 118.1332 - val_mae: 8.2731\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 88.0256 - mae: 7.0881 - val_loss: 108.7818 - val_mae: 7.8997\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 81.2789 - mae: 6.7758 - val_loss: 102.5444 - val_mae: 7.6232\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 76.4029 - mae: 6.4832 - val_loss: 96.6826 - val_mae: 7.3684\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 71.9853 - mae: 6.2370 - val_loss: 91.0666 - val_mae: 7.1498\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 68.0223 - mae: 6.0078 - val_loss: 85.1639 - val_mae: 6.9773\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 63.9821 - mae: 5.8010 - val_loss: 80.6489 - val_mae: 6.8384\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 61.0234 - mae: 5.6307 - val_loss: 76.1051 - val_mae: 6.7052\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 57.9551 - mae: 5.4759 - val_loss: 71.6168 - val_mae: 6.5280\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 55.2393 - mae: 5.3268 - val_loss: 68.7763 - val_mae: 6.3592\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 53.1490 - mae: 5.1957 - val_loss: 65.6105 - val_mae: 6.2133\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 51.0660 - mae: 5.0803 - val_loss: 62.7929 - val_mae: 5.9809\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 48.9767 - mae: 4.9610 - val_loss: 60.2563 - val_mae: 5.8606\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 47.1260 - mae: 4.8505 - val_loss: 57.6379 - val_mae: 5.7251\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 45.0731 - mae: 4.7448 - val_loss: 54.7676 - val_mae: 5.5922\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step - loss: 43.1404 - mae: 4.6567 - val_loss: 52.5991 - val_mae: 5.4609\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 41.6087 - mae: 4.5738 - val_loss: 50.0545 - val_mae: 5.3346\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 39.6724 - mae: 4.4665 - val_loss: 47.6754 - val_mae: 5.2136\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 38.1465 - mae: 4.3879 - val_loss: 46.0450 - val_mae: 5.0988\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 36.8183 - mae: 4.3228 - val_loss: 44.1010 - val_mae: 4.9880\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 35.4116 - mae: 4.2337 - val_loss: 42.3088 - val_mae: 4.8990\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 34.1543 - mae: 4.1710 - val_loss: 40.6511 - val_mae: 4.7868\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 32.8561 - mae: 4.0955 - val_loss: 39.5371 - val_mae: 4.7055\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 32.0333 - mae: 4.0280 - val_loss: 38.3484 - val_mae: 4.6563\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 31.2415 - mae: 3.9957 - val_loss: 37.3566 - val_mae: 4.5838\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 30.4070 - mae: 3.9363 - val_loss: 36.1981 - val_mae: 4.4962\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 29.5691 - mae: 3.8662 - val_loss: 35.1226 - val_mae: 4.4450\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 28.8368 - mae: 3.8251 - val_loss: 34.3405 - val_mae: 4.3765\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 28.1389 - mae: 3.7797 - val_loss: 33.1019 - val_mae: 4.3371\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 27.3776 - mae: 3.7503 - val_loss: 32.4600 - val_mae: 4.3182\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 26.8858 - mae: 3.7168 - val_loss: 31.9198 - val_mae: 4.2824\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 26.4469 - mae: 3.6971 - val_loss: 31.2351 - val_mae: 4.2259\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 25.9489 - mae: 3.6565 - val_loss: 30.5174 - val_mae: 4.1723\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 25.5022 - mae: 3.6243 - val_loss: 29.6905 - val_mae: 4.1032\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 24.8622 - mae: 3.5903 - val_loss: 29.1325 - val_mae: 4.0554\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 24.5104 - mae: 3.5546 - val_loss: 28.6030 - val_mae: 4.0234\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 24.1311 - mae: 3.5383 - val_loss: 28.1118 - val_mae: 4.0037\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 23.6574 - mae: 3.5189 - val_loss: 27.5421 - val_mae: 3.9742\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 23.3607 - mae: 3.4958 - val_loss: 27.0393 - val_mae: 3.9209\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 22.9667 - mae: 3.4868 - val_loss: 26.7608 - val_mae: 3.8828\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.7253 - mae: 3.4640 - val_loss: 26.4662 - val_mae: 3.8574\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.5211 - mae: 3.4461 - val_loss: 26.1337 - val_mae: 3.8609\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.2229 - mae: 3.4487 - val_loss: 25.6397 - val_mae: 3.8190\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 21.9778 - mae: 3.4168 - val_loss: 25.1952 - val_mae: 3.8287\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 21.6082 - mae: 3.4052 - val_loss: 24.8793 - val_mae: 3.7978\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 21.4006 - mae: 3.3914 - val_loss: 24.5865 - val_mae: 3.7903\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 21.2043 - mae: 3.3796 - val_loss: 24.4928 - val_mae: 3.7875\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 21.0319 - mae: 3.3901 - val_loss: 24.1600 - val_mae: 3.7452\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.8054 - mae: 3.3728 - val_loss: 23.7713 - val_mae: 3.6940\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.6130 - mae: 3.3331 - val_loss: 23.5907 - val_mae: 3.6873\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.3857 - mae: 3.3307 - val_loss: 23.0533 - val_mae: 3.6004\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.1926 - mae: 3.2957 - val_loss: 22.8476 - val_mae: 3.5854\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.0405 - mae: 3.2819 - val_loss: 22.7008 - val_mae: 3.5871\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 19.8285 - mae: 3.2639 - val_loss: 22.5709 - val_mae: 3.5906\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 19.6735 - mae: 3.2577 - val_loss: 22.5364 - val_mae: 3.6170\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 19.5551 - mae: 3.2544 - val_loss: 22.5083 - val_mae: 3.6234\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 19.2825 - mae: 3.2573 - val_loss: 22.4225 - val_mae: 3.6064\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 19.1910 - mae: 3.2635 - val_loss: 22.1132 - val_mae: 3.5786\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 19.0275 - mae: 3.2323 - val_loss: 21.7677 - val_mae: 3.5239\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.8865 - mae: 3.2148 - val_loss: 21.5023 - val_mae: 3.4880\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 18.7008 - mae: 3.1956 - val_loss: 21.1804 - val_mae: 3.4517\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.5628 - mae: 3.1735 - val_loss: 20.8777 - val_mae: 3.4283\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.3348 - mae: 3.1448 - val_loss: 20.7301 - val_mae: 3.4295\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 28.1708 - mae: 4.1534\n",
      "[[15.640486]\n",
      " [39.35023 ]]\n",
      "[15.2 42.3]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "# let us view on sample from the features\n",
    "print(X_train[0], y_train[0])\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# first we fit the scaler on the training dataset\n",
    "scaler.fit(X_train)\n",
    "# then we call the transform method to scale both the training and testing data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# a sample output\n",
    "print(X_train_scaled[0])\n",
    "from keras import models, layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=[X_train.shape[1]]))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.summary()\n",
    "# output layer\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=100)\n",
    "model.evaluate(X_test_scaled, y_test)\n",
    "# output\n",
    "# [26.68399990306181, 3.7581424339144838]\n",
    "# we get a sample data (the first 2 inputs from the training data)\n",
    "to_predict = X_train_scaled[:2]\n",
    "# we call the predict method\n",
    "predictions = model.predict(to_predict)\n",
    "# print the predictions\n",
    "print(predictions)\n",
    "# output\n",
    "# array([[13.272537], [39.808475]], dtype=float32)\n",
    "# print the real values\n",
    "print(y_train[:2])\n",
    "# array([15.2, 42.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:33:46.915173Z",
     "start_time": "2022-06-24T02:33:42.772944Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 15, saw 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7144/1123939.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 15, saw 5\n"
     ]
    }
   ],
   "source": [
    "# mlp for regression\n",
    "from numpy import sqrt\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df = read_csv(path, header=None)\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "n_features = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))\n",
    "# make a prediction\n",
    "row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM  Long Short-Term Memory layer - Hochreiter 1997.\n",
    "RNN(Recurrent Neural Network, 순환신경망)은 시퀀스 데이터를 모델링 하기 위해 등장\n",
    "이미지를 텍스트로 설명해주는 모델\n",
    "글의 번역기와 네이버의 파파고는 RNN을 응용한 모델\n",
    "RNN 기반 모델은 기존 통계 기반 모델의 비해 우수한 성능\n",
    "RNN을 통해서 영화 대본을 짜는 실험\n",
    "시퀀스 입력 & 시퀀스 출력 구조를 갖고 있습니다. 이 구조의 모델을 다른 말로 encoder-decoder 모델\n",
    "RNN은 히든 노드가 방향을 가진 엣지로 연결돼 순환구조를 이루는(directed cycle) 인공신경망의 한 종류입니다. 음성, 문자 등 순차적으로 등장하는 데이터 처리에 적합한 모델로 알려져 있는데요. Convolutional Neural Networks(CNN)과 더불어 최근 들어 각광 받고 있는 알고리즘입니다.\n",
    "예컨대 ‘h’의 다음 정답은 ‘e’, ‘e’ 다음은 ‘l’, ‘l’ 다음은 ‘l’, ‘l’ 다음은 ‘o’가 정답입니다.\n",
    "STM은 RNN의 히든 state에 cell-state를 추가한 구조입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:35:15.768266Z",
     "start_time": "2022-06-24T02:35:15.159403Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihlee\\AppData\\Local\\Temp/ipykernel_7144/766703848.py:24: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  df = read_csv(path, header=0, index_col=0, squeeze=True)\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 15, saw 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7144/766703848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# load the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# retrieve the values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 15, saw 5\n"
     ]
    }
   ],
   "source": [
    "# lstm for time series forecasting\n",
    "from numpy import sqrt\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return asarray(X), asarray(y)\n",
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\n",
    "df = read_csv(path, header=0, index_col=0, squeeze=True)\n",
    "# retrieve the values\n",
    "values = df.values.astype('float32')\n",
    "# specify the window size\n",
    "n_steps = 5\n",
    "# split into samples\n",
    "X, y = split_sequence(values, n_steps)\n",
    "# reshape into [samples, timesteps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "# split into train/test\n",
    "n_test = 12\n",
    "X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_steps,1)))\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit(X_train, y_train, epochs=350, batch_size=32, verbose=2, validation_data=(X_test, y_test))\n",
    "mse, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))\n",
    "# make a prediction\n",
    "row = asarray([18024.0, 16722.0, 14385.0, 21342.0, 17180.0]).reshape((1, n_steps, 1))\n",
    "yhat = model.predict(row)\n",
    "print('Predicted: %.3f' % (yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testAI",
   "language": "python",
   "name": "testai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
