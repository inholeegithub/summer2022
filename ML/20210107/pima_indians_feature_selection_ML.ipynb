{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.353 0.744 0.59  0.354 0.    0.501 0.234 0.483]\n",
      " [0.059 0.427 0.541 0.293 0.    0.396 0.117 0.167]\n",
      " [0.471 0.92  0.525 0.    0.    0.347 0.254 0.183]\n",
      " [0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n",
      " [0.    0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "#     Rescale data (between 0 and 1)\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "filename = 'C:/Users/In-Ho Lee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "#     separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "#     summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
      " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
      " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
     ]
    }
   ],
   "source": [
    "#     Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "filename = 'C:/Users/In-Ho Lee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "#     separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "#     summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n",
      " [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n",
      " [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n",
      " [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n",
      " [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n"
     ]
    }
   ],
   "source": [
    "#     Normalize data (length of 1)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "filename = 'C:/Users/In-Ho Lee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "#     separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "#     summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(normalizedX[0:5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#     binarization\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "filename = 'C:/Users/In-Ho Lee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "#     separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "#     summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(binaryX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 중요하다고 생각되는 특징데이터만 선택하여 특징데이터의 종류를 줄이기 위한 방법\n",
    "https://machinelearningmastery.com/feature-selection-machine-learning-python/\n",
    "\n",
    "4 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 111.52  1411.887   17.605   53.108 2175.565  127.669    5.393  181.304]\n",
      "[[148.    0.   33.6  50. ]\n",
      " [ 85.    0.   26.6  31. ]\n",
      " [183.    0.   23.3  32. ]\n",
      " [ 89.   94.   28.1  21. ]\n",
      " [137.  168.   43.1  33. ]]\n"
     ]
    }
   ],
   "source": [
    "#     Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "#      load data\n",
    "filename = 'C:/Users/In-Ho Lee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "#     feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "#     summarize scores\n",
    "# set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "#     summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features:  3\n",
      "Selected Features: [ True False False False False  True  True False]\n",
      "Feature Ranking: [1 2 4 5 6 1 1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=3 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#     Feature Extraction with RFE     Recursive Feature Elimination\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#     load data\n",
    "filename = 'C:/Users/In-Ho Lee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "#     feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: \", fit.n_features_)\n",
    "print(\"Selected Features:\",  fit.support_)\n",
    "print(\"Feature Ranking:\",  fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  [0.889 0.062 0.026]\n",
      "[[-2.022e-03  9.781e-02  1.609e-02  6.076e-02  9.931e-01  1.401e-02\n",
      "   5.372e-04 -3.565e-03]\n",
      " [-2.265e-02 -9.722e-01 -1.419e-01  5.786e-02  9.463e-02 -4.697e-02\n",
      "  -8.168e-04 -1.402e-01]\n",
      " [-2.246e-02  1.434e-01 -9.225e-01 -3.070e-01  2.098e-02 -1.324e-01\n",
      "  -6.400e-04 -1.255e-01]]\n"
     ]
    }
   ],
   "source": [
    "#     Feature Extraction with PCA\n",
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA\n",
    "#     load data\n",
    "filename = 'C:/Users/In-Ho Lee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "#     feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "#     summarize components\n",
    "print(\"Explained Variance: \",  fit.explained_variance_ratio_)\n",
    "print(fit.components_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.107 0.242 0.098 0.08  0.075 0.138 0.12  0.14 ]\n"
     ]
    }
   ],
   "source": [
    "#     Feature Importance with Extra Trees Classifier\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#     load data\n",
    "filename = 'C:/Users/In-Ho Lee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "#     feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/spot-check-machine-learning-algorithms-in-python/\n",
    "무작위 추출 조사\n",
    "\n",
    "마우스 캡처 --> 탭 --> 시프트 탭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 53 models\n",
      ">logistic: 0.848 (+/-0.034)\n",
      ">ridge-0.1: 0.845 (+/-0.038)\n",
      ">ridge-0.2: 0.845 (+/-0.038)\n",
      ">ridge-0.3: 0.845 (+/-0.038)\n",
      ">ridge-0.4: 0.845 (+/-0.038)\n",
      ">ridge-0.5: 0.845 (+/-0.038)\n",
      ">ridge-0.6: 0.845 (+/-0.038)\n",
      ">ridge-0.7: 0.846 (+/-0.039)\n",
      ">ridge-0.8: 0.847 (+/-0.039)\n",
      ">ridge-0.9: 0.847 (+/-0.039)\n",
      ">ridge-1.0: 0.847 (+/-0.039)\n",
      ">sgd: 0.824 (+/-0.036)\n",
      ">pa: 0.809 (+/-0.058)\n",
      ">knn-1: 0.726 (+/-0.040)\n",
      ">knn-2: 0.688 (+/-0.026)\n",
      ">knn-3: 0.741 (+/-0.036)\n",
      ">knn-4: 0.726 (+/-0.027)\n",
      ">knn-5: 0.768 (+/-0.035)\n",
      ">knn-6: 0.755 (+/-0.028)\n",
      ">knn-7: 0.769 (+/-0.038)\n",
      ">knn-8: 0.761 (+/-0.045)\n",
      ">knn-9: 0.772 (+/-0.042)\n",
      ">knn-10: 0.765 (+/-0.040)\n",
      ">knn-11: 0.781 (+/-0.043)\n",
      ">knn-12: 0.780 (+/-0.045)\n",
      ">knn-13: 0.789 (+/-0.036)\n",
      ">knn-14: 0.788 (+/-0.036)\n",
      ">knn-15: 0.800 (+/-0.045)\n",
      ">knn-16: 0.791 (+/-0.039)\n",
      ">knn-17: 0.799 (+/-0.027)\n",
      ">knn-18: 0.796 (+/-0.031)\n",
      ">knn-19: 0.799 (+/-0.033)\n",
      ">knn-20: 0.801 (+/-0.035)\n",
      ">cart: 0.792 (+/-0.038)\n",
      ">extra: 0.715 (+/-0.048)\n",
      ">svml: 0.841 (+/-0.035)\n",
      ">svmp: 0.810 (+/-0.048)\n",
      ">svmr0.1: 0.827 (+/-0.034)\n",
      ">svmr0.2: 0.837 (+/-0.031)\n",
      ">svmr0.3: 0.840 (+/-0.032)\n",
      ">svmr0.4: 0.840 (+/-0.035)\n",
      ">svmr0.5: 0.847 (+/-0.034)\n",
      ">svmr0.6: 0.847 (+/-0.037)\n",
      ">svmr0.7: 0.849 (+/-0.039)\n",
      ">svmr0.8: 0.850 (+/-0.038)\n",
      ">svmr0.9: 0.849 (+/-0.039)\n",
      ">svmr1.0: 0.849 (+/-0.038)\n",
      ">bayes: 0.816 (+/-0.035)\n",
      ">ada: 0.839 (+/-0.031)\n",
      ">bag: 0.853 (+/-0.046)\n",
      ">rf: 0.862 (+/-0.034)\n",
      ">et: 0.864 (+/-0.034)\n",
      ">gbm: 0.866 (+/-0.044)\n",
      "\n",
      "Rank=1, Name=gbm, Score=0.866 (+/- 0.044)\n",
      "Rank=2, Name=et, Score=0.864 (+/- 0.034)\n",
      "Rank=3, Name=rf, Score=0.862 (+/- 0.034)\n",
      "Rank=4, Name=bag, Score=0.853 (+/- 0.046)\n",
      "Rank=5, Name=svmr0.8, Score=0.850 (+/- 0.038)\n",
      "Rank=6, Name=svmr1.0, Score=0.849 (+/- 0.038)\n",
      "Rank=7, Name=svmr0.9, Score=0.849 (+/- 0.039)\n",
      "Rank=8, Name=svmr0.7, Score=0.849 (+/- 0.039)\n",
      "Rank=9, Name=logistic, Score=0.848 (+/- 0.034)\n",
      "Rank=10, Name=svmr0.6, Score=0.847 (+/- 0.037)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# binary classification spot check script\n",
    "import warnings\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# load the dataset, returns X and y elements\n",
    "def load_dataset():\n",
    "    return make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "\n",
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "\t# linear models\n",
    "\tmodels['logistic'] = LogisticRegression()\n",
    "\talpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\tfor a in alpha:\n",
    "\t\tmodels['ridge-'+str(a)] = RidgeClassifier(alpha=a)\n",
    "\tmodels['sgd'] = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\tmodels['pa'] = PassiveAggressiveClassifier(max_iter=1000, tol=1e-3)\n",
    "\t# non-linear models\n",
    "\tn_neighbors = range(1, 21)\n",
    "\tfor k in n_neighbors:\n",
    "\t\tmodels['knn-'+str(k)] = KNeighborsClassifier(n_neighbors=k)\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['extra'] = ExtraTreeClassifier()\n",
    "\tmodels['svml'] = SVC(kernel='linear')\n",
    "\tmodels['svmp'] = SVC(kernel='poly')\n",
    "\tc_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\tfor c in c_values:\n",
    "\t\tmodels['svmr'+str(c)] = SVC(C=c)\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\t# ensemble models\n",
    "\tn_trees = 100\n",
    "\tmodels['ada'] = AdaBoostClassifier(n_estimators=n_trees)\n",
    "\tmodels['bag'] = BaggingClassifier(n_estimators=n_trees)\n",
    "\tmodels['rf'] = RandomForestClassifier(n_estimators=n_trees)\n",
    "\tmodels['et'] = ExtraTreesClassifier(n_estimators=n_trees)\n",
    "\tmodels['gbm'] = GradientBoostingClassifier(n_estimators=n_trees)\n",
    "\tprint('Defined %d models' % len(models))\n",
    "\treturn models\n",
    "\n",
    "# create a feature preparation pipeline for a model\n",
    "def make_pipeline(model):\n",
    "\tsteps = list()\n",
    "\t# standardization\n",
    "\tsteps.append(('standardize', StandardScaler()))\n",
    "\t# normalization\n",
    "\tsteps.append(('normalize', MinMaxScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric):\n",
    "\t# create the pipeline\n",
    "\tpipeline = make_pipeline(model)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# evaluate a model and try to trap errors and and hide warnings\n",
    "def robust_evaluate_model(X, y, model, folds, metric):\n",
    "\tscores = None\n",
    "\ttry:\n",
    "\t\twith warnings.catch_warnings():\n",
    "\t\t\twarnings.filterwarnings(\"ignore\")\n",
    "\t\t\tscores = evaluate_model(X, y, model, folds, metric)\n",
    "\texcept:\n",
    "\t\tscores = None\n",
    "\treturn scores\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, folds=10, metric='accuracy'):\n",
    "\tresults = dict()\n",
    "\tfor name, model in models.items():\n",
    "\t\t# evaluate the model\n",
    "\t\tscores = robust_evaluate_model(X, y, model, folds, metric)\n",
    "\t\t# show process\n",
    "\t\tif scores is not None:\n",
    "\t\t\t# store a result\n",
    "\t\t\tresults[name] = scores\n",
    "\t\t\tmean_score, std_score = mean(scores), std(scores)\n",
    "\t\t\tprint('>%s: %.3f (+/-%.3f)' % (name, mean_score, std_score))\n",
    "\t\telse:\n",
    "\t\t\tprint('>%s: error' % name)\n",
    "\treturn results\n",
    "\n",
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=True, top_n=10):\n",
    "\t# check for no results\n",
    "\tif len(results) == 0:\n",
    "\t\tprint('no results')\n",
    "\t\treturn\n",
    "\t# determine how many results to summarize\n",
    "\tn = min(top_n, len(results))\n",
    "\t# create a list of (name, mean(scores)) tuples\n",
    "\tmean_scores = [(k,mean(v)) for k,v in results.items()]\n",
    "\t# sort tuples by mean score\n",
    "\tmean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "\t# reverse for descending order (e.g. for accuracy)\n",
    "\tif maximize:\n",
    "\t\tmean_scores = list(reversed(mean_scores))\n",
    "\t# retrieve the top n for summarization\n",
    "\tnames = [x[0] for x in mean_scores[:n]]\n",
    "\tscores = [results[x[0]] for x in mean_scores[:n]]\n",
    "\t# print the top n\n",
    "\tprint()\n",
    "\tfor i in range(n):\n",
    "\t\tname = names[i]\n",
    "\t\tmean_score, std_score = mean(results[name]), std(results[name])\n",
    "\t\tprint('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' % (i+1, name, mean_score, std_score))\n",
    "\t# boxplot for the top n\n",
    "\tpyplot.boxplot(scores, labels=names)\n",
    "\t_, labels = pyplot.xticks()\n",
    "\tpyplot.setp(labels, rotation=90)\n",
    "\tpyplot.savefig('C:/Users/In-Ho Lee/testAI/spotcheck.png')\n",
    "\n",
    "# load dataset\n",
    "X, y = load_dataset()\n",
    "# get model list\n",
    "models = define_models()\n",
    "# evaluate models\n",
    "results = evaluate_models(X, y, models)\n",
    "# summarize results\n",
    "summarize_results(results)\n",
    "\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.model_selection import KFold\n",
    "# #     Spot-Check Algorithms\n",
    "# models = []\n",
    "# models.append(('LR', LogisticRegression()))\n",
    "# models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# models.append(('KNN', KNeighborsClassifier()))\n",
    "# models.append(('CART', DecisionTreeClassifier()))\n",
    "# models.append(('NB', GaussianNB()))\n",
    "# models.append(('SVM', SVC()))\n",
    "# #     evaluate each model in turn\n",
    "# results = []\n",
    "# names = []\n",
    "# for name, model in models:\n",
    "#     kfold = KFold(n_splits=10, shuffle=True, random_state=77)\n",
    "#     cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#     print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.0 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.1 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.2 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.3 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.4 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.6 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.7 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.8 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=0.9 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\In-Ho Lee\\.conda\\envs\\testAI\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass l1_ratio=1.0 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 190 models\n",
      ">lr: -0.011 (+/-0.001)\n",
      ">lasso-0.0: -0.011 (+/-0.001)\n",
      ">lasso-0.1: -4.756 (+/-0.808)\n",
      ">lasso-0.2: -18.996 (+/-3.268)\n",
      ">lasso-0.3: -42.730 (+/-7.379)\n",
      ">lasso-0.4: -75.957 (+/-13.144)\n",
      ">lasso-0.5: -118.679 (+/-20.561)\n",
      ">lasso-0.6: -170.895 (+/-29.631)\n",
      ">lasso-0.7: -232.605 (+/-40.354)\n",
      ">lasso-0.8: -303.810 (+/-52.729)\n",
      ">lasso-0.9: -384.509 (+/-66.757)\n",
      ">lasso-1.0: -474.701 (+/-82.438)\n",
      ">ridge-0.0: -0.011 (+/-0.001)\n",
      ">ridge-0.1: -0.902 (+/-0.167)\n",
      ">ridge-0.2: -3.534 (+/-0.668)\n",
      ">ridge-0.3: -7.847 (+/-1.492)\n",
      ">ridge-0.4: -13.780 (+/-2.628)\n",
      ">ridge-0.5: -21.277 (+/-4.064)\n",
      ">ridge-0.6: -30.283 (+/-5.788)\n",
      ">ridge-0.7: -40.744 (+/-7.790)\n",
      ">ridge-0.8: -52.610 (+/-10.059)\n",
      ">ridge-0.9: -65.831 (+/-12.586)\n",
      ">ridge-1.0: -80.359 (+/-15.361)\n",
      ">en-0.0-0.0: -0.011 (+/-0.001)\n",
      ">en-0.0-0.1: -0.011 (+/-0.001)\n",
      ">en-0.0-0.2: -0.011 (+/-0.001)\n",
      ">en-0.0-0.3: -0.011 (+/-0.001)\n",
      ">en-0.0-0.4: -0.011 (+/-0.001)\n",
      ">en-0.0-0.5: -0.011 (+/-0.001)\n",
      ">en-0.0-0.6: -0.011 (+/-0.001)\n",
      ">en-0.0-0.7: -0.011 (+/-0.001)\n",
      ">en-0.0-0.8: -0.011 (+/-0.001)\n",
      ">en-0.0-0.9: -0.011 (+/-0.001)\n",
      ">en-0.0-1.0: -0.011 (+/-0.001)\n",
      ">en-0.1-0.0: -19635.111 (+/-3395.451)\n",
      ">en-0.1-0.1: -18906.123 (+/-3275.718)\n",
      ">en-0.1-0.2: -18052.723 (+/-3135.107)\n",
      ">en-0.1-0.3: -17040.802 (+/-2967.784)\n",
      ">en-0.1-0.4: -15822.998 (+/-2765.387)\n",
      ">en-0.1-0.5: -14332.198 (+/-2515.878)\n",
      ">en-0.1-0.6: -12471.327 (+/-2201.595)\n",
      ">en-0.1-0.7: -10100.282 (+/-1796.747)\n",
      ">en-0.1-0.8: -7033.457 (+/-1265.969)\n",
      ">en-0.1-0.9: -3170.692 (+/-580.494)\n",
      ">en-0.1-1.0: -4.756 (+/-0.808)\n",
      ">en-0.2-0.0: -23567.698 (+/-4030.526)\n",
      ">en-0.2-0.1: -23079.263 (+/-3951.314)\n",
      ">en-0.2-0.2: -22490.923 (+/-3855.750)\n",
      ">en-0.2-0.3: -21768.873 (+/-3738.175)\n",
      ">en-0.2-0.4: -20861.672 (+/-3589.976)\n",
      ">en-0.2-0.5: -19687.958 (+/-3396.972)\n",
      ">en-0.2-0.6: -18112.145 (+/-3135.876)\n",
      ">en-0.2-0.7: -15890.529 (+/-2765.333)\n",
      ">en-0.2-0.8: -12547.410 (+/-2202.432)\n",
      ">en-0.2-0.9: -7116.206 (+/-1268.099)\n",
      ">en-0.2-1.0: -18.996 (+/-3.268)\n",
      ">en-0.3-0.0: -25160.296 (+/-4284.521)\n",
      ">en-0.3-0.1: -24800.003 (+/-4226.181)\n",
      ">en-0.3-0.2: -24361.278 (+/-4155.073)\n",
      ">en-0.3-0.3: -23815.315 (+/-4066.424)\n",
      ">en-0.3-0.4: -23117.170 (+/-3952.164)\n",
      ">en-0.3-0.5: -22193.163 (+/-3800.204)\n",
      ">en-0.3-0.6: -20913.503 (+/-3589.444)\n",
      ">en-0.3-0.7: -19024.823 (+/-3277.626)\n",
      ">en-0.3-0.8: -15968.424 (+/-2768.736)\n",
      ">en-0.3-0.9: -10277.647 (+/-1805.660)\n",
      ">en-0.3-1.0: -42.730 (+/-7.379)\n",
      ">en-0.4-0.0: -26021.593 (+/-4421.147)\n",
      ">en-0.4-0.1: -25737.921 (+/-4375.117)\n",
      ">en-0.4-0.2: -25390.543 (+/-4318.739)\n",
      ">en-0.4-0.3: -24955.061 (+/-4247.546)\n",
      ">en-0.4-0.4: -24393.030 (+/-4155.062)\n",
      ">en-0.4-0.5: -23640.200 (+/-4031.347)\n",
      ">en-0.4-0.6: -22578.406 (+/-3857.204)\n",
      ">en-0.4-0.7: -20970.171 (+/-3592.574)\n",
      ">en-0.4-0.8: -18252.335 (+/-3142.595)\n",
      ">en-0.4-0.9: -12738.343 (+/-2216.894)\n",
      ">en-0.4-1.0: -75.957 (+/-13.144)\n",
      ">en-0.5-0.0: -26561.113 (+/-4506.470)\n",
      ">en-0.5-0.1: -26328.065 (+/-4468.524)\n",
      ">en-0.5-0.2: -26041.702 (+/-4421.862)\n",
      ">en-0.5-0.3: -25681.164 (+/-4362.291)\n",
      ">en-0.5-0.4: -25213.433 (+/-4285.171)\n",
      ">en-0.5-0.5: -24581.450 (+/-4181.446)\n",
      ">en-0.5-0.6: -23680.368 (+/-4033.692)\n",
      ">en-0.5-0.7: -22291.911 (+/-3805.502)\n",
      ">en-0.5-0.8: -19878.145 (+/-3407.581)\n",
      ">en-0.5-0.9: -14677.565 (+/-2537.253)\n",
      ">en-0.5-1.0: -118.679 (+/-20.561)\n",
      ">en-0.6-0.0: -26930.765 (+/-4564.815)\n",
      ">en-0.6-0.1: -26733.564 (+/-4532.574)\n",
      ">en-0.6-0.2: -26490.750 (+/-4492.644)\n",
      ">en-0.6-0.3: -26184.271 (+/-4441.692)\n",
      ">en-0.6-0.4: -25785.096 (+/-4375.715)\n",
      ">en-0.6-0.5: -25242.656 (+/-4286.769)\n",
      ">en-0.6-0.6: -24463.135 (+/-4158.770)\n",
      ">en-0.6-0.7: -23248.261 (+/-3959.495)\n",
      ">en-0.6-0.8: -21091.657 (+/-3603.278)\n",
      ">en-0.6-0.9: -16238.518 (+/-2794.559)\n",
      ">en-0.6-1.0: -170.895 (+/-29.631)\n",
      ">en-0.7-0.0: -27199.852 (+/-4607.229)\n",
      ">en-0.7-0.1: -27029.339 (+/-4579.215)\n",
      ">en-0.7-0.2: -26819.155 (+/-4544.278)\n",
      ">en-0.7-0.3: -26553.463 (+/-4499.906)\n",
      ">en-0.7-0.4: -26206.141 (+/-4442.610)\n",
      ">en-0.7-0.5: -25732.412 (+/-4364.561)\n",
      ">en-0.7-0.6: -25048.146 (+/-4252.386)\n",
      ">en-0.7-0.7: -23971.438 (+/-4075.191)\n",
      ">en-0.7-0.8: -22031.580 (+/-3754.765)\n",
      ">en-0.7-0.9: -17519.651 (+/-3005.100)\n",
      ">en-0.7-1.0: -232.605 (+/-40.354)\n",
      ">en-0.8-0.0: -27404.494 (+/-4639.452)\n",
      ">en-0.8-0.1: -27254.624 (+/-4614.698)\n",
      ">en-0.8-0.2: -27069.767 (+/-4583.644)\n",
      ">en-0.8-0.3: -26835.847 (+/-4544.435)\n",
      ">en-0.8-0.4: -26529.250 (+/-4493.791)\n",
      ">en-0.8-0.5: -26109.966 (+/-4424.768)\n",
      ">en-0.8-0.6: -25501.394 (+/-4324.780)\n",
      ">en-0.8-0.7: -24537.682 (+/-4165.742)\n",
      ">en-0.8-0.8: -22781.445 (+/-3875.836)\n",
      ">en-0.8-0.9: -18588.484 (+/-3180.842)\n",
      ">en-0.8-1.0: -303.810 (+/-52.729)\n",
      ">en-0.9-0.0: -27565.366 (+/-4664.763)\n",
      ">en-0.9-0.1: -27431.937 (+/-4642.604)\n",
      ">en-0.9-0.2: -27267.325 (+/-4614.664)\n",
      ">en-0.9-0.3: -27058.767 (+/-4579.707)\n",
      ">en-0.9-0.4: -26784.986 (+/-4534.286)\n",
      ">en-0.9-0.5: -26409.883 (+/-4472.550)\n",
      ">en-0.9-0.6: -25863.151 (+/-4382.199)\n",
      ">en-0.9-0.7: -24993.183 (+/-4238.602)\n",
      ">en-0.9-0.8: -23394.354 (+/-3974.742)\n",
      ">en-0.9-0.9: -19492.825 (+/-3328.396)\n",
      ">en-0.9-1.0: -384.509 (+/-66.757)\n",
      ">en-1.0-0.0: -27695.152 (+/-4685.171)\n",
      ">en-1.0-0.1: -27575.112 (+/-4665.114)\n",
      ">en-1.0-0.2: -27427.092 (+/-4639.759)\n",
      ">en-1.0-0.3: -27239.294 (+/-4608.249)\n",
      ">en-1.0-0.4: -26992.542 (+/-4567.298)\n",
      ">en-1.0-0.5: -26653.630 (+/-4511.312)\n",
      ">en-1.0-0.6: -26158.725 (+/-4429.369)\n",
      ">en-1.0-0.7: -25368.138 (+/-4298.861)\n",
      ">en-1.0-0.8: -23904.654 (+/-4057.544)\n",
      ">en-1.0-0.9: -20267.558 (+/-3454.520)\n",
      ">en-1.0-1.0: -474.701 (+/-82.438)\n",
      ">huber: -0.011 (+/-0.002)\n",
      ">lars: -0.011 (+/-0.001)\n",
      ">llars: -6818.447 (+/-1183.737)\n",
      ">pa: -0.014 (+/-0.004)\n",
      ">ranscac: -0.011 (+/-0.001)\n",
      ">sgd: -1959.404 (+/-595.652)\n",
      ">theil: -0.011 (+/-0.002)\n",
      ">knn-1: -30869.042 (+/-3905.159)\n",
      ">knn-2: -23313.703 (+/-4263.314)\n",
      ">knn-3: -21308.250 (+/-3942.296)\n",
      ">knn-4: -19989.521 (+/-3146.635)\n",
      ">knn-5: -19575.096 (+/-3217.275)\n",
      ">knn-6: -19077.575 (+/-2944.185)\n",
      ">knn-7: -18611.225 (+/-3059.335)\n",
      ">knn-8: -18616.046 (+/-2952.398)\n",
      ">knn-9: -18543.176 (+/-2781.085)\n",
      ">knn-10: -18480.473 (+/-2848.115)\n",
      ">knn-11: -18313.496 (+/-2777.947)\n",
      ">knn-12: -18455.572 (+/-2880.450)\n",
      ">knn-13: -18384.412 (+/-3073.738)\n",
      ">knn-14: -18375.317 (+/-2957.064)\n",
      ">knn-15: -18387.072 (+/-3092.035)\n",
      ">knn-16: -18370.580 (+/-3066.935)\n",
      ">knn-17: -18291.717 (+/-3018.298)\n",
      ">knn-18: -18304.525 (+/-2967.820)\n",
      ">knn-19: -18306.125 (+/-3035.414)\n",
      ">knn-20: -18310.841 (+/-3105.589)\n",
      ">cart: -16372.877 (+/-2546.322)\n",
      ">extra: -19401.670 (+/-3601.298)\n",
      ">svml: -23929.372 (+/-4041.658)\n",
      ">svmp: -216.677 (+/-68.782)\n",
      ">svmr0.1: -28841.475 (+/-4854.910)\n",
      ">svmr0.2: -28716.238 (+/-4835.799)\n",
      ">svmr0.3: -28590.896 (+/-4816.352)\n",
      ">svmr0.4: -28465.770 (+/-4797.115)\n",
      ">svmr0.5: -28340.765 (+/-4778.207)\n",
      ">svmr0.6: -28215.959 (+/-4759.141)\n",
      ">svmr0.7: -28092.578 (+/-4741.121)\n",
      ">svmr0.8: -27969.609 (+/-4723.518)\n",
      ">svmr0.9: -27848.012 (+/-4706.996)\n",
      ">svmr1.0: -27726.492 (+/-4690.390)\n",
      ">ada: -6134.765 (+/-1519.994)\n",
      ">bag: -6121.542 (+/-1514.610)\n",
      ">rf: -6119.851 (+/-1388.611)\n",
      ">et: -5033.012 (+/-992.193)\n",
      ">gbm: -2348.103 (+/-493.480)\n",
      "\n",
      "Rank=1, Name=lars, Score=-0.011 (+/- 0.001)\n",
      "Rank=2, Name=ranscac, Score=-0.011 (+/- 0.001)\n",
      "Rank=3, Name=lr, Score=-0.011 (+/- 0.001)\n",
      "Rank=4, Name=ridge-0.0, Score=-0.011 (+/- 0.001)\n",
      "Rank=5, Name=en-0.0-1.0, Score=-0.011 (+/- 0.001)\n",
      "Rank=6, Name=en-0.0-0.9, Score=-0.011 (+/- 0.001)\n",
      "Rank=7, Name=en-0.0-0.8, Score=-0.011 (+/- 0.001)\n",
      "Rank=8, Name=en-0.0-0.7, Score=-0.011 (+/- 0.001)\n",
      "Rank=9, Name=en-0.0-0.6, Score=-0.011 (+/- 0.001)\n",
      "Rank=10, Name=en-0.0-0.5, Score=-0.011 (+/- 0.001)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# regression spot check script\n",
    "import warnings\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# load the dataset, returns X and y elements\n",
    "def load_dataset():\n",
    "\treturn make_regression(n_samples=1000, n_features=50, noise=0.1, random_state=1)\n",
    "\n",
    "# create a dict of standard models to evaluate {name:object}\n",
    "def get_models(models=dict()):\n",
    "\t# linear models\n",
    "\tmodels['lr'] = LinearRegression()\n",
    "\talpha = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\tfor a in alpha:\n",
    "\t\tmodels['lasso-'+str(a)] = Lasso(alpha=a)\n",
    "\tfor a in alpha:\n",
    "\t\tmodels['ridge-'+str(a)] = Ridge(alpha=a)\n",
    "\tfor a1 in alpha:\n",
    "\t\tfor a2 in alpha:\n",
    "\t\t\tname = 'en-' + str(a1) + '-' + str(a2)\n",
    "\t\t\tmodels[name] = ElasticNet(a1, a2)\n",
    "\tmodels['huber'] = HuberRegressor()\n",
    "\tmodels['lars'] = Lars()\n",
    "\tmodels['llars'] = LassoLars()\n",
    "\tmodels['pa'] = PassiveAggressiveRegressor(max_iter=1000, tol=1e-3)\n",
    "\tmodels['ranscac'] = RANSACRegressor()\n",
    "\tmodels['sgd'] = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "\tmodels['theil'] = TheilSenRegressor()\n",
    "\t# non-linear models\n",
    "\tn_neighbors = range(1, 21)\n",
    "\tfor k in n_neighbors:\n",
    "\t\tmodels['knn-'+str(k)] = KNeighborsRegressor(n_neighbors=k)\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['extra'] = ExtraTreeRegressor()\n",
    "\tmodels['svml'] = SVR(kernel='linear')\n",
    "\tmodels['svmp'] = SVR(kernel='poly')\n",
    "\tc_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\tfor c in c_values:\n",
    "\t\tmodels['svmr'+str(c)] = SVR(C=c)\n",
    "\t# ensemble models\n",
    "\tn_trees = 100\n",
    "\tmodels['ada'] = AdaBoostRegressor(n_estimators=n_trees)\n",
    "\tmodels['bag'] = BaggingRegressor(n_estimators=n_trees)\n",
    "\tmodels['rf'] = RandomForestRegressor(n_estimators=n_trees)\n",
    "\tmodels['et'] = ExtraTreesRegressor(n_estimators=n_trees)\n",
    "\tmodels['gbm'] = GradientBoostingRegressor(n_estimators=n_trees)\n",
    "\tprint('Defined %d models' % len(models))\n",
    "\treturn models\n",
    "\n",
    "# create a feature preparation pipeline for a model\n",
    "def make_pipeline(model):\n",
    "\tsteps = list()\n",
    "\t# standardization\n",
    "\tsteps.append(('standardize', StandardScaler()))\n",
    "\t# normalization\n",
    "\tsteps.append(('normalize', MinMaxScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric):\n",
    "\t# create the pipeline\n",
    "\tpipeline = make_pipeline(model)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# evaluate a model and try to trap errors and and hide warnings\n",
    "def robust_evaluate_model(X, y, model, folds, metric):\n",
    "\tscores = None\n",
    "\ttry:\n",
    "\t\twith warnings.catch_warnings():\n",
    "\t\t\twarnings.filterwarnings(\"ignore\")\n",
    "\t\t\tscores = evaluate_model(X, y, model, folds, metric)\n",
    "\texcept:\n",
    "\t\tscores = None\n",
    "\treturn scores\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, folds=10, metric='accuracy'):\n",
    "\tresults = dict()\n",
    "\tfor name, model in models.items():\n",
    "\t\t# evaluate the model\n",
    "\t\tscores = robust_evaluate_model(X, y, model, folds, metric)\n",
    "\t\t# show process\n",
    "\t\tif scores is not None:\n",
    "\t\t\t# store a result\n",
    "\t\t\tresults[name] = scores\n",
    "\t\t\tmean_score, std_score = mean(scores), std(scores)\n",
    "\t\t\tprint('>%s: %.3f (+/-%.3f)' % (name, mean_score, std_score))\n",
    "\t\telse:\n",
    "\t\t\tprint('>%s: error' % name)\n",
    "\treturn results\n",
    "\n",
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=True, top_n=10):\n",
    "\t# check for no results\n",
    "\tif len(results) == 0:\n",
    "\t\tprint('no results')\n",
    "\t\treturn\n",
    "\t# determine how many results to summarize\n",
    "\tn = min(top_n, len(results))\n",
    "\t# create a list of (name, mean(scores)) tuples\n",
    "\tmean_scores = [(k,mean(v)) for k,v in results.items()]\n",
    "\t# sort tuples by mean score\n",
    "\tmean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "\t# reverse for descending order (e.g. for accuracy)\n",
    "\tif maximize:\n",
    "\t\tmean_scores = list(reversed(mean_scores))\n",
    "\t# retrieve the top n for summarization\n",
    "\tnames = [x[0] for x in mean_scores[:n]]\n",
    "\tscores = [results[x[0]] for x in mean_scores[:n]]\n",
    "\t# print the top n\n",
    "\tprint()\n",
    "\tfor i in range(n):\n",
    "\t\tname = names[i]\n",
    "\t\tmean_score, std_score = mean(results[name]), std(results[name])\n",
    "\t\tprint('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' % (i+1, name, mean_score, std_score))\n",
    "\t# boxplot for the top n\n",
    "\tpyplot.boxplot(scores, labels=names)\n",
    "\t_, labels = pyplot.xticks()\n",
    "\tpyplot.setp(labels, rotation=90)\n",
    "\tpyplot.savefig('spotcheck.png')\n",
    "\n",
    "# load dataset\n",
    "X, y = load_dataset()\n",
    "# get model list\n",
    "models = get_models()\n",
    "# evaluate models\n",
    "results = evaluate_models(X, y, models, metric='neg_mean_squared_error')\n",
    "# summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testAI",
   "language": "python",
   "name": "testai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
