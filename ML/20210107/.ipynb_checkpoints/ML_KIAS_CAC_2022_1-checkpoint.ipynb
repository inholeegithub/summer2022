{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656d8926",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/setup-python-environment-machine-learning-deep-learning-anaconda/\n",
    "\n",
    "\n",
    "pip install statsmodels\n",
    "\n",
    "download  --> *.py\n",
    "\n",
    "control shift -1\n",
    "\n",
    "a\n",
    "\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f1b799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:26:34.508602Z",
     "start_time": "2022-06-24T08:26:34.495594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3691459b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:26:44.548524Z",
     "start_time": "2022-06-24T08:26:34.510586Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihlee\\anaconda3\\envs\\testAI\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\ihlee\\anaconda3\\envs\\testAI\\lib\\site-packages\\numpy\\.libs\\libopenblas.el2c6ple4zyw3eceviv3oxxgrn2nrfm2.gfortran-win_amd64.dll\n",
      "C:\\Users\\ihlee\\anaconda3\\envs\\testAI\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.22.2\n",
      "matplotlib: 3.5.0\n",
      "pandas: 1.4.0\n",
      "scipy: 1.7.3\n",
      "sklearn: 1.0.2\n",
      "lightgbm: 3.2.1\n",
      "xgboost: 1.3.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihlee\\anaconda3\\envs\\testAI\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost: 0.26.1\n",
      "tensorflow: 2.5.0\n",
      "keras: 2.4.3\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)\n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "if False:\n",
    "# statsmodels\n",
    "    import statsmodels\n",
    "    print('statsmodels: %s' % statsmodels.__version__)\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)\n",
    "import lightgbm as lgb\n",
    "print('lightgbm: %s' % lgb.__version__)\n",
    "import xgboost\n",
    "print('xgboost: %s' % xgboost.__version__)\n",
    "import catboost\n",
    "print('catboost: %s' % catboost.__version__)\n",
    "import tensorflow\n",
    "print('tensorflow: %s' % tensorflow.__version__)\n",
    "import keras\n",
    "print('keras: %s' % keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77ab9e",
   "metadata": {},
   "source": [
    "conda install -c anaconda cudatoolkit\n",
    "conda install -c anaconda cudnn\n",
    "conda install -c anaconda tensorflow-gpu\n",
    "\n",
    "conda list cudatoolkit\n",
    "conda list cudnn\n",
    "\n",
    "nvidia-smi\n",
    "nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2477f414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:26:44.563488Z",
     "start_time": "2022-06-24T08:26:44.550512Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', 'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.29.30037/bin/HostX64/x64/cl.exe'), ('cuda_compute_capabilities', ['compute_35', 'compute_52', 'compute_60', 'compute_61', 'compute_70', 'compute_75', 'compute_80']), ('cuda_version', '64_113'), ('cudart_dll_name', 'cudart64_113.dll'), ('cudnn_dll_name', 'cudnn64_8.dll'), ('cudnn_version', '64_8'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False), ('msvcp_dll_names', 'msvcp140.dll,msvcp140_1.dll'), ('nvcuda_dll_name', 'nvcuda.dll')])\n",
      "64_113\n",
      "64_8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.python.platform.build_info as build\n",
    "print(build.build_info)\n",
    "print(build.build_info['cuda_version'])\n",
    "print(build.build_info['cudnn_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c9f331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:28:21.516285Z",
     "start_time": "2022-06-24T08:26:44.565485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 226968341540686984,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 1417120974\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 11491875923304165331\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecf997f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:28:21.546268Z",
     "start_time": "2022-06-24T08:28:21.518266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ihlee\\AppData\\Local\\Temp/ipykernel_25480/28396742.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())\n",
    "tf.config.experimental.list_physical_devices(device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd1f5bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:28:21.561241Z",
     "start_time": "2022-06-24T08:28:21.547248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "OrderedDict([('cpu_compiler', 'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.29.30037/bin/HostX64/x64/cl.exe'), ('cuda_compute_capabilities', ['compute_35', 'compute_52', 'compute_60', 'compute_61', 'compute_70', 'compute_75', 'compute_80']), ('cuda_version', '64_113'), ('cudart_dll_name', 'cudart64_113.dll'), ('cudnn_dll_name', 'cudnn64_8.dll'), ('cudnn_version', '64_8'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False), ('msvcp_dll_names', 'msvcp140.dll,msvcp140_1.dll'), ('nvcuda_dll_name', 'nvcuda.dll')])\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12065985142077046370\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1417120974\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15449055243195309282\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "import tensorflow.python.platform.build_info as build\n",
    "print(build.build_info)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n",
    "tf.test.is_built_with_cuda()\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "tf.config.list_physical_devices('CPU')\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a3429",
   "metadata": {},
   "source": [
    "GPU:n번을 사용하려면 번호를 n으로 설정.\n",
    "(아래 예시에서는 GPU:0번이 사용됩니다.)\n",
    "\n",
    "control-alt-del --> 성능 --> GPU usage/percentage, memory, temperature\n",
    "\n",
    "CPU 강제 사용: -1로 번호를 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b64d527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:28:21.576233Z",
     "start_time": "2022-06-24T08:28:21.562240Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2357c907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:28:25.294925Z",
     "start_time": "2022-06-24T08:28:21.578231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n",
      "Epoch 1/3\n",
      "67/67 [==============================] - 1s 6ms/step - loss: 246.4157 - accuracy: 0.1100\n",
      "Epoch 2/3\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.3023 - accuracy: 0.1125\n",
      "Epoch 3/3\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 2.3023 - accuracy: 0.1126\n",
      "GPU, batch_size dependent\n",
      "Epoch 1/3\n",
      "67/67 [==============================] - 1s 6ms/step - loss: 2.3053 - accuracy: 0.1126\n",
      "Epoch 2/3\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.3016 - accuracy: 0.1126\n",
      "Epoch 3/3\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.3014 - accuracy: 0.1126\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 넘파이 데이터를 텐서 데이터로 변환\n",
    "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "y_train = tf.one_hot(y_train, depth=len(np.unique(y_train)))\n",
    "y_test = tf.one_hot(y_test, depth=len(np.unique(y_train)))\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(), metrics=['accuracy'])\n",
    "\n",
    "print(\"CPU\")\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    model.fit(x_train, y_train, batch_size=900, epochs=3)\n",
    "\n",
    "print(\"GPU, batch_size dependent\")\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    model.fit(x_train, y_train, batch_size=900, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29646f",
   "metadata": {},
   "source": [
    "error message : mouse capture --> google --> stackoverflow.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60ca3c",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c54fe73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:28:29.388910Z",
     "start_time": "2022-06-24T08:28:25.299919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n",
      "(1000,)\n",
      "[ 3.09434646  1.51658079 -0.26702159 -1.93730608 -1.41636893  2.10574155\n",
      "  3.84636834 -2.2513449  -0.61542662 -5.39583947 -0.48939403 -1.21989079\n",
      "  0.92764958  1.61863108  0.79314288  0.1984768  -2.9673391  -0.81177834\n",
      " -1.7756556   3.61202634]\n",
      "1\n",
      "Accuracy: 0.867 (0.031)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a logistic regression model using repeated k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[10,:])\n",
    "print(y[10])\n",
    "# prepare the cross-validation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348fc260",
   "metadata": {},
   "source": [
    "mouse capture, tab, shift tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd92bd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:28:33.528926Z",
     "start_time": "2022-06-24T08:28:29.390124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 mean=0.8680 se=0.011\n",
      ">2 mean=0.8675 se=0.008\n",
      ">3 mean=0.8673 se=0.006\n",
      ">4 mean=0.8670 se=0.006\n",
      ">5 mean=0.8658 se=0.005\n",
      ">6 mean=0.8655 se=0.004\n",
      ">7 mean=0.8651 se=0.004\n",
      ">8 mean=0.8651 se=0.004\n",
      ">9 mean=0.8656 se=0.003\n",
      ">10 mean=0.8658 se=0.003\n",
      ">11 mean=0.8655 se=0.003\n",
      ">12 mean=0.8654 se=0.003\n",
      ">13 mean=0.8652 se=0.003\n",
      ">14 mean=0.8651 se=0.003\n",
      ">15 mean=0.8653 se=0.003\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare the number of repeats for repeated k-fold cross-validation\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# evaluate a model with a given number of repeats\n",
    "def evaluate_model(X, y, repeats):\n",
    "\t# prepare the cross-validation procedure\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "\t# create model\n",
    "\tmodel = LogisticRegression()\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# configurations to test\n",
    "repeats = range(1,16)\n",
    "results = list()\n",
    "for r in repeats:\n",
    "    # evaluate using a given number of repeats\n",
    "    scores = evaluate_model(X, y, r)\n",
    "    # summarize\n",
    "    print('>%d mean=%.4f se=%.3f' % (r, mean(scores), sem(scores)))\n",
    "    # store\n",
    "    results.append(scores)\n",
    "# plot the results\n",
    "pyplot.boxplot(results, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00516d00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T08:28:33.783772Z",
     "start_time": "2022-06-24T08:28:33.530913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot of blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue', 2:'green'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d999f8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (1000, 2)\n",
      "(100, 3) (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# develop an MLP for blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "# generate 2D classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)\n",
    "print(trainy.shape, testy.shape)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=500, verbose=0)\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# learning curves of model accuracy\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2dc38",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.552Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "import matplotlib.pyplot as plt\n",
    "# Make data: Two circles on x-y plane as a classification problem\n",
    "X, y = make_circles(n_samples=1000, factor=0.5, noise=0.1)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "plt.show()\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "model = Sequential([\n",
    "    Input(shape=(2,)),\n",
    "    Dense(5, \"relu\"),\n",
    "    Dense(1, \"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X, y, batch_size=32, epochs=100, verbose=0)\n",
    "print(model.evaluate(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed079895",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.556Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(2,)),\n",
    "    Dense(5, \"sigmoid\"),\n",
    "    Dense(5, \"sigmoid\"),\n",
    "    Dense(5, \"sigmoid\"),\n",
    "    Dense(1, \"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X, y, batch_size=32, epochs=100, verbose=0)\n",
    "print(model.evaluate(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca7878",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.559Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(2,)),\n",
    "    Dense(5, \"relu\"),\n",
    "    Dense(5, \"relu\"),\n",
    "    Dense(5, \"relu\"),\n",
    "    Dense(1, \"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X, y, batch_size=32, epochs=100, verbose=0)\n",
    "print(model.evaluate(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69584680",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.562Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "#from keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(learning_rate=0.1)\n",
    "#model.compile(loss='binary_crossentropy', optimizer=sgd)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, y, batch_size=1, epochs=100)\n",
    "#print(model.predict_proba(X))\n",
    "print(model.predict(X).round())\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(weights)\n",
    "\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482c82c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.565Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "#from keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=2, activation='tanh'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.1))\n",
    "model.fit(X, y, batch_size=1, epochs=500)\n",
    "#print(model.predict_proba(X))\n",
    "print(model.predict(X).round())\n",
    "\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(weights)\n",
    "\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfc7c8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.570Z"
    }
   },
   "outputs": [],
   "source": [
    "#     MLP with dropout on the two circles dataset\n",
    "from sklearn.datasets import make_circles\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "#     generate 2D classification dataset\n",
    "X, y = make_circles(n_samples=200, noise=0.1, random_state=1)\n",
    "#     split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape,testX.shape)\n",
    "print(trainy.shape,testy.shape)\n",
    "#     define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#     fit model\n",
    "history = model.fit(trainX,trainy,validation_data=(testX,testy),epochs=8000,verbose=0)\n",
    "#     evaluate the model\n",
    "_, train_acc = model.evaluate(trainX,trainy,verbose=0)\n",
    "_, test_acc = model.evaluate(testX,testy,verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc,test_acc))\n",
    "#     plot history\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ac36b",
   "metadata": {},
   "source": [
    "maxnorm(m) will, if the L2-Norm of your weights exceeds m, scale your whole weight matrix by a factor that reduces the norm to m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ddf348",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.578Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Example of dropout on the sonar dataset: hidden layer\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "#from keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "#     load dataset\n",
    "dataframe = read_csv(\"C:/Users/ihlee/testAI/scikitlearn_keras_examples/sonar.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "#     split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]\n",
    "#     encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "#     dropout in hidden layers with weight constraint\n",
    "def create_model():\n",
    "    #     create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60,input_dim=60, activation='relu',kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(30,activation='relu',kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #     Compile model\n",
    "    sgd = SGD(lr=0.1,momentum=0.9)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp',KerasClassifier(build_fn=create_model,epochs=300,batch_size=16,verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Hidden: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211c481",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fecfd6d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.583Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of saving sub-models for later use in a stacking ensemble\n",
    "from sklearn.datasets import make_blobs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "from os import makedirs\n",
    "# stacked generalization with neural net meta model on blobs dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers.merge import concatenate\n",
    "from numpy import argmax\n",
    "# load models from file\n",
    "def load_all_models(n_models):\n",
    "        all_models = list()\n",
    "        for i in range(n_models):\n",
    "                # define filename for this ensemble\n",
    "                filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "                # load model from file\n",
    "                model = load_model(filename)\n",
    "                # add to list of members\n",
    "                all_models.append(model)\n",
    "                print('>loaded %s' % filename)\n",
    "        return all_models\n",
    "# define stacked model from multiple member input models\n",
    "def define_stacked_model(members):\n",
    "        # update all layers in all models to not be trainable\n",
    "        for i in range(len(members)):\n",
    "                model = members[i]\n",
    "                for layer in model.layers:\n",
    "                        # make not trainable\n",
    "                        layer.trainable = False\n",
    "                        # rename to avoid 'unique layer name' issue\n",
    "                        layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
    "        # define multi-headed input\n",
    "        ensemble_visible = [model.input for model in members]\n",
    "        # concatenate merge output from each model\n",
    "        ensemble_outputs = [model.output for model in members]\n",
    "        merge = concatenate(ensemble_outputs)\n",
    "        hidden = Dense(10, activation='relu')(merge)\n",
    "        output = Dense(3, activation='softmax')(hidden)\n",
    "        model = Model(inputs=ensemble_visible, outputs=output)\n",
    "        # plot graph of ensemble\n",
    "        plot_model(model,show_shapes=True,to_file='model_graph.png')\n",
    "        # compile\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "# fit a stacked model\n",
    "def fit_stacked_model(model, inputX, inputy):\n",
    "        # prepare input data\n",
    "        X = [inputX for _ in range(len(model.input))]\n",
    "        # encode output data\n",
    "        inputy_enc = to_categorical(inputy)\n",
    "        # fit model\n",
    "        model.fit(X, inputy_enc, epochs=300, verbose=0)\n",
    "# make a prediction with a stacked model\n",
    "def predict_stacked_model(model, inputX):\n",
    "        # prepare input data\n",
    "        X = [inputX for _ in range(len(model.input))]\n",
    "        # make prediction\n",
    "        return model.predict(X, verbose=0)\n",
    "# fit model on dataset\n",
    "def fit_model(trainX, trainy):\n",
    "        # define model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        # fit model\n",
    "        model.fit(trainX, trainy, epochs=500, verbose=0)\n",
    "        return model\n",
    "\n",
    "# generate 2D classification dataset\n",
    "X, y = make_blobs(n_samples=1100,centers=3,n_features=2,cluster_std=2,random_state=2)\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)\n",
    "import os\n",
    "import shutil\n",
    "# create directory for models\n",
    "if os.path.isdir('C:/Users/ihlee/testAI/20210107/models'):\n",
    "    shutil.rmtree('C:/Users/ihlee/testAI/20210107/models')\n",
    "    print('directory is present')\n",
    "makedirs('models')\n",
    "# fit and save models\n",
    "n_members = 5\n",
    "for i in range(n_members):\n",
    "        # fit model\n",
    "        model = fit_model(trainX, trainy)\n",
    "        # save model\n",
    "        filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "        model.save(filename)\n",
    "        print('>Saved %s' % filename)\n",
    "\n",
    "# generate 2D classification dataset\n",
    "X, y = make_blobs(n_samples=1100,centers=3,n_features=2,cluster_std=2,random_state=2)\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)\n",
    "# load all models\n",
    "n_members = 5\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))\n",
    "# define ensemble model\n",
    "stacked_model = define_stacked_model(members)\n",
    "# fit stacked model on test dataset\n",
    "fit_stacked_model(stacked_model, testX, testy)\n",
    "# make predictions and evaluate\n",
    "yhat = predict_stacked_model(stacked_model, testX)\n",
    "yhat = argmax(yhat, axis=1)\n",
    "acc = accuracy_score(testy, yhat)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ed871",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.586Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate two moons dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "# generate 2D classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fbf16d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.589Z"
    }
   },
   "outputs": [],
   "source": [
    "# overfit mlp for the moons dataset plotting history\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot\n",
    "# generate 2D classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(trainX,trainy, validation_data=(testX,testy),epochs=4000,verbose=0)\n",
    "# summarize history for accuracy\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ac2e9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.593Z"
    }
   },
   "outputs": [],
   "source": [
    "# mlp with weight regularization for the moons dataset plotting history\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from matplotlib import pyplot\n",
    "# generate 2D classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(trainX,trainy, validation_data=(testX,testy), epochs=4000, verbose=0)\n",
    "# summarize history for accuracy\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8d242",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.596Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid search regularization values for moons dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from matplotlib import pyplot\n",
    "# generate 2D classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# grid search values\n",
    "values = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "all_train, all_test = list(), list()\n",
    "for param in values:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=2, activation='relu', kernel_regularizer=l2(param)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(trainX, trainy, epochs=4000, verbose=0)\n",
    "    _, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "    _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "    print('Param: %f, Train: %.3f, Test: %.3f' % (param, train_acc, test_acc))\n",
    "    all_train.append(train_acc)\n",
    "    all_test.append(test_acc)\n",
    "# plot train and test means\n",
    "pyplot.semilogx(values, all_train, label='train', marker='o')\n",
    "pyplot.semilogx(values, all_test, label='test', marker='o')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86cac71",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.600Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3D plot of the test function\n",
    "from numpy import arange\n",
    "from numpy import meshgrid\n",
    "from matplotlib import pyplot\n",
    "# objective function\n",
    "def objective(x, y):\n",
    "    return x**2.0 + y**2.0\n",
    "# define range for input\n",
    "r_min, r_max = -1.0, 1.0\n",
    "# sample input range uniformly at 0.1 increments\n",
    "xaxis = arange(r_min, r_max, 0.1)\n",
    "yaxis = arange(r_min, r_max, 0.1)\n",
    "# create a mesh from the axis\n",
    "x, y = meshgrid(xaxis, yaxis)\n",
    "# compute targets\n",
    "results = objective(x, y)\n",
    "# create a surface plot with the jet color scheme\n",
    "figure = pyplot.figure()\n",
    "axis = figure.gca(projection='3d')\n",
    "axis.plot_surface(x, y, results, cmap='jet')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c828003f",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1412.6980.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5672b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.606Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gradient descent optimization with adam for a two-dimensional test function\n",
    "from math import sqrt\n",
    "from numpy import asarray\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "# objective function\n",
    "def objective(x, y):\n",
    "    return x**2.0 + y**2.0\n",
    "# derivative of objective function\n",
    "def derivative(x, y):\n",
    "    return asarray([x * 2.0, y * 2.0])\n",
    "# gradient descent algorithm with adam\n",
    "def adam(objective, derivative, bounds, n_iter, alpha, beta1, beta2, eps=1e-8):\n",
    "    # generate an initial point\n",
    "    x = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "    score = objective(x[0], x[1])\n",
    "    # initialize first and second moments\n",
    "    m = [0.0 for _ in range(bounds.shape[0])]\n",
    "    v = [0.0 for _ in range(bounds.shape[0])]\n",
    "    # run the gradient descent updates\n",
    "    for t in range(n_iter):\n",
    "        # calculate gradient g(t)\n",
    "        g = derivative(x[0], x[1])\n",
    "        # build a solution one variable at a time\n",
    "        for i in range(x.shape[0]):\n",
    "            # m(t) = beta1 * m(t-1) + (1 - beta1) * g(t)\n",
    "            m[i] = beta1 * m[i] + (1.0 - beta1) * g[i]\n",
    "            # v(t) = beta2 * v(t-1) + (1 - beta2) * g(t)^2\n",
    "            v[i] = beta2 * v[i] + (1.0 - beta2) * g[i]**2\n",
    "            # mhat(t) = m(t) / (1 - beta1(t))\n",
    "            mhat = m[i] / (1.0 - beta1**(t+1))\n",
    "            # vhat(t) = v(t) / (1 - beta2(t))\n",
    "            vhat = v[i] / (1.0 - beta2**(t+1))\n",
    "            # x(t) = x(t-1) - alpha * mhat(t) / (sqrt(vhat(t)) + eps)\n",
    "            x[i] = x[i] - alpha * mhat / (sqrt(vhat) + eps)\n",
    "        # evaluate candidate point\n",
    "        score = objective(x[0], x[1])\n",
    "        # report progress\n",
    "        print('>%d f(%s) = %.5f' % (t, x, score))\n",
    "    return [x, score]\n",
    "\n",
    "# seed the pseudo random number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "# define the total iterations\n",
    "n_iter = 60\n",
    "# steps size\n",
    "alpha = 0.02\n",
    "# factor for average gradient\n",
    "beta1 = 0.8\n",
    "# factor for average squared gradient\n",
    "beta2 = 0.999\n",
    "# perform the gradient descent search with adam\n",
    "best, score = adam(objective, derivative, bounds, n_iter, alpha, beta1, beta2)\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (best, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6382d4b",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/simple-genetic-algorithm-from-scratch-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd154a",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/applications/plot_digits_denoising.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb938a6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.611Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = fetch_openml(data_id=41082, as_frame=False, return_X_y=True)\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464dcd2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.614Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,stratify=y,random_state=0,train_size=1000,test_size=100)\n",
    "rng = np.random.RandomState(0)\n",
    "noise = rng.normal(scale=0.25, size=X_test.shape)\n",
    "X_test_noisy = X_test + noise\n",
    "noise = rng.normal(scale=0.25, size=X_train.shape)\n",
    "X_train_noisy = X_train + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4856bc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.617Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_digits(X, title):\n",
    "    \"\"\"Small helper function to plot 100 digits.\"\"\"\n",
    "    fig, axs = plt.subplots(nrows=10, ncols=10, figsize=(8, 8))\n",
    "    for img, ax in zip(X, axs.ravel()):\n",
    "        ax.imshow(img.reshape((16, 16)), cmap=\"Greys\")\n",
    "        ax.axis(\"off\")\n",
    "    fig.suptitle(title, fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe7dd1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.620Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_digits(X_test, \"Uncorrupted test images\")\n",
    "plot_digits(X_test_noisy, f\"Noisy test images\\nMSE: {np.mean((X_test - X_test_noisy) ** 2):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2489f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.624Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "pca = PCA(n_components=32)\n",
    "kernel_pca = KernelPCA(n_components=400,kernel=\"rbf\",gamma=1e-3,fit_inverse_transform=True,alpha=5e-3)\n",
    "pca.fit(X_train_noisy)\n",
    "_ = kernel_pca.fit(X_train_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd9c81",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.627Z"
    }
   },
   "outputs": [],
   "source": [
    "X_reconstructed_kernel_pca=kernel_pca.inverse_transform(kernel_pca.transform(X_test_noisy))\n",
    "X_reconstructed_pca=pca.inverse_transform(pca.transform(X_test_noisy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78175db3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.633Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_digits(X_test, \"Uncorrupted test images\")\n",
    "plot_digits(X_reconstructed_pca,\n",
    "    f\"PCA reconstruction\\nMSE: {np.mean((X_test - X_reconstructed_pca) ** 2):.2f}\",)\n",
    "plot_digits(X_reconstructed_kernel_pca,\n",
    "    \"Kernel PCA reconstruction\\n\"\n",
    "    f\"MSE: {np.mean((X_test - X_reconstructed_kernel_pca) ** 2):.2f}\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56e993",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.639Z"
    }
   },
   "outputs": [],
   "source": [
    "# cross-entropy for predicted probability distribution vs label\n",
    "from math import log\n",
    "from matplotlib import pyplot\n",
    "# calculate cross-entropy\n",
    "def cross_entropy(p, q, ets=1e-15):\n",
    "    return -sum([p[i]*log(q[i]+ets) for i in range(len(p))])\n",
    "\n",
    "# define the target distribution for two events\n",
    "target = [0.0, 1.0]\n",
    "# define probabilities for the first event\n",
    "probs = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]\n",
    "# create probability distributions for the two events\n",
    "dists = [[1.0 - p, p] for p in probs]\n",
    "# calculate cross-entropy for each distribution\n",
    "ents = [cross_entropy(target, d) for d in dists]\n",
    "# plot probability distribution vs cross-entropy\n",
    "pyplot.plot([1-p for p in probs], ents, marker='.')\n",
    "pyplot.title('Probability Distribution vs Cross-Entropy')\n",
    "pyplot.xticks([1-p for p in probs], ['[%.1f,%.1f]'%(d[0],d[1]) for d in dists], rotation=70)\n",
    "pyplot.subplots_adjust(bottom=0.2)\n",
    "pyplot.xlabel('Probability Distribution')\n",
    "pyplot.ylabel('Cross-Entropy (nats)')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b0a334",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.644Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of calculating the js divergence between two mass functions\n",
    "from math import log2\n",
    "from math import sqrt\n",
    "from numpy import asarray\n",
    "# calculate the KL divergence\n",
    "def kl_divergence(p, q):\n",
    "    return sum(p[i] * log2(p[i]/q[i]) for i in range(len(p)))\n",
    "\n",
    "# calculate the JS divergence\n",
    "def js_divergence(p, q):\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n",
    "\n",
    "# define distributions\n",
    "p = asarray([0.10, 0.40, 0.50])\n",
    "q = asarray([0.80, 0.15, 0.05])\n",
    "# calculate JS(P || Q)\n",
    "js_pq = js_divergence(p, q)\n",
    "print('JS(P || Q) divergence: %.3f bits' % js_pq)\n",
    "print('JS(P || Q) distance: %.3f' % sqrt(js_pq))\n",
    "# calculate JS(Q || P)\n",
    "js_qp = js_divergence(q, p)\n",
    "print('JS(Q || P) divergence: %.3f bits' % js_qp)\n",
    "print('JS(Q || P) distance: %.3f' % sqrt(js_qp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec434ce",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.652Z"
    }
   },
   "outputs": [],
   "source": [
    "# explore xgboost random forest number of trees effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBRFClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000,n_features=20,n_informative=15,n_redundant=5,random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # define the number of trees to consider\n",
    "    n_trees = [10, 50, 100, 500, 1000, 5000]\n",
    "    for v in n_trees:\n",
    "        models[str(v)] = XGBRFClassifier(n_estimators=v, subsample=0.9, colsample_bynode=0.2)\n",
    "    return models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the model evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model and collect the results\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367640e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.660Z"
    }
   },
   "outputs": [],
   "source": [
    "# explore lightgbm boosting type effect on performance\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000,n_features=20,n_informative=15,n_redundant=5,random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    types = ['gbdt', 'dart', 'goss']\n",
    "    for t in types:\n",
    "        models[t] = LGBMClassifier(boosting_type=t)\n",
    "    return models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv,n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab68ee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.667Z"
    }
   },
   "outputs": [],
   "source": [
    "# grid search kernel for gaussian process classifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=100,n_features=20,n_informative=15,n_redundant=5,random_state=1)\n",
    "# define model\n",
    "model = GaussianProcessClassifier()\n",
    "# define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(), 1*DotProduct(), 1*Matern(),  1*RationalQuadratic(), 1*WhiteKernel()]\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize best\n",
    "print('Best Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "# summarize all\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16051098",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.673Z"
    }
   },
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(testy))]\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(testy, ns_probs)\n",
    "lr_auc = roc_auc_score(testy, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a64aa2",
   "metadata": {},
   "source": [
    "First, let’s define a synthetic imbalanced binary classification problem with 10,000 examples, 99 percent of which are in the majority class and 1 percent are in the minority class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36579209",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.678Z"
    }
   },
   "outputs": [],
   "source": [
    "# easy ensemble for imbalanced classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=4)\n",
    "# define model\n",
    "model = EasyEnsembleClassifier(n_estimators=10)\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "# summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c87a4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.681Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of Bayesian optimization for a 1D function from scratch\n",
    "from math import sin\n",
    "from math import pi\n",
    "from numpy import arange\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from numpy import asarray\n",
    "from numpy.random import normal\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# objective function\n",
    "def objective(x, noise=0.1):\n",
    "    noise = normal(loc=0, scale=noise)\n",
    "    return (x**2 * sin(5 * pi * x)**6.0) + noise\n",
    "\n",
    "# surrogate or approximation for the objective function\n",
    "def surrogate(model, X):\n",
    "    # catch any warning generated when making a prediction\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter(\"ignore\")\n",
    "        return model.predict(X, return_std=True)\n",
    "\n",
    "# probability of improvement acquisition function\n",
    "def acquisition(X, Xsamples, model):\n",
    "    # calculate the best surrogate score found so far\n",
    "    yhat, _ = surrogate(model, X)\n",
    "    best = max(yhat)\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "    mu = mu[:, 0]\n",
    "    # calculate the probability of improvement\n",
    "    probs = norm.cdf((mu - best) / (std+1E-9))\n",
    "    return probs\n",
    "\n",
    "# optimize the acquisition function\n",
    "def opt_acquisition(X, y, model):\n",
    "    # random search, generate random samples\n",
    "    Xsamples = random(100)\n",
    "    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(X, Xsamples, model)\n",
    "    # locate the index of the largest scores\n",
    "    ix = argmax(scores)\n",
    "    return Xsamples[ix, 0]\n",
    "\n",
    "# plot real observations vs surrogate function\n",
    "def plot(X, y, model):\n",
    "    # scatter plot of inputs and real objective function\n",
    "    pyplot.scatter(X, y)\n",
    "    # line plot of surrogate function across domain\n",
    "    Xsamples = asarray(arange(0, 1, 0.001))\n",
    "    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "    ysamples, _ = surrogate(model, Xsamples)\n",
    "    pyplot.plot(Xsamples, ysamples)\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "\n",
    "# sample the domain sparsely with noise\n",
    "X = random(100)\n",
    "y = asarray([objective(x) for x in X])\n",
    "# reshape into rows and cols\n",
    "X = X.reshape(len(X), 1)\n",
    "y = y.reshape(len(y), 1)\n",
    "# define the model\n",
    "model = GaussianProcessRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# plot before hand\n",
    "plot(X, y, model)\n",
    "# perform the optimization process\n",
    "for i in range(100):\n",
    "    # select the next point to sample\n",
    "    x = opt_acquisition(X, y, model)\n",
    "    # sample the point\n",
    "    actual = objective(x)\n",
    "    # summarize the finding\n",
    "    est, _ = surrogate(model, [[x]])\n",
    "    print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "    # add the data to the dataset\n",
    "    X = vstack((X, [[x]]))\n",
    "    y = vstack((y, [[actual]]))\n",
    "    # update the model\n",
    "    model.fit(X, y)\n",
    "\n",
    "# plot all samples and the final surrogate function\n",
    "plot(X, y, model)\n",
    "# best result\n",
    "ix = argmax(y)\n",
    "print('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31639430",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.685Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import numpy as np\n",
    "def target(x):\n",
    "    return np.exp(-(x-3)**2) + np.exp(-(3*x-2)**2) + 1/(x**2+1)\n",
    "bayes_optimizer = BayesianOptimization(target, {'x': (-2, 6)}, random_state=0)\n",
    "bayes_optimizer.maximize(init_points=2, n_iter=34, acq='ei', xi=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7dd8c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.688Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as optimize\n",
    "from bayes_opt import BayesianOptimization\n",
    "fun = lambda x: (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
    "res = optimize.minimize(fun, (2, 0), method='TNC', tol=1e-10)\n",
    "print(res.x)\n",
    "print(res.fun)\n",
    "def fun(x1,x2):\n",
    "      return -((x1-1)**2+ (x2-2.5)**2)\n",
    "BO = BayesianOptimization(fun, {'x1': (0., 2.), 'x2': (0., 3.) }, verbose=2)\n",
    "BO.maximize(init_points=2, n_iter=40)\n",
    "for i, res in enumerate(BO.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "print(BO.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c8055",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.693Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import numpy as np\n",
    "def lgb_evaluate(numLeaves, maxDepth, scaleWeight, minChildWeight, subsample, colSam):\n",
    "    reg=lgb.LGBMRegressor(num_leaves=31, max_depth= 2,scale_pos_weight= scaleWeight, min_child_weight= minChildWeight, subsample= 0.4, colsample_bytree= 0.4, learning_rate=0.05,   n_estimators=20)\n",
    "#   scores = cross_val_score(reg, train_x, train_y, cv=5, scoring='roc_auc')\n",
    "    scores = cross_val_score(reg,train_x,train_y,cv=5,scoring='neg_mean_squared_error')\n",
    "    return np.mean(scores)\n",
    "def bayesOpt(train_x, train_y):\n",
    "    lgbBO = BayesianOptimization(lgb_evaluate, {'numLeaves': (5,90),'maxDepth': (2,90),'scaleWeight': (1,10000),'minChildWeight': (0.01,70),'subsample': (0.4,1),'colSam': (0.4,1) })\n",
    "    lgbBO.maximize(init_points=5, n_iter=50)\n",
    "    print(lgbBO.res)\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "train_x, X_test, train_y, y_test = train_test_split(X, y, test_size=0.2)\n",
    "bayesOpt(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ff6cc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.696Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import loadtxt\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import numpy as np\n",
    "def lgb_evaluate(numLeaves, maxDepth, scaleWeight, minChildWeight, subsample, colSam):\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        objective = 'binary',\n",
    "        metric= 'auc',\n",
    "        reg_alpha= 0,\n",
    "        reg_lambda= 2,\n",
    "#       bagging_fraction= 0.999,\n",
    "        min_split_gain= 0,\n",
    "        min_child_samples= 10,\n",
    "        subsample_freq= 3,\n",
    "#       subsample_for_bin= 50000,\n",
    "#       n_estimators= 9999999,\n",
    "        n_estimators= 99,\n",
    "        num_leaves= int(numLeaves),\n",
    "        max_depth= int(maxDepth),\n",
    "        scale_pos_weight= scaleWeight,\n",
    "        min_child_weight= minChildWeight,\n",
    "        subsample= subsample,\n",
    "        colsample_bytree= colSam,\n",
    "        verbose =-1)\n",
    "    scores = cross_val_score(clf, train_x, train_y, cv=5, scoring='roc_auc')\n",
    "    return np.mean(scores)\n",
    "def bayesOpt(train_x, train_y):\n",
    "    lgbBO = BayesianOptimization(lgb_evaluate, {                                               \n",
    "                                                'numLeaves':  (5, 90),\n",
    "                                                'maxDepth': (2, 90),\n",
    "                                                'scaleWeight': (1, 10000),\n",
    "                                                'minChildWeight': (0.01, 70),\n",
    "                                                'subsample': (0.4, 1),                                               \n",
    "                                                'colSam': (0.4, 1)\n",
    "                                            })\n",
    "    lgbBO.maximize(init_points=5, n_iter=200)\n",
    "    print(lgbBO.res)\n",
    "dataset = loadtxt('C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "train_x, X_test, train_y, y_test = train_test_split(X, y, test_size=0.2)\n",
    "bayesOpt(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497edd64",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.699Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First XGBoost model for Pima Indians dataset\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load data\n",
    "dataset = loadtxt('C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927a71b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.702Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot feature importance using built-in function\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "dataset = loadtxt('C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X, y)\n",
    "# plot feature importance\n",
    "plot_importance(model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6028c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.708Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot learning curve\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "dataset =loadtxt('C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model.fit(X_train,y_train,eval_metric=[\"error\",\"logloss\"],eval_set=eval_set,verbose=True)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test,predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# retrieve performance metrics\n",
    "results = model.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Log Loss')\n",
    "pyplot.title('XGBoost Log Loss')\n",
    "pyplot.show()\n",
    "# plot classification error\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Classification Error')\n",
    "pyplot.title('XGBoost Classification Error')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b673e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.714Z"
    }
   },
   "outputs": [],
   "source": [
    "# explore lightgbm number of trees effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    trees = [10, 50, 100, 500, 1000, 5000]\n",
    "    for n in trees:\n",
    "        models[str(n)] = LGBMClassifier(n_estimators=n)\n",
    "    return models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "    cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3,random_state=1)\n",
    "    scores=cross_val_score(model,X,y,scoring='accuracy',cv=cv,n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00687eb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Author: Andreas Mueller <amueller@ais.uni-bonn.de>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# This dataset is way too high-dimensional. Better do PCA:\n",
    "pca = PCA(n_components=2)\n",
    "# Maybe some original features were good, too?\n",
    "selection = SelectKBest(k=1)\n",
    "# Build estimator from PCA and Univariate selection:\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "# Use combined features to transform dataset:\n",
    "X_features = combined_features.fit(X, y).transform(X)\n",
    "print(\"Combined space has\", X_features.shape[1], \"features\")\n",
    "svm = SVC(kernel=\"linear\")\n",
    "# Do grid search over k, n_components and C:\n",
    "pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "param_grid = dict(\n",
    "    features__pca__n_components=[1, 2, 3],\n",
    "    features__univ_select__k=[1, 2],\n",
    "    svm__C=[0.1, 1, 10],)\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=10)\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e236a6e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.730Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of manually specifying the loss function for binary classification\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "# define dataset\n",
    "X, y =make_classification(n_samples=1000,n_features=20,n_informative=15,n_redundant=5,random_state=1)\n",
    "# define the model\n",
    "model = XGBClassifier(objective='binary:logistic')\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# summarize the model loss function\n",
    "print(model.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b25a93f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.734Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of automatically choosing the loss function for multi-class classification\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1, n_classes=3)\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# summarize the model loss function\n",
    "print(model.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c114a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.738Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of automatically choosing the loss function for regression\n",
    "from sklearn.datasets import make_regression\n",
    "from xgboost import XGBRegressor\n",
    "# define dataset\n",
    "X, y =make_regression(n_samples=1000,n_features=20,n_informative=15,noise=0.1,random_state=7)\n",
    "# define the model\n",
    "model = XGBRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# summarize the model loss function\n",
    "print(model.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3302e7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.741Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.20,random_state=42)\n",
    "print(\"Train data length:\",len(X_train));\n",
    "print(\"Test data length:\",len(X_test));\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "parameters = {\n",
    "    'eta': 0.3,\n",
    "    'silent': True,  # option for logging\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass tasks\n",
    "    'num_class': 3,  # number of classes to predic\n",
    "    'max_depth': 3  # depth of the trees in the boosting process\n",
    "    }\n",
    "num_round = 20  # the number of training iterations\n",
    "bst = xgb.train(parameters, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "print( preds[:5])\n",
    "'''\n",
    "Selecting the column that represents the highest probability\n",
    "(note that, for each line, there is 3 columns, indicating the probability for each class)\n",
    "'''\n",
    "import numpy as np\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print(best_preds)\n",
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(y_test,best_preds,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a9a95",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.745Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "from sklearn.metrics import precision_score\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "# use DMatrix for xgbosot\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "# use svmlight file for xgboost\n",
    "dump_svmlight_file(X_train,y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test,y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')\n",
    "# set xgboost params\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations\n",
    "#------------- numpy array ------------------\n",
    "# training and testing - numpy matrices\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "# extracting most confident predictions\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print(\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))\n",
    "# ------------- svm file ---------------------\n",
    "# training and testing - svm file\n",
    "bst_svm = xgb.train(param, dtrain_svm, num_round)\n",
    "preds = bst.predict(dtest_svm)\n",
    "# extracting most confident predictions\n",
    "best_preds_svm = [np.argmax(line) for line in preds]\n",
    "print(\"Svm file precision:\",precision_score(y_test, best_preds_svm, average='macro'))\n",
    "# --------------------------------------------\n",
    "# dump the models\n",
    "bst.dump_model('dump.raw.txt')\n",
    "bst_svm.dump_model('dump_svm.raw.txt')\n",
    "# save the models for later\n",
    "joblib.dump(bst, 'bst_model.pkl', compress=True)\n",
    "joblib.dump(bst_svm, 'bst_svm_model.pkl', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2345c30",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.749Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "X_reduced = PCA(n_components=3).fit_transform(iris.data)\n",
    "ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "plt.show()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "X = iris.data  # we only take the first two features.\n",
    "y = iris.target\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))\n",
    "le = preprocessing.LabelEncoder() #\n",
    "y_label=le.fit_transform(y)\n",
    "classes=le.classes_\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y_label,test_size=0.30,random_state=42)\n",
    "\n",
    "params = {\n",
    "          \"objective\" : \"multiclass\",\n",
    "          \"num_class\" : 4,\n",
    "          \"num_leaves\" : 60,\n",
    "          \"max_depth\": -1,\n",
    "          \"learning_rate\" : 0.01,\n",
    "          \"bagging_fraction\" : 0.9,  # subsample\n",
    "          \"feature_fraction\" : 0.9,  # colsample_bytree\n",
    "          \"bagging_freq\" : 5,        # subsample_freq\n",
    "          \"bagging_seed\" : 2018,\n",
    "          \"verbosity\" : -1 }\n",
    "\n",
    "\n",
    "lgtrain, lgval = lgb.Dataset(X_train, y_train), lgb.Dataset(X_test, y_test)\n",
    "lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "y_pred =np.argmax(lgbmodel.predict(X_test),axis=1)\n",
    "y_true =y_test\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, classes=classes,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "from sklearn.metrics import accuracy_score\n",
    "print( accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31087e",
   "metadata": {},
   "source": [
    "AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbbf24",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.753Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "\n",
    "# synthetic classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=2000,n_features=30,n_informative=10,n_redundant=10,random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "num_inputs = 30\n",
    "num_hidden = 2 \n",
    "num_outputs = num_inputs \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(num_inputs, input_shape=[num_inputs]))\n",
    "model.add(Dense(20,activation='relu'))    # 5 < 20 < num_inputs\n",
    "model.add(Dense(5,activation='relu'))     # 2 < 5 \n",
    "model.add(Dense(num_hidden, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))   # 2 < 5\n",
    "model.add(Dense(20,activation='relu'))   # 2 < 5 < 20 < num_outputs=num_inputs\n",
    "model.add(Dense(num_outputs))\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X, X, validation_split=0.20, epochs=250, batch_size=10, verbose=0)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss', fontsize=20)\n",
    "plt.ylabel('loss', fontsize=20)\n",
    "plt.xlabel('epoch', fontsize=20)\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(index=3).output)\n",
    "intermediate_output = intermediate_layer_model.predict(X)\n",
    "print(intermediate_output.shape)\n",
    "\n",
    "sns.scatterplot(intermediate_output[:,0],intermediate_output[:,1], hue=y  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f3f5c",
   "metadata": {},
   "source": [
    "VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ecc1e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.757Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab03e8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.761Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf44aa6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.764Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5121d03",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.768Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b964b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.771Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda92a6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.774Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(mnist_digits, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a91fd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.778Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d572850",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.784Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_label_clusters(vae, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "plot_label_clusters(vae, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ce13e",
   "metadata": {},
   "source": [
    "ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc72cc7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.789Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "#     this is the size of our encoded representations\n",
    "encoding_dim = 32           # 32 floats -> compression of factor 24.5, assuming the input is 784 floats, 28*28/32 = 24.5\n",
    "\n",
    "#     this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "#     \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "#      \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "#      this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "#      this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "#     create a placeholder for an encoded 32D input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "#     retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "#     create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))\n",
    "#     encode and decode some digits\n",
    "#     note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "#     use matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "n = 10                     # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    #      display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    #      display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f84de9",
   "metadata": {},
   "source": [
    "denoising "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f106f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.794Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 784))\n",
    "x_test = np.reshape(x_test, (len(x_test), 784))\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=784))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(784, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.fit(x_train_noisy, x_train, epochs=100,batch_size=256, shuffle=True, validation_data=(x_test_noisy, x_test))\n",
    "decoded_imgs = model.predict(x_test)\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(1, n+1):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # display noisy\n",
    "    ax = plt.subplot(3, n, i + n)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + 2*n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e7712",
   "metadata": {},
   "source": [
    "1D GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea478109",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.803Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_real_samples(n):\n",
    "    '''generate n real samples with class labels'''\n",
    "    x1 = np.random.rand(n) - 0.5 #generate a random number between [-0.5,0.5]\n",
    "    x2 = x1**3        #generate outputs\n",
    "    x1 = x1.reshape(n, 1)\n",
    "    x2 = x2.reshape(n, 1)\n",
    "    X = np.hstack((x1, x2))   #stack layers\n",
    "    y = np.ones((n, 1))     #generate class label\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ffd20",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.809Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def define_discriminator(inputs = 2):\n",
    "    ''' function to return the compiled discriminator model'''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, activation = 'relu', kernel_initializer = 'he_uniform', input_dim = inputs))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(15, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(5, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "discriminator_model = define_discriminator()\n",
    "discriminator_model.summary()\n",
    "plot_model(discriminator_model, to_file = 'discriminator_model.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed18c3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.812Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_generator(latent_dim, outputs = 2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, activation = 'relu', kernel_initializer= 'he_uniform', input_dim = latent_dim))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(15, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model.add(LeakyReLU(alpha = 0.01))\n",
    "    model.add(Dense(outputs, activation = 'linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8009d1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.815Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 5\n",
    "generator_model = define_generator(latent_dim)\n",
    "generator_model.summary()\n",
    "plot_model(generator_model, to_file = 'generator_model.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafb291",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.818Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n):\n",
    "    '''generate points in latent space as input for the generator'''\n",
    "    x_input = np.random.rand(latent_dim*n) #generate points in latent space\n",
    "    x_input = x_input.reshape(n,latent_dim)  #reshape\n",
    "    return x_input\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n):\n",
    "    x_input = generate_latent_points(latent_dim, n) #genarate points in latent space\n",
    "    x = generator.predict(x_input) #predict outputs\n",
    "    y = np.zeros((n, 1))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5b28e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.820Z"
    }
   },
   "outputs": [],
   "source": [
    "X, _ = generate_fake_samples(generator_model, latent_dim, 100)\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a1b65",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.823Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    '''define the combined generator and discriminator model'''\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650a835",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.826Z"
    }
   },
   "outputs": [],
   "source": [
    "gan_model = define_gan(generator_model, discriminator_model)\n",
    "gan_model.summary()\n",
    "plot_model(gan_model, to_file = 'gan_model.png', show_layer_names = True, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d0123",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.829Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_gan(g_model,d_model,gan_model,latent_dim, num_epochs = 10000,num_eval = 2000, batch_size = 128):\n",
    "    ''' function to train gan model'''\n",
    "    half_batch = int(batch_size/2)\n",
    "  #run epochs\n",
    "    for i in range(num_epochs):\n",
    "        X_real, y_real = generate_real_samples(half_batch) #generate real examples\n",
    "        d_model.train_on_batch(X_real, y_real)               # train on real data\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch) #generate fake samples\n",
    "        d_model.train_on_batch(X_fake, y_fake)                #train on fake data\n",
    "        #prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_points(latent_dim, batch_size)\n",
    "        y_gan = np.ones((batch_size, 1))    #generate fake labels for gan\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "        if (i+1) % num_eval == 0:\n",
    "            summarize_performance(i + 1, g_model, d_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49fdc9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.831Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, generator, discriminator, latent_dim, n = 100):\n",
    "    '''evaluate the discriminator and plot real and fake samples'''\n",
    "    x_real, y_real = generate_real_samples(n)      #generate real samples\n",
    "    _, acc_real = discriminator.evaluate(x_real, y_real, verbose = 1)\n",
    "    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose = 1)\n",
    "    print('Epoch: ' + str(epoch) + ' Real Acc.: ' + str(acc_real) + ' Fake Acc.: '+ str(acc_fake))\n",
    "    plt.scatter(x_real[:,0], x_real[:,1], color = 'red')\n",
    "    plt.scatter(x_fake[:,0], x_fake[:,1], color = 'blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1d9d0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.837Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gan(generator_model, discriminator_model, gan_model, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3265f5",
   "metadata": {},
   "source": [
    "표준화 = StandardScaler\n",
    "정규화 = MinMaxScaler\n",
    " \n",
    "정규화란, 모든 값을 0~1 사이의 값으로 바꾸는 것\n",
    "\n",
    "표준화란, 모든 값을 평균이 0이고 분산이 1인 정규 분포로 만드는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64bdf6",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/muammerhuseyinoglu/prediction-of-wine-quality/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0cc31f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.842Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe26c9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.844Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "df = pd.read_csv('C:/Users/ihlee/testAI/winequality-red.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498e6d6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.847Z"
    }
   },
   "outputs": [],
   "source": [
    "quality = df[\"quality\"].values\n",
    "category = []\n",
    "for num in quality:\n",
    "    if num<=5:\n",
    "        category.append(\"Bad\")\n",
    "    elif num>6:\n",
    "        category.append(\"Good\")\n",
    "    else:\n",
    "        category.append(\"Mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e54b12",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.850Z"
    }
   },
   "outputs": [],
   "source": [
    "#Information about the data columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19208b06",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.853Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create new data\n",
    "category = pd.DataFrame(data=category, columns=[\"category\"])\n",
    "data = pd.concat([df,category],axis=1)\n",
    "data.drop(columns=\"quality\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3efc1e4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.856Z"
    }
   },
   "outputs": [],
   "source": [
    "#Here we see that its quite a downing trend in the volatile acidity as we go higher the quality \n",
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(x = 'quality', y = 'volatile acidity', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e83bd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.859Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03854e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.861Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(data[\"category\"],palette=\"muted\")\n",
    "data[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6a947",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.864Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25882689",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.867Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=df[\"quality\"],y=df[\"alcohol\"],palette=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37e1e7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.871Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.jointplot(y=df[\"density\"],x=df[\"alcohol\"],kind=\"hex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd733fc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.874Z"
    }
   },
   "outputs": [],
   "source": [
    "X= data.iloc[:,:-1].values\n",
    "y=data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0775878",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.877Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a9126f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.880Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y =LabelEncoder()\n",
    "y= labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d477bf3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.882Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(k_neighbors=4)\n",
    "# transform the dataset\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadfb80",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.885Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722dfc62",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.888Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3856e431",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "x_pca = pca.fit_transform(X)\n",
    "#plot the graph to find the principal components\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), 'ro-')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4cdd2d",
   "metadata": {},
   "source": [
    "#AS per the graph, we can see that 8 principal components attribute for 90% of variation in the data. \n",
    "#we shall pick the first 8 components for our prediction.\n",
    "pca_new = PCA(n_components=8)\n",
    "x_new = pca_new.fit_transform(X)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_new, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d25243",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.892Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "pred_svc =svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c50ad3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.895Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predicting Cross Validation Score\n",
    "cv_dt = cross_val_score(estimator = svc, X = X_train, y = y_train, cv = 10)\n",
    "print(\"CV: \", cv_dt.mean())\n",
    "\n",
    "y_pred_dt_train = svc.predict(X_train)\n",
    "accuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\n",
    "print(\"Training set: \", accuracy_dt_train)\n",
    "\n",
    "y_pred_dt_test = svc.predict(X_test)\n",
    "accuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\n",
    "print(\"Test set: \", accuracy_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2f53a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.897Z"
    }
   },
   "outputs": [],
   "source": [
    "con_mat = confusion_matrix(y_test,pred_svc)\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28732f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.902Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "print(classification_report(y_test,pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c1c73",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.908Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=250)\n",
    "rfc.fit(X_train, y_train)\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "print(classification_report(y_test, pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c78c6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.913Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "importances = rfc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd80950",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.916Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(rfc.feature_importances_,index =feature_names)\n",
    "feat_importances.nlargest(11).plot(kind=\"barh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b5857",
   "metadata": {},
   "source": [
    "pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bf4b2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.919Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting Cross Validation Score\n",
    "cv_dt = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\n",
    "print(\"CV: \", cv_dt.mean())\n",
    "\n",
    "y_pred_dt_train = rfc.predict(X_train)\n",
    "accuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\n",
    "print(\"Training set: \", accuracy_dt_train)\n",
    "\n",
    "y_pred_dt_test = rfc.predict(X_test)\n",
    "accuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\n",
    "print(\"Test set: \", accuracy_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed7394d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.922Z"
    }
   },
   "outputs": [],
   "source": [
    "con_mat = confusion_matrix(y_test,pred_rfc)\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de35686",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.925Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "pred_knn=knn.predict(X_test)\n",
    "print(classification_report(y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf6d99",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting Cross Validation Score\n",
    "cv_dt = cross_val_score(estimator = knn, X = X_train, y = y_train, cv = 10)\n",
    "print(\"CV: \", cv_dt.mean())\n",
    "\n",
    "y_pred_dt_train = knn.predict(X_train)\n",
    "accuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\n",
    "print(\"Training set: \", accuracy_dt_train)\n",
    "\n",
    "y_pred_dt_test = knn.predict(X_test)\n",
    "accuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\n",
    "print(\"Test set: \", accuracy_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b4e53",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.933Z"
    }
   },
   "outputs": [],
   "source": [
    "con_mat = confusion_matrix(y_test,pred_knn)\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541f5ee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.938Z"
    }
   },
   "outputs": [],
   "source": [
    "conclusion = pd.DataFrame({'models': [\"SVC\",\"Random Forest\",\"KNN\"],\n",
    "                           'accuracies': [accuracy_score(y_test,pred_svc),accuracy_score(y_test,pred_rfc),accuracy_score(y_test,pred_knn)]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8e508",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.944Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate = 0.1, loss = 'deviance', n_estimators = 100)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9658ea9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting Cross Validation Score\n",
    "cv_dt = cross_val_score(estimator = xgb, X = X_train, y = y_train, cv = 10)\n",
    "print(\"CV: \", cv_dt.mean())\n",
    "\n",
    "y_pred_dt_train = xgb.predict(X_train)\n",
    "accuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\n",
    "print(\"Training set: \", accuracy_dt_train)\n",
    "\n",
    "y_pred_dt_test = xgb.predict(X_test)\n",
    "accuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\n",
    "print(\"Test set: \", accuracy_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d20be",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.950Z"
    }
   },
   "outputs": [],
   "source": [
    "con_mat = confusion_matrix(y_test,y_pred_dt_test)\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250eaa9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.953Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedfb09",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.956Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predicting Cross Validation Score\n",
    "cv_dt = cross_val_score(estimator = lgbm, X = X_train, y = y_train, cv = 10)\n",
    "print(\"CV: \", cv_dt.mean())\n",
    "\n",
    "y_pred_dt_train = lgbm.predict(X_train)\n",
    "accuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\n",
    "print(\"Training set: \", accuracy_dt_train)\n",
    "\n",
    "y_pred_dt_test = lgbm.predict(X_test)\n",
    "accuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\n",
    "print(\"Test set: \", accuracy_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5deaabf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.959Z"
    }
   },
   "outputs": [],
   "source": [
    "con_mat = confusion_matrix(y_test,y_pred_dt_test)\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2363b9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.962Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier()\n",
    "cat.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f289e0f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting Cross Validation Score\n",
    "cv_dt = cross_val_score(estimator = cat, X = X_train, y = y_train, cv = 10)\n",
    "print(\"CV: \", cv_dt.mean())\n",
    "\n",
    "y_pred_dt_train = cat.predict(X_train)\n",
    "accuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\n",
    "print(\"Training set: \", accuracy_dt_train)\n",
    "\n",
    "y_pred_dt_test = cat.predict(X_test)\n",
    "accuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\n",
    "print(\"Test set: \", accuracy_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7791fb7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.968Z"
    }
   },
   "outputs": [],
   "source": [
    "con_mat = confusion_matrix(y_test,y_pred_dt_test)\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d641c2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "# scatter plot of examples by class label\n",
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ef787",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.974Z"
    }
   },
   "outputs": [],
   "source": [
    "# decision tree evaluated on imbalanced dataset\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "# define model\n",
    "model = DecisionTreeClassifier()\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a6e03",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.976Z"
    }
   },
   "outputs": [],
   "source": [
    "# decision tree evaluated on imbalanced dataset with SMOTE oversampling\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "# define pipeline\n",
    "steps = [('over', SMOTE()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2e946",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.979Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "items = [\"tv\", \"radio\", \"microwave\", \"mixer\", \"fan\", \"monitor\", \"keyboard\"]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aeeb48",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.982Z"
    }
   },
   "outputs": [],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6667b4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.985Z"
    }
   },
   "outputs": [],
   "source": [
    "print(encoder.inverse_transform([4, 5, 3, 2, 4, 2, 0, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f2a23",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.989Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'items': items})\n",
    "print(df)\n",
    "print(pd.get_dummies(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad786365",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.993Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.tree import export_graphviz\n",
    "#import graphviz\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_target = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_target, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=999)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ab931",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:34.997Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "\n",
    "lr_clf = LogisticRegression(solver=\"liblinear\")\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "vo_clf = VotingClassifier(estimators=[(\"LR\", lr_clf), (\"KNN\", knn_clf)], voting=\"soft\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=999)\n",
    "\n",
    "classifiers = [vo_clf, lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    name = classifier.__class__.__name__\n",
    "    print(f\"{name} accuracy : {accuracy_score(y_test, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c575a0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.000Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cancer = load_breast_cancer()\n",
    "np.random.seed(9)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target)\n",
    "\n",
    "params = {'n_estimators': [100], 'max_depth': [6, 8, 10, 12], 'min_samples_leaf': [8, 12, 18],\n",
    "          'min_samples_split': [8, 16, 20]}\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "grid_clf = GridSearchCV(clf, param_grid=params, cv=2, n_jobs=-1)  # -1 은 cpu를 다 쓴다는 의미\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"optimal parameters\\n{grid_clf.best_params_}\")\n",
    "print(f\"best score: {grid_clf.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9bedb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.004Z"
    }
   },
   "outputs": [],
   "source": [
    "# MLP for Pima Indians dataset saved to single file\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load pima indians dataset\n",
    "dataset = loadtxt(\"C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# save model and architecture to single file\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a9eba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.008Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load model\n",
    "model = load_model('model.h5')\n",
    "# summarize model.\n",
    "model.summary()\n",
    "# load dataset\n",
    "dataset = loadtxt(\"C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# evaluate the model\n",
    "score = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c491175",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c8b74",
   "metadata": {},
   "source": [
    "import joblib\n",
    "# save model\n",
    "joblib.dump(my_model, 'lgb.pkl')\n",
    "# load model\n",
    "gbm_pickle = joblib.load('lgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69e1cb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.014Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=10_000, n_features=10)\n",
    "reg = lgb.LGBMRegressor(n_estimators=10,verbose=-1,)\n",
    "reg.fit(X, y)\n",
    "joblib.dump(reg, 'lgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290bf23",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.016Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=1_000, n_features=10)\n",
    "reg = joblib.load('lgb.pkl')\n",
    "preds = reg.predict(X)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c453c26",
   "metadata": {},
   "source": [
    "https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/plot_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449a3d5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.020Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "if lgb.compat.MATPLOTLIB_INSTALLED:\n",
    "    import matplotlib.pyplot as plt\n",
    "else:\n",
    "    raise ImportError('You need to install matplotlib for plot_example.py.')\n",
    "\n",
    "print('Loading data...')\n",
    "# load or create your dataset\n",
    "df_train = pd.read_csv('C:/Users/In-Ho Lee/testAI/regression/regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv('C:/Users/In-Ho Lee/testAI/regression/regression.test', header=None, sep='\\t')\n",
    "\n",
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'num_leaves': 5,\n",
    "    'metric': ('l1', 'l2'),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "evals_result = {}  # to record eval results for plotting\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=[lgb_train, lgb_test],\n",
    "                feature_name=['f' + str(i + 1) for i in range(X_train.shape[-1])],\n",
    "                categorical_feature=[21],\n",
    "                evals_result=evals_result,\n",
    "                verbose_eval=10)\n",
    "\n",
    "print('Plotting metrics recorded during training...')\n",
    "ax = lgb.plot_metric(evals_result, metric='l1')\n",
    "plt.show()\n",
    "\n",
    "print('Plotting feature importances...')\n",
    "ax = lgb.plot_importance(gbm, max_num_features=10)\n",
    "plt.show()\n",
    "\n",
    "print('Plotting split value histogram...')\n",
    "ax = lgb.plot_split_value_histogram(gbm, feature='f26', bins='auto')\n",
    "plt.show()\n",
    "\n",
    "print('Plotting 54th tree...')  # one tree use categorical feature to split\n",
    "ax = lgb.plot_tree(gbm, tree_index=53, figsize=(15, 15), show_info=['split_gain'])\n",
    "plt.show()\n",
    "\n",
    "print('Plotting 54th tree with graphviz...')\n",
    "graph = lgb.create_tree_digraph(gbm, tree_index=53, name='Tree54')\n",
    "graph.render(view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93078af9",
   "metadata": {},
   "source": [
    "https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/python-guide/simple_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2320e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.023Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('Loading data...')\n",
    "# load or create your dataset\n",
    "df_train = pd.read_csv('C:/Users/In-Ho Lee/testAI/regression/regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv('C:/Users/In-Ho Lee/testAI/regression/regression.test', header=None, sep='\\t')\n",
    "\n",
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "print('Saving model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb8986",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.026Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of plotting learning curves\n",
    "from sklearn.datasets import make_classification\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "n_features = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "sgd = SGD(learning_rate=0.001, momentum=0.8)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy')\n",
    "history = model.fit(X,y, epochs=300,batch_size=32,verbose=0,validation_split=0.3)\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Cross Entropy')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "plot_model(model,'model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40202b2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.028Z"
    }
   },
   "outputs": [],
   "source": [
    "#       Binary classification\n",
    "#       A training program with keras\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "np.random.seed(34)\n",
    "#      fix random seed for reproducibility\n",
    "#      np.random.seed(7)\n",
    "#      load pima indians dataset\n",
    "dataset = np.loadtxt(\"C:/Users/ihlee/testAI/scikitlearn_keras_examples/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "#      split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X, Y = shuffle(X,Y,random_state=0)\n",
    "x_train, x_test, y_train, y_test= train_test_split(X,Y, test_size=0.2)\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=8, activation='relu'))\n",
    "for i in range(2):\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.10, epochs=300, batch_size=5, verbose=2)\n",
    "#      evaluate the model\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "predictions=model.predict(x_test)\n",
    "rounded=[round(x[0]) for x in predictions]\n",
    "print(rounded)\n",
    "if True:\n",
    "#      serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "#      serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a52497",
   "metadata": {},
   "source": [
    "pip install pydot pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4020e42",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.037Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "import tensorflow.python.platform.build_info as build\n",
    "print(build.build_info)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n",
    "tf.test.is_built_with_cuda()\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "tf.config.list_physical_devices('CPU')\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27c92c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.040Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())\n",
    "tf.config.experimental.list_physical_devices(device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf4372",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.043Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495395c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.046Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "print('Python version : ', sys.version)\n",
    "print('TensorFlow version : ', tf.__version__)\n",
    "print('Keras version : ', keras.__version__)\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(5,5),strides=(1,1),padding='same',activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model.fit(x_train, y_train,batch_size=batch_size, epochs=epochs,verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save('MNIST_CNN_model.h5')\n",
    "n = 0\n",
    "plt.imshow(x_test[n].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "print('The Answer is ', model.predict_classes(x_test[n].reshape((1, 28, 28, 1))))\n",
    "import random\n",
    "predicted_result = model.predict(x_test)\n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "test_labels = np.argmax(y_test, axis=1)\n",
    "wrong_result = []\n",
    "for n in range(0, len(test_labels)):\n",
    "    if predicted_labels[n] != test_labels[n]:\n",
    "        wrong_result.append(n)\n",
    "samples = random.choices(population=wrong_result, k=16)\n",
    "count = 0\n",
    "nrows = ncols = 4\n",
    "plt.figure(figsize=(12,8))\n",
    "for n in samples:\n",
    "    count += 1\n",
    "    plt.subplot(nrows, ncols, count)\n",
    "    plt.imshow(x_test[n].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    tmp = \"Label:\" + str(test_labels[n]) + \", Prediction:\" + str(predicted_labels[n])\n",
    "    plt.title(tmp)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498f3bd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.049Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "from tensorflow import keras\n",
    "print('Python version : ', sys.version)\n",
    "print('TensorFlow version : ', tf.__version__)\n",
    "print('Keras version : ', keras.__version__)\n",
    "#from keras.models import load_model\n",
    "model = tf.keras.models.load_model('MNIST_CNN_model.h5')\n",
    "model.summary()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if False:\n",
    "    test1 = plt.imread('./my_num/re_1.jpg')\n",
    "    plt.imshow(test1);\n",
    "    test_num = plt.imread('./my_num/re_1.jpg')\n",
    "    test_num = test_num[:,:,0]\n",
    "    test_num = (test_num > 125) * test_num\n",
    "    test_num = test_num.astype('float32') / 255.\n",
    "    plt.imshow(test_num, cmap='Greys', interpolation='nearest');\n",
    "    test_num = test_num.reshape((1, 28, 28, 1))\n",
    "    print('The Answer is ', model.predict_classes(test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c99beec",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple CNN model for the CIFAR-10 Dataset\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=(32,32,3),padding='same',activation='relu',kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu',kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=epochs, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12337e29",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Large CNN model for the CIFAR-10 Dataset\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=(32,32,3),activation='relu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32,(3, 3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu',kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu',kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6a62e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T08:26:35.057Z"
    }
   },
   "outputs": [],
   "source": [
    "# genetic algorithm search for continuous function optimization\n",
    "from numpy.random import randint\n",
    "from numpy.random import rand\n",
    "# objective function\n",
    "def objective(x):\n",
    "    return x[0]**2.0 + x[1]**2.0\n",
    "# decode bitstring to numbers\n",
    "def decode(bounds, n_bits, bitstring):\n",
    "    decoded = list()\n",
    "    largest = 2**n_bits\n",
    "    for i in range(len(bounds)):\n",
    "        # extract the substring\n",
    "        start, end = i * n_bits, (i * n_bits)+n_bits\n",
    "        substring = bitstring[start:end]\n",
    "        # convert bitstring to a string of chars\n",
    "        chars = ''.join([str(s) for s in substring])\n",
    "        # convert string to integer\n",
    "        integer = int(chars, 2)\n",
    "        # scale integer to desired range\n",
    "        value = bounds[i][0] + (integer/largest) * (bounds[i][1] - bounds[i][0])\n",
    "        # store\n",
    "        decoded.append(value)\n",
    "    return decoded\n",
    "# tournament selection\n",
    "def selection(pop, scores, k=3):\n",
    "    # first random selection\n",
    "    selection_ix = randint(len(pop))\n",
    "    for ix in randint(0, len(pop), k-1):\n",
    "        # check if better (e.g. perform a tournament)\n",
    "        if scores[ix] < scores[selection_ix]:\n",
    "            selection_ix = ix\n",
    "    return pop[selection_ix]\n",
    "# crossover two parents to create two children\n",
    "def crossover(p1, p2, r_cross):\n",
    "    # children are copies of parents by default\n",
    "    c1, c2 = p1.copy(), p2.copy()\n",
    "    # check for recombination\n",
    "    if rand() < r_cross:\n",
    "        # select crossover point that is not on the end of the string\n",
    "        pt = randint(1, len(p1)-2)\n",
    "        # perform crossover\n",
    "        c1 = p1[:pt] + p2[pt:]\n",
    "        c2 = p2[:pt] + p1[pt:]\n",
    "    return [c1, c2]\n",
    "# mutation operator\n",
    "def mutation(bitstring, r_mut):\n",
    "    for i in range(len(bitstring)):\n",
    "        # check for a mutation\n",
    "        if rand() < r_mut:\n",
    "            # flip the bit\n",
    "            bitstring[i] = 1 - bitstring[i]\n",
    "# genetic algorithm\n",
    "def genetic_algorithm(objective, bounds, n_bits, n_iter, n_pop, r_cross, r_mut):\n",
    "    # initial population of random bitstring\n",
    "    pop = [randint(0, 2, n_bits*len(bounds)).tolist() for _ in range(n_pop)]\n",
    "    # keep track of best solution\n",
    "    best, best_eval = 0, objective(decode(bounds, n_bits, pop[0]))\n",
    "    # enumerate generations\n",
    "    for gen in range(n_iter):\n",
    "        # decode population\n",
    "        decoded = [decode(bounds, n_bits, p) for p in pop]\n",
    "        # evaluate all candidates in the population\n",
    "        scores = [objective(d) for d in decoded]\n",
    "        # check for new best solution\n",
    "        for i in range(n_pop):\n",
    "            if scores[i] < best_eval:\n",
    "                best, best_eval = pop[i], scores[i]\n",
    "                print(\">%d, new best f(%s) = %f\" % (gen,  decoded[i], scores[i]))\n",
    "        # select parents\n",
    "        selected = [selection(pop, scores) for _ in range(n_pop)]\n",
    "        # create the next generation\n",
    "        children = list()\n",
    "        for i in range(0, n_pop, 2):\n",
    "            # get selected parents in pairs\n",
    "            p1, p2 = selected[i], selected[i+1]\n",
    "            # crossover and mutation\n",
    "            for c in crossover(p1, p2, r_cross):\n",
    "                # mutation\n",
    "                mutation(c, r_mut)\n",
    "                # store for next generation\n",
    "                children.append(c)\n",
    "        # replace population\n",
    "        pop = children\n",
    "    return [best, best_eval]\n",
    "\n",
    "# define range for input\n",
    "bounds = [[-5.0, 5.0], [-5.0, 5.0]]\n",
    "# define the total iterations\n",
    "n_iter = 100\n",
    "# bits per variable\n",
    "n_bits = 16\n",
    "# define the population size\n",
    "n_pop = 100\n",
    "# crossover rate\n",
    "r_cross = 0.9\n",
    "# mutation rate\n",
    "r_mut = 1.0 / (float(n_bits) * len(bounds))\n",
    "# perform the genetic algorithm search\n",
    "best, score = genetic_algorithm(objective, bounds, n_bits, n_iter, n_pop, r_cross, r_mut)\n",
    "print('Done!')\n",
    "decoded = decode(bounds, n_bits, best)\n",
    "print('f(%s) = %f' % (decoded, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testAI",
   "language": "python",
   "name": "testai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
